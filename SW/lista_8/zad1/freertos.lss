
freertos.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .data         00000024  00800100  0000246a  000024fe  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  1 .text         0000246a  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .bss          0000074c  00800124  00800124  00002522  2**0
                  ALLOC
  3 .stab         00007668  00000000  00000000  00002524  2**2
                  CONTENTS, READONLY, DEBUGGING
  4 .stabstr      00004385  00000000  00000000  00009b8c  2**0
                  CONTENTS, READONLY, DEBUGGING
  5 .comment      00000011  00000000  00000000  0000df11  2**0
                  CONTENTS, READONLY
  6 .note.gnu.avr.deviceinfo 00000040  00000000  00000000  0000df24  2**2
                  CONTENTS, READONLY
  7 .debug_info   000005f4  00000000  00000000  0000df64  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_abbrev 000005a2  00000000  00000000  0000e558  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_line   0000001a  00000000  00000000  0000eafa  2**0
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    00000208  00000000  00000000  0000eb14  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	0c 94 34 00 	jmp	0x68	; 0x68 <__ctors_end>
       4:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
       8:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
       c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      10:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      14:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      18:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      1c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      20:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      24:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      28:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      2c:	0c 94 99 11 	jmp	0x2332	; 0x2332 <__vector_11>
      30:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      34:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      38:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      3c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      40:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      44:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      48:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      4c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      50:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      54:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      58:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      5c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      60:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      64:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>

00000068 <__ctors_end>:
      68:	11 24       	eor	r1, r1
      6a:	1f be       	out	0x3f, r1	; 63
      6c:	cf ef       	ldi	r28, 0xFF	; 255
      6e:	d8 e0       	ldi	r29, 0x08	; 8
      70:	de bf       	out	0x3e, r29	; 62
      72:	cd bf       	out	0x3d, r28	; 61

00000074 <__do_copy_data>:
      74:	11 e0       	ldi	r17, 0x01	; 1
      76:	a0 e0       	ldi	r26, 0x00	; 0
      78:	b1 e0       	ldi	r27, 0x01	; 1
      7a:	ea e6       	ldi	r30, 0x6A	; 106
      7c:	f4 e2       	ldi	r31, 0x24	; 36
      7e:	02 c0       	rjmp	.+4      	; 0x84 <__do_copy_data+0x10>
      80:	05 90       	lpm	r0, Z+
      82:	0d 92       	st	X+, r0
      84:	a4 32       	cpi	r26, 0x24	; 36
      86:	b1 07       	cpc	r27, r17
      88:	d9 f7       	brne	.-10     	; 0x80 <__do_copy_data+0xc>

0000008a <__do_clear_bss>:
      8a:	28 e0       	ldi	r18, 0x08	; 8
      8c:	a4 e2       	ldi	r26, 0x24	; 36
      8e:	b1 e0       	ldi	r27, 0x01	; 1
      90:	01 c0       	rjmp	.+2      	; 0x94 <.do_clear_bss_start>

00000092 <.do_clear_bss_loop>:
      92:	1d 92       	st	X+, r1

00000094 <.do_clear_bss_start>:
      94:	a0 37       	cpi	r26, 0x70	; 112
      96:	b2 07       	cpc	r27, r18
      98:	e1 f7       	brne	.-8      	; 0x92 <.do_clear_bss_loop>
      9a:	0e 94 c7 11 	call	0x238e	; 0x238e <main>
      9e:	0c 94 33 12 	jmp	0x2466	; 0x2466 <_exit>

000000a2 <__bad_interrupt>:
      a2:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

000000a6 <vDrabinka>:
}


static void vDrabinka(void* pvParameters)
{
	UCSR0B &= ~_BV(RXEN0) & ~_BV(TXEN0);
      a6:	80 91 c1 00 	lds	r24, 0x00C1	; 0x8000c1 <__DATA_REGION_ORIGIN__+0x61>
      aa:	87 7e       	andi	r24, 0xE7	; 231
      ac:	80 93 c1 00 	sts	0x00C1, r24	; 0x8000c1 <__DATA_REGION_ORIGIN__+0x61>
	LED_DDR_D |= 0b11111111;
      b0:	8a b1       	in	r24, 0x0a	; 10
      b2:	8f ef       	ldi	r24, 0xFF	; 255
      b4:	8a b9       	out	0x0a, r24	; 10
	while(1){
		LED_PORT_D = 0b00000001;
      b6:	11 e0       	ldi	r17, 0x01	; 1
      b8:	1b b9       	out	0x0b, r17	; 11
      ba:	c7 e0       	ldi	r28, 0x07	; 7
      bc:	d0 e0       	ldi	r29, 0x00	; 0
		for (int i = 0; i < 7; ++i)
		{
			LED_PORT_D = (LED_PORT_D << 1);
      be:	8b b1       	in	r24, 0x0b	; 11
      c0:	88 0f       	add	r24, r24
      c2:	8b b9       	out	0x0b, r24	; 11
			vTaskDelay(50 / portTICK_PERIOD_MS);
      c4:	82 e3       	ldi	r24, 0x32	; 50
      c6:	90 e0       	ldi	r25, 0x00	; 0
      c8:	0e 94 e1 04 	call	0x9c2	; 0x9c2 <vTaskDelay>
      cc:	21 97       	sbiw	r28, 0x01	; 1
{
	UCSR0B &= ~_BV(RXEN0) & ~_BV(TXEN0);
	LED_DDR_D |= 0b11111111;
	while(1){
		LED_PORT_D = 0b00000001;
		for (int i = 0; i < 7; ++i)
      ce:	b9 f7       	brne	.-18     	; 0xbe <vDrabinka+0x18>
      d0:	c7 e0       	ldi	r28, 0x07	; 7
      d2:	d0 e0       	ldi	r29, 0x00	; 0
			LED_PORT_D = (LED_PORT_D << 1);
			vTaskDelay(50 / portTICK_PERIOD_MS);
		}
		for (int i = 0; i < 7; ++i)
		{
			LED_PORT_D = (LED_PORT_D >> 1);
      d4:	8b b1       	in	r24, 0x0b	; 11
      d6:	86 95       	lsr	r24
      d8:	8b b9       	out	0x0b, r24	; 11
			vTaskDelay(50 / portTICK_PERIOD_MS);
      da:	82 e3       	ldi	r24, 0x32	; 50
      dc:	90 e0       	ldi	r25, 0x00	; 0
      de:	0e 94 e1 04 	call	0x9c2	; 0x9c2 <vTaskDelay>
      e2:	21 97       	sbiw	r28, 0x01	; 1
		for (int i = 0; i < 7; ++i)
		{
			LED_PORT_D = (LED_PORT_D << 1);
			vTaskDelay(50 / portTICK_PERIOD_MS);
		}
		for (int i = 0; i < 7; ++i)
      e4:	b9 f7       	brne	.-18     	; 0xd4 <vDrabinka+0x2e>
      e6:	e8 cf       	rjmp	.-48     	; 0xb8 <vDrabinka+0x12>

000000e8 <vSekunda>:
 * Private function definitions.
 ******************************************************************************/

static void vSekunda(void* pvParameters)
{
	BTN_PORT |= _BV(BTN);
      e8:	2c 9a       	sbi	0x05, 4	; 5
	LED_DDR |= _BV(LED);
      ea:	25 9a       	sbi	0x04, 5	; 4
	while(1)
	{
		if (BTN_PIN & _BV(BTN))
			press_memory[counter] = 1;
      ec:	c1 e0       	ldi	r28, 0x01	; 1
      ee:	d0 e0       	ldi	r29, 0x00	; 0
		else
			press_memory[counter] = 0;
		if (press_memory[(counter + 1) % 101])
      f0:	05 e6       	ldi	r16, 0x65	; 101
      f2:	10 e0       	ldi	r17, 0x00	; 0
      f4:	80 91 a4 07 	lds	r24, 0x07A4	; 0x8007a4 <counter>
      f8:	90 91 a5 07 	lds	r25, 0x07A5	; 0x8007a5 <counter+0x1>
	BTN_PORT |= _BV(BTN);
	LED_DDR |= _BV(LED);
	while(1)
	{
		if (BTN_PIN & _BV(BTN))
			press_memory[counter] = 1;
      fc:	fc 01       	movw	r30, r24
      fe:	ee 0f       	add	r30, r30
     100:	ff 1f       	adc	r31, r31
     102:	ea 55       	subi	r30, 0x5A	; 90
     104:	f8 4f       	sbci	r31, 0xF8	; 248
{
	BTN_PORT |= _BV(BTN);
	LED_DDR |= _BV(LED);
	while(1)
	{
		if (BTN_PIN & _BV(BTN))
     106:	1c 9b       	sbis	0x03, 4	; 3
     108:	03 c0       	rjmp	.+6      	; 0x110 <vSekunda+0x28>
			press_memory[counter] = 1;
     10a:	d1 83       	std	Z+1, r29	; 0x01
     10c:	c0 83       	st	Z, r28
     10e:	02 c0       	rjmp	.+4      	; 0x114 <vSekunda+0x2c>
		else
			press_memory[counter] = 0;
     110:	11 82       	std	Z+1, r1	; 0x01
     112:	10 82       	st	Z, r1
		if (press_memory[(counter + 1) % 101])
     114:	01 96       	adiw	r24, 0x01	; 1
     116:	b8 01       	movw	r22, r16
     118:	0e 94 02 12 	call	0x2404	; 0x2404 <__divmodhi4>
     11c:	fc 01       	movw	r30, r24
     11e:	ee 0f       	add	r30, r30
     120:	ff 1f       	adc	r31, r31
     122:	ea 55       	subi	r30, 0x5A	; 90
     124:	f8 4f       	sbci	r31, 0xF8	; 248
     126:	80 81       	ld	r24, Z
     128:	91 81       	ldd	r25, Z+1	; 0x01
     12a:	89 2b       	or	r24, r25
     12c:	11 f0       	breq	.+4      	; 0x132 <vSekunda+0x4a>
			LED_PORT &= ~_BV(LED);
     12e:	2d 98       	cbi	0x05, 5	; 5
     130:	01 c0       	rjmp	.+2      	; 0x134 <vSekunda+0x4c>
		else
			LED_PORT |= _BV(LED);
     132:	2d 9a       	sbi	0x05, 5	; 5
		vTaskDelay(10 / portTICK_PERIOD_MS);
     134:	8a e0       	ldi	r24, 0x0A	; 10
     136:	90 e0       	ldi	r25, 0x00	; 0
     138:	0e 94 e1 04 	call	0x9c2	; 0x9c2 <vTaskDelay>
		counter++;
     13c:	80 91 a4 07 	lds	r24, 0x07A4	; 0x8007a4 <counter>
     140:	90 91 a5 07 	lds	r25, 0x07A5	; 0x8007a5 <counter+0x1>
     144:	01 96       	adiw	r24, 0x01	; 1
		if (counter >= 101)
     146:	85 36       	cpi	r24, 0x65	; 101
     148:	91 05       	cpc	r25, r1
     14a:	2c f4       	brge	.+10     	; 0x156 <vSekunda+0x6e>
		if (press_memory[(counter + 1) % 101])
			LED_PORT &= ~_BV(LED);
		else
			LED_PORT |= _BV(LED);
		vTaskDelay(10 / portTICK_PERIOD_MS);
		counter++;
     14c:	90 93 a5 07 	sts	0x07A5, r25	; 0x8007a5 <counter+0x1>
     150:	80 93 a4 07 	sts	0x07A4, r24	; 0x8007a4 <counter>
     154:	04 c0       	rjmp	.+8      	; 0x15e <vSekunda+0x76>
		if (counter >= 101)
		 counter = 0;
     156:	10 92 a5 07 	sts	0x07A5, r1	; 0x8007a5 <counter+0x1>
     15a:	10 92 a4 07 	sts	0x07A4, r1	; 0x8007a4 <counter>
			vTaskDelay(10 / portTICK_PERIOD_MS);
     15e:	8a e0       	ldi	r24, 0x0A	; 10
     160:	90 e0       	ldi	r25, 0x00	; 0
     162:	0e 94 e1 04 	call	0x9c2	; 0x9c2 <vTaskDelay>
	}
     166:	c6 cf       	rjmp	.-116    	; 0xf4 <vSekunda+0xc>

00000168 <vApplicationIdleHook>:
 * \fn static vApplicationIdleHook(void)
 *
 * \brief
 ******************************************************************************/
void vApplicationIdleHook(void)
{
     168:	08 95       	ret

0000016a <prvResetNextTaskUnblockTime>:

static void prvResetNextTaskUnblockTime( void )
{
TCB_t *pxTCB;

	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
     16a:	e0 91 52 01 	lds	r30, 0x0152	; 0x800152 <pxDelayedTaskList>
     16e:	f0 91 53 01 	lds	r31, 0x0153	; 0x800153 <pxDelayedTaskList+0x1>
     172:	80 81       	ld	r24, Z
     174:	81 11       	cpse	r24, r1
     176:	03 c0       	rjmp	.+6      	; 0x17e <prvResetNextTaskUnblockTime+0x14>
	{
		/* The new current delayed list is empty.  Set xNextTaskUnblockTime to
		the maximum possible value so it is	extremely unlikely that the
		if( xTickCount >= xNextTaskUnblockTime ) test will pass until
		there is an item in the delayed list. */
		xNextTaskUnblockTime = portMAX_DELAY;
     178:	8f ef       	ldi	r24, 0xFF	; 255
     17a:	9f ef       	ldi	r25, 0xFF	; 255
     17c:	0c c0       	rjmp	.+24     	; 0x196 <prvResetNextTaskUnblockTime+0x2c>
	{
		/* The new current delayed list is not empty, get the value of
		the item at the head of the delayed list.  This is the time at
		which the task at the head of the delayed list should be removed
		from the Blocked state. */
		( pxTCB ) = listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
     17e:	e0 91 52 01 	lds	r30, 0x0152	; 0x800152 <pxDelayedTaskList>
     182:	f0 91 53 01 	lds	r31, 0x0153	; 0x800153 <pxDelayedTaskList+0x1>
     186:	05 80       	ldd	r0, Z+5	; 0x05
     188:	f6 81       	ldd	r31, Z+6	; 0x06
     18a:	e0 2d       	mov	r30, r0
		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xStateListItem ) );
     18c:	06 80       	ldd	r0, Z+6	; 0x06
     18e:	f7 81       	ldd	r31, Z+7	; 0x07
     190:	e0 2d       	mov	r30, r0
     192:	82 81       	ldd	r24, Z+2	; 0x02
     194:	93 81       	ldd	r25, Z+3	; 0x03
     196:	90 93 2a 01 	sts	0x012A, r25	; 0x80012a <xNextTaskUnblockTime+0x1>
     19a:	80 93 29 01 	sts	0x0129, r24	; 0x800129 <xNextTaskUnblockTime>
     19e:	08 95       	ret

000001a0 <prvAddCurrentTaskToDelayedList>:
#endif /* configUSE_TASK_NOTIFICATIONS */
/*-----------------------------------------------------------*/


static void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait, const BaseType_t xCanBlockIndefinitely )
{
     1a0:	ff 92       	push	r15
     1a2:	0f 93       	push	r16
     1a4:	1f 93       	push	r17
     1a6:	cf 93       	push	r28
     1a8:	df 93       	push	r29
     1aa:	ec 01       	movw	r28, r24
     1ac:	f6 2e       	mov	r15, r22
TickType_t xTimeToWake;
const TickType_t xConstTickCount = xTickCount;
     1ae:	00 91 31 01 	lds	r16, 0x0131	; 0x800131 <xTickCount>
     1b2:	10 91 32 01 	lds	r17, 0x0132	; 0x800132 <xTickCount+0x1>
	}
	#endif

	/* Remove the task from the ready list before adding it to the blocked list
	as the same list item is used for both lists. */
	if( uxListRemove( &( pxCurrentTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
     1b6:	80 91 24 01 	lds	r24, 0x0124	; 0x800124 <__data_end>
     1ba:	90 91 25 01 	lds	r25, 0x0125	; 0x800125 <__data_end+0x1>
     1be:	02 96       	adiw	r24, 0x02	; 2
     1c0:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
		mtCOVERAGE_TEST_MARKER();
	}

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		if( ( xTicksToWait == portMAX_DELAY ) && ( xCanBlockIndefinitely != pdFALSE ) )
     1c4:	cf 3f       	cpi	r28, 0xFF	; 255
     1c6:	8f ef       	ldi	r24, 0xFF	; 255
     1c8:	d8 07       	cpc	r29, r24
     1ca:	89 f4       	brne	.+34     	; 0x1ee <prvAddCurrentTaskToDelayedList+0x4e>
     1cc:	ff 20       	and	r15, r15
     1ce:	79 f0       	breq	.+30     	; 0x1ee <prvAddCurrentTaskToDelayedList+0x4e>
		{
			/* Add the task to the suspended task list instead of a delayed task
			list to ensure it is not woken by a timing event.  It will block
			indefinitely. */
			vListInsertEnd( &xSuspendedTaskList, &( pxCurrentTCB->xStateListItem ) );
     1d0:	60 91 24 01 	lds	r22, 0x0124	; 0x800124 <__data_end>
     1d4:	70 91 25 01 	lds	r23, 0x0125	; 0x800125 <__data_end+0x1>
     1d8:	6e 5f       	subi	r22, 0xFE	; 254
     1da:	7f 4f       	sbci	r23, 0xFF	; 255
     1dc:	84 e3       	ldi	r24, 0x34	; 52
     1de:	91 e0       	ldi	r25, 0x01	; 1

		/* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */
		( void ) xCanBlockIndefinitely;
	}
	#endif /* INCLUDE_vTaskSuspend */
}
     1e0:	df 91       	pop	r29
     1e2:	cf 91       	pop	r28
     1e4:	1f 91       	pop	r17
     1e6:	0f 91       	pop	r16
     1e8:	ff 90       	pop	r15
		if( ( xTicksToWait == portMAX_DELAY ) && ( xCanBlockIndefinitely != pdFALSE ) )
		{
			/* Add the task to the suspended task list instead of a delayed task
			list to ensure it is not woken by a timing event.  It will block
			indefinitely. */
			vListInsertEnd( &xSuspendedTaskList, &( pxCurrentTCB->xStateListItem ) );
     1ea:	0c 94 b3 0d 	jmp	0x1b66	; 0x1b66 <vListInsertEnd>
		else
		{
			/* Calculate the time at which the task should be woken if the event
			does not occur.  This may overflow but this doesn't matter, the
			kernel will manage it correctly. */
			xTimeToWake = xConstTickCount + xTicksToWait;
     1ee:	c0 0f       	add	r28, r16
     1f0:	d1 1f       	adc	r29, r17

			/* The list item will be inserted in wake time order. */
			listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );
     1f2:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     1f6:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     1fa:	d3 83       	std	Z+3, r29	; 0x03
     1fc:	c2 83       	std	Z+2, r28	; 0x02

			if( xTimeToWake < xConstTickCount )
			{
				/* Wake time has overflowed.  Place this item in the overflow
				list. */
				vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
     1fe:	60 91 24 01 	lds	r22, 0x0124	; 0x800124 <__data_end>
     202:	70 91 25 01 	lds	r23, 0x0125	; 0x800125 <__data_end+0x1>
			xTimeToWake = xConstTickCount + xTicksToWait;

			/* The list item will be inserted in wake time order. */
			listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );

			if( xTimeToWake < xConstTickCount )
     206:	c0 17       	cp	r28, r16
     208:	d1 07       	cpc	r29, r17
     20a:	68 f4       	brcc	.+26     	; 0x226 <prvAddCurrentTaskToDelayedList+0x86>
			{
				/* Wake time has overflowed.  Place this item in the overflow
				list. */
				vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
     20c:	80 91 50 01 	lds	r24, 0x0150	; 0x800150 <pxOverflowDelayedTaskList>
     210:	90 91 51 01 	lds	r25, 0x0151	; 0x800151 <pxOverflowDelayedTaskList+0x1>
     214:	6e 5f       	subi	r22, 0xFE	; 254
     216:	7f 4f       	sbci	r23, 0xFF	; 255

		/* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */
		( void ) xCanBlockIndefinitely;
	}
	#endif /* INCLUDE_vTaskSuspend */
}
     218:	df 91       	pop	r29
     21a:	cf 91       	pop	r28
     21c:	1f 91       	pop	r17
     21e:	0f 91       	pop	r16
     220:	ff 90       	pop	r15

			if( xTimeToWake < xConstTickCount )
			{
				/* Wake time has overflowed.  Place this item in the overflow
				list. */
				vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
     222:	0c 94 d4 0d 	jmp	0x1ba8	; 0x1ba8 <vListInsert>
			}
			else
			{
				/* The wake time has not overflowed, so the current block list
				is used. */
				vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
     226:	80 91 52 01 	lds	r24, 0x0152	; 0x800152 <pxDelayedTaskList>
     22a:	90 91 53 01 	lds	r25, 0x0153	; 0x800153 <pxDelayedTaskList+0x1>
     22e:	6e 5f       	subi	r22, 0xFE	; 254
     230:	7f 4f       	sbci	r23, 0xFF	; 255
     232:	0e 94 d4 0d 	call	0x1ba8	; 0x1ba8 <vListInsert>

				/* If the task entering the blocked state was placed at the
				head of the list of blocked tasks then xNextTaskUnblockTime
				needs to be updated too. */
				if( xTimeToWake < xNextTaskUnblockTime )
     236:	80 91 29 01 	lds	r24, 0x0129	; 0x800129 <xNextTaskUnblockTime>
     23a:	90 91 2a 01 	lds	r25, 0x012A	; 0x80012a <xNextTaskUnblockTime+0x1>
     23e:	c8 17       	cp	r28, r24
     240:	d9 07       	cpc	r29, r25
     242:	20 f4       	brcc	.+8      	; 0x24c <prvAddCurrentTaskToDelayedList+0xac>
				{
					xNextTaskUnblockTime = xTimeToWake;
     244:	d0 93 2a 01 	sts	0x012A, r29	; 0x80012a <xNextTaskUnblockTime+0x1>
     248:	c0 93 29 01 	sts	0x0129, r28	; 0x800129 <xNextTaskUnblockTime>

		/* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */
		( void ) xCanBlockIndefinitely;
	}
	#endif /* INCLUDE_vTaskSuspend */
}
     24c:	df 91       	pop	r29
     24e:	cf 91       	pop	r28
     250:	1f 91       	pop	r17
     252:	0f 91       	pop	r16
     254:	ff 90       	pop	r15
     256:	08 95       	ret

00000258 <prvIdleTask>:
	{
		TCB_t *pxTCB;

		/* uxDeletedTasksWaitingCleanUp is used to prevent taskENTER_CRITICAL()
		being called too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
     258:	80 91 3d 01 	lds	r24, 0x013D	; 0x80013d <uxDeletedTasksWaitingCleanUp>
     25c:	88 23       	and	r24, r24
     25e:	09 f1       	breq	.+66     	; 0x2a2 <prvIdleTask+0x4a>
		{
			taskENTER_CRITICAL();
     260:	0f b6       	in	r0, 0x3f	; 63
     262:	f8 94       	cli
     264:	0f 92       	push	r0
			{
				pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
     266:	e0 91 43 01 	lds	r30, 0x0143	; 0x800143 <xTasksWaitingTermination+0x5>
     26a:	f0 91 44 01 	lds	r31, 0x0144	; 0x800144 <xTasksWaitingTermination+0x6>
     26e:	c6 81       	ldd	r28, Z+6	; 0x06
     270:	d7 81       	ldd	r29, Z+7	; 0x07
				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
     272:	ce 01       	movw	r24, r28
     274:	02 96       	adiw	r24, 0x02	; 2
     276:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
				--uxCurrentNumberOfTasks;
     27a:	80 91 33 01 	lds	r24, 0x0133	; 0x800133 <uxCurrentNumberOfTasks>
     27e:	81 50       	subi	r24, 0x01	; 1
     280:	80 93 33 01 	sts	0x0133, r24	; 0x800133 <uxCurrentNumberOfTasks>
				--uxDeletedTasksWaitingCleanUp;
     284:	80 91 3d 01 	lds	r24, 0x013D	; 0x80013d <uxDeletedTasksWaitingCleanUp>
     288:	81 50       	subi	r24, 0x01	; 1
     28a:	80 93 3d 01 	sts	0x013D, r24	; 0x80013d <uxDeletedTasksWaitingCleanUp>
			}
			taskEXIT_CRITICAL();
     28e:	0f 90       	pop	r0
     290:	0f be       	out	0x3f, r0	; 63

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )
		{
			/* The task can only have been allocated dynamically - free both
			the stack and TCB. */
			vPortFree( pxTCB->pxStack );
     292:	8f 89       	ldd	r24, Y+23	; 0x17
     294:	98 8d       	ldd	r25, Y+24	; 0x18
     296:	0e 94 28 10 	call	0x2050	; 0x2050 <vPortFree>
			vPortFree( pxTCB );
     29a:	ce 01       	movw	r24, r28
     29c:	0e 94 28 10 	call	0x2050	; 0x2050 <vPortFree>
     2a0:	db cf       	rjmp	.-74     	; 0x258 <prvIdleTask>

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
     2a2:	80 91 66 01 	lds	r24, 0x0166	; 0x800166 <pxReadyTasksLists>
     2a6:	82 30       	cpi	r24, 0x02	; 2
     2a8:	10 f0       	brcs	.+4      	; 0x2ae <prvIdleTask+0x56>
			{
				taskYIELD();
     2aa:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
			/* Call the user defined function from within the idle task.  This
			allows the application designer to add background functionality
			without the overhead of a separate task.
			NOTE: vApplicationIdleHook() MUST NOT, UNDER ANY CIRCUMSTANCES,
			CALL A FUNCTION THAT MIGHT BLOCK. */
			vApplicationIdleHook();
     2ae:	0e 94 b4 00 	call	0x168	; 0x168 <vApplicationIdleHook>
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_TICKLESS_IDLE */
	}
     2b2:	d2 cf       	rjmp	.-92     	; 0x258 <prvIdleTask>

000002b4 <xTaskCreate>:
							const char * const pcName,		/*lint !e971 Unqualified char types are allowed for strings and single characters only. */
							const configSTACK_DEPTH_TYPE usStackDepth,
							void * const pvParameters,
							UBaseType_t uxPriority,
							TaskHandle_t * const pxCreatedTask )
	{
     2b4:	3f 92       	push	r3
     2b6:	4f 92       	push	r4
     2b8:	5f 92       	push	r5
     2ba:	6f 92       	push	r6
     2bc:	7f 92       	push	r7
     2be:	8f 92       	push	r8
     2c0:	9f 92       	push	r9
     2c2:	af 92       	push	r10
     2c4:	bf 92       	push	r11
     2c6:	cf 92       	push	r12
     2c8:	df 92       	push	r13
     2ca:	ef 92       	push	r14
     2cc:	ff 92       	push	r15
     2ce:	0f 93       	push	r16
     2d0:	1f 93       	push	r17
     2d2:	cf 93       	push	r28
     2d4:	df 93       	push	r29
     2d6:	4c 01       	movw	r8, r24
     2d8:	16 2f       	mov	r17, r22
     2da:	37 2e       	mov	r3, r23
     2dc:	6a 01       	movw	r12, r20
     2de:	59 01       	movw	r10, r18
		#else /* portSTACK_GROWTH */
		{
		StackType_t *pxStack;

			/* Allocate space for the stack used by the task being created. */
			pxStack = pvPortMalloc( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); /*lint !e9079 All values returned by pvPortMalloc() have at least the alignment required by the MCU's stack and this allocation is the stack. */
     2e0:	ca 01       	movw	r24, r20
     2e2:	0e 94 f6 0f 	call	0x1fec	; 0x1fec <pvPortMalloc>
     2e6:	2c 01       	movw	r4, r24

			if( pxStack != NULL )
     2e8:	89 2b       	or	r24, r25
     2ea:	09 f4       	brne	.+2      	; 0x2ee <xTaskCreate+0x3a>
     2ec:	d1 c0       	rjmp	.+418    	; 0x490 <__LOCK_REGION_LENGTH__+0x90>
			{
				/* Allocate space for the TCB. */
				pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) ); /*lint !e9087 !e9079 All values returned by pvPortMalloc() have at least the alignment required by the MCU's stack, and the first member of TCB_t is always a pointer to the task's stack. */
     2ee:	86 e2       	ldi	r24, 0x26	; 38
     2f0:	90 e0       	ldi	r25, 0x00	; 0
     2f2:	0e 94 f6 0f 	call	0x1fec	; 0x1fec <pvPortMalloc>
     2f6:	ec 01       	movw	r28, r24

				if( pxNewTCB != NULL )
     2f8:	89 2b       	or	r24, r25
     2fa:	79 f0       	breq	.+30     	; 0x31a <xTaskCreate+0x66>
				{
					/* Store the stack location in the TCB. */
					pxNewTCB->pxStack = pxStack;
     2fc:	58 8e       	std	Y+24, r5	; 0x18
     2fe:	4f 8a       	std	Y+23, r4	; 0x17
	grows from high memory to low (as per the 80x86) or vice versa.
	portSTACK_GROWTH is used to make the result positive or negative as required
	by the port. */
	#if( portSTACK_GROWTH < 0 )
	{
		pxTopOfStack = &( pxNewTCB->pxStack[ ulStackDepth - ( uint32_t ) 1 ] );
     300:	c6 01       	movw	r24, r12
     302:	01 97       	sbiw	r24, 0x01	; 1
     304:	32 01       	movw	r6, r4
     306:	68 0e       	add	r6, r24
     308:	79 1e       	adc	r7, r25
     30a:	be 01       	movw	r22, r28
     30c:	67 5e       	subi	r22, 0xE7	; 231
     30e:	7f 4f       	sbci	r23, 0xFF	; 255
     310:	e1 2f       	mov	r30, r17
     312:	f3 2d       	mov	r31, r3
     314:	cf 01       	movw	r24, r30
     316:	08 96       	adiw	r24, 0x08	; 8
     318:	07 c0       	rjmp	.+14     	; 0x328 <xTaskCreate+0x74>
				}
				else
				{
					/* The stack cannot be used as the TCB was not created.  Free
					it again. */
					vPortFree( pxStack );
     31a:	c2 01       	movw	r24, r4
     31c:	0e 94 28 10 	call	0x2050	; 0x2050 <vPortFree>
     320:	b7 c0       	rjmp	.+366    	; 0x490 <__LOCK_REGION_LENGTH__+0x90>
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
     322:	e8 17       	cp	r30, r24
     324:	f9 07       	cpc	r31, r25
     326:	49 f0       	breq	.+18     	; 0x33a <xTaskCreate+0x86>
     328:	9f 01       	movw	r18, r30
	{
		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
     32a:	41 91       	ld	r20, Z+
     32c:	db 01       	movw	r26, r22
     32e:	4d 93       	st	X+, r20
     330:	bd 01       	movw	r22, r26

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == ( char ) 0x00 )
     332:	d9 01       	movw	r26, r18
     334:	2c 91       	ld	r18, X
     336:	21 11       	cpse	r18, r1
     338:	f4 cf       	rjmp	.-24     	; 0x322 <xTaskCreate+0x6e>
		}
	}

	/* Ensure the name string is terminated in the case that the string length
	was greater or equal to configMAX_TASK_NAME_LEN. */
	pxNewTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
     33a:	18 a2       	std	Y+32, r1	; 0x20
     33c:	04 30       	cpi	r16, 0x04	; 4
     33e:	08 f0       	brcs	.+2      	; 0x342 <xTaskCreate+0x8e>
     340:	03 e0       	ldi	r16, 0x03	; 3
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxNewTCB->uxPriority = uxPriority;
     342:	0e 8b       	std	Y+22, r16	; 0x16
		pxNewTCB->uxBasePriority = uxPriority;
		pxNewTCB->uxMutexesHeld = 0;
	}
	#endif /* configUSE_MUTEXES */

	vListInitialiseItem( &( pxNewTCB->xStateListItem ) );
     344:	6e 01       	movw	r12, r28
     346:	b2 e0       	ldi	r27, 0x02	; 2
     348:	cb 0e       	add	r12, r27
     34a:	d1 1c       	adc	r13, r1
     34c:	c6 01       	movw	r24, r12
     34e:	0e 94 af 0d 	call	0x1b5e	; 0x1b5e <vListInitialiseItem>
	vListInitialiseItem( &( pxNewTCB->xEventListItem ) );
     352:	ce 01       	movw	r24, r28
     354:	0c 96       	adiw	r24, 0x0c	; 12
     356:	0e 94 af 0d 	call	0x1b5e	; 0x1b5e <vListInitialiseItem>

	/* Set the pxNewTCB as a link back from the ListItem_t.  This is so we can get
	back to	the containing TCB from a generic item in a list. */
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xStateListItem ), pxNewTCB );
     35a:	d9 87       	std	Y+9, r29	; 0x09
     35c:	c8 87       	std	Y+8, r28	; 0x08

	/* Event lists are always in priority order. */
	listSET_LIST_ITEM_VALUE( &( pxNewTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     35e:	84 e0       	ldi	r24, 0x04	; 4
     360:	90 e0       	ldi	r25, 0x00	; 0
     362:	80 1b       	sub	r24, r16
     364:	91 09       	sbc	r25, r1
     366:	9d 87       	std	Y+13, r25	; 0x0d
     368:	8c 87       	std	Y+12, r24	; 0x0c
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xEventListItem ), pxNewTCB );
     36a:	db 8b       	std	Y+19, r29	; 0x13
     36c:	ca 8b       	std	Y+18, r28	; 0x12
	}
	#endif

	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
	{
		pxNewTCB->ulNotifiedValue = 0;
     36e:	19 a2       	std	Y+33, r1	; 0x21
     370:	1a a2       	std	Y+34, r1	; 0x22
     372:	1b a2       	std	Y+35, r1	; 0x23
     374:	1c a2       	std	Y+36, r1	; 0x24
		pxNewTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
     376:	1d a2       	std	Y+37, r1	; 0x25
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged );
	}
	#else /* portUSING_MPU_WRAPPERS */
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
     378:	a5 01       	movw	r20, r10
     37a:	b4 01       	movw	r22, r8
     37c:	c3 01       	movw	r24, r6
     37e:	0e 94 37 10 	call	0x206e	; 0x206e <pxPortInitialiseStack>
     382:	99 83       	std	Y+1, r25	; 0x01
     384:	88 83       	st	Y, r24
	}
	#endif /* portUSING_MPU_WRAPPERS */

	if( pxCreatedTask != NULL )
     386:	e1 14       	cp	r14, r1
     388:	f1 04       	cpc	r15, r1
     38a:	19 f0       	breq	.+6      	; 0x392 <xTaskCreate+0xde>
	{
		/* Pass the handle out in an anonymous way.  The handle can be used to
		change the created task's priority, delete the created task, etc.*/
		*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
     38c:	f7 01       	movw	r30, r14
     38e:	d1 83       	std	Z+1, r29	; 0x01
     390:	c0 83       	st	Z, r28

static void prvAddNewTaskToReadyList( TCB_t *pxNewTCB )
{
	/* Ensure interrupts don't access the task lists while the lists are being
	updated. */
	taskENTER_CRITICAL();
     392:	0f b6       	in	r0, 0x3f	; 63
     394:	f8 94       	cli
     396:	0f 92       	push	r0
	{
		uxCurrentNumberOfTasks++;
     398:	80 91 33 01 	lds	r24, 0x0133	; 0x800133 <uxCurrentNumberOfTasks>
     39c:	8f 5f       	subi	r24, 0xFF	; 255
     39e:	80 93 33 01 	sts	0x0133, r24	; 0x800133 <uxCurrentNumberOfTasks>
		if( pxCurrentTCB == NULL )
     3a2:	80 91 24 01 	lds	r24, 0x0124	; 0x800124 <__data_end>
     3a6:	90 91 25 01 	lds	r25, 0x0125	; 0x800125 <__data_end+0x1>
     3aa:	89 2b       	or	r24, r25
     3ac:	d1 f5       	brne	.+116    	; 0x422 <__LOCK_REGION_LENGTH__+0x22>
		{
			/* There are no other tasks, or all the other tasks are in
			the suspended state - make this the current task. */
			pxCurrentTCB = pxNewTCB;
     3ae:	d0 93 25 01 	sts	0x0125, r29	; 0x800125 <__data_end+0x1>
     3b2:	c0 93 24 01 	sts	0x0124, r28	; 0x800124 <__data_end>

			if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
     3b6:	80 91 33 01 	lds	r24, 0x0133	; 0x800133 <uxCurrentNumberOfTasks>
     3ba:	81 30       	cpi	r24, 0x01	; 1
     3bc:	09 f0       	breq	.+2      	; 0x3c0 <xTaskCreate+0x10c>
     3be:	41 c0       	rjmp	.+130    	; 0x442 <__LOCK_REGION_LENGTH__+0x42>
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
     3c0:	86 e6       	ldi	r24, 0x66	; 102
     3c2:	91 e0       	ldi	r25, 0x01	; 1
     3c4:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
     3c8:	8f e6       	ldi	r24, 0x6F	; 111
     3ca:	91 e0       	ldi	r25, 0x01	; 1
     3cc:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
     3d0:	88 e7       	ldi	r24, 0x78	; 120
     3d2:	91 e0       	ldi	r25, 0x01	; 1
     3d4:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
     3d8:	81 e8       	ldi	r24, 0x81	; 129
     3da:	91 e0       	ldi	r25, 0x01	; 1
     3dc:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	}

	vListInitialise( &xDelayedTaskList1 );
     3e0:	8d e5       	ldi	r24, 0x5D	; 93
     3e2:	91 e0       	ldi	r25, 0x01	; 1
     3e4:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	vListInitialise( &xDelayedTaskList2 );
     3e8:	84 e5       	ldi	r24, 0x54	; 84
     3ea:	91 e0       	ldi	r25, 0x01	; 1
     3ec:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	vListInitialise( &xPendingReadyList );
     3f0:	87 e4       	ldi	r24, 0x47	; 71
     3f2:	91 e0       	ldi	r25, 0x01	; 1
     3f4:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>

	#if ( INCLUDE_vTaskDelete == 1 )
	{
		vListInitialise( &xTasksWaitingTermination );
     3f8:	8e e3       	ldi	r24, 0x3E	; 62
     3fa:	91 e0       	ldi	r25, 0x01	; 1
     3fc:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskDelete */

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		vListInitialise( &xSuspendedTaskList );
     400:	84 e3       	ldi	r24, 0x34	; 52
     402:	91 e0       	ldi	r25, 0x01	; 1
     404:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskSuspend */

	/* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList
	using list2. */
	pxDelayedTaskList = &xDelayedTaskList1;
     408:	8d e5       	ldi	r24, 0x5D	; 93
     40a:	91 e0       	ldi	r25, 0x01	; 1
     40c:	90 93 53 01 	sts	0x0153, r25	; 0x800153 <pxDelayedTaskList+0x1>
     410:	80 93 52 01 	sts	0x0152, r24	; 0x800152 <pxDelayedTaskList>
	pxOverflowDelayedTaskList = &xDelayedTaskList2;
     414:	84 e5       	ldi	r24, 0x54	; 84
     416:	91 e0       	ldi	r25, 0x01	; 1
     418:	90 93 51 01 	sts	0x0151, r25	; 0x800151 <pxOverflowDelayedTaskList+0x1>
     41c:	80 93 50 01 	sts	0x0150, r24	; 0x800150 <pxOverflowDelayedTaskList>
     420:	10 c0       	rjmp	.+32     	; 0x442 <__LOCK_REGION_LENGTH__+0x42>
		else
		{
			/* If the scheduler is not already running, make this task the
			current task if it is the highest priority task to be created
			so far. */
			if( xSchedulerRunning == pdFALSE )
     422:	80 91 2f 01 	lds	r24, 0x012F	; 0x80012f <xSchedulerRunning>
     426:	81 11       	cpse	r24, r1
     428:	0c c0       	rjmp	.+24     	; 0x442 <__LOCK_REGION_LENGTH__+0x42>
			{
				if( pxCurrentTCB->uxPriority <= pxNewTCB->uxPriority )
     42a:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     42e:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     432:	96 89       	ldd	r25, Z+22	; 0x16
     434:	8e 89       	ldd	r24, Y+22	; 0x16
     436:	89 17       	cp	r24, r25
     438:	20 f0       	brcs	.+8      	; 0x442 <__LOCK_REGION_LENGTH__+0x42>
				{
					pxCurrentTCB = pxNewTCB;
     43a:	d0 93 25 01 	sts	0x0125, r29	; 0x800125 <__data_end+0x1>
     43e:	c0 93 24 01 	sts	0x0124, r28	; 0x800124 <__data_end>
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}

		uxTaskNumber++;
     442:	80 91 2b 01 	lds	r24, 0x012B	; 0x80012b <uxTaskNumber>
     446:	8f 5f       	subi	r24, 0xFF	; 255
     448:	80 93 2b 01 	sts	0x012B, r24	; 0x80012b <uxTaskNumber>
			pxNewTCB->uxTCBNumber = uxTaskNumber;
		}
		#endif /* configUSE_TRACE_FACILITY */
		traceTASK_CREATE( pxNewTCB );

		prvAddTaskToReadyList( pxNewTCB );
     44c:	8e 89       	ldd	r24, Y+22	; 0x16
     44e:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     452:	98 17       	cp	r25, r24
     454:	10 f4       	brcc	.+4      	; 0x45a <__LOCK_REGION_LENGTH__+0x5a>
     456:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     45a:	f9 e0       	ldi	r31, 0x09	; 9
     45c:	8f 9f       	mul	r24, r31
     45e:	c0 01       	movw	r24, r0
     460:	11 24       	eor	r1, r1
     462:	b6 01       	movw	r22, r12
     464:	8a 59       	subi	r24, 0x9A	; 154
     466:	9e 4f       	sbci	r25, 0xFE	; 254
     468:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

		portSETUP_TCB( pxNewTCB );
	}
	taskEXIT_CRITICAL();
     46c:	0f 90       	pop	r0
     46e:	0f be       	out	0x3f, r0	; 63

	if( xSchedulerRunning != pdFALSE )
     470:	80 91 2f 01 	lds	r24, 0x012F	; 0x80012f <xSchedulerRunning>
     474:	88 23       	and	r24, r24
     476:	51 f0       	breq	.+20     	; 0x48c <__LOCK_REGION_LENGTH__+0x8c>
	{
		/* If the created task is of a higher priority than the current task
		then it should run now. */
		if( pxCurrentTCB->uxPriority < pxNewTCB->uxPriority )
     478:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     47c:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     480:	96 89       	ldd	r25, Z+22	; 0x16
     482:	8e 89       	ldd	r24, Y+22	; 0x16
     484:	98 17       	cp	r25, r24
     486:	10 f4       	brcc	.+4      	; 0x48c <__LOCK_REGION_LENGTH__+0x8c>
		{
			taskYIELD_IF_USING_PREEMPTION();
     488:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
			}
			#endif /* configSUPPORT_STATIC_ALLOCATION */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
     48c:	81 e0       	ldi	r24, 0x01	; 1
     48e:	01 c0       	rjmp	.+2      	; 0x492 <__LOCK_REGION_LENGTH__+0x92>
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
     490:	8f ef       	ldi	r24, 0xFF	; 255
		}

		return xReturn;
	}
     492:	df 91       	pop	r29
     494:	cf 91       	pop	r28
     496:	1f 91       	pop	r17
     498:	0f 91       	pop	r16
     49a:	ff 90       	pop	r15
     49c:	ef 90       	pop	r14
     49e:	df 90       	pop	r13
     4a0:	cf 90       	pop	r12
     4a2:	bf 90       	pop	r11
     4a4:	af 90       	pop	r10
     4a6:	9f 90       	pop	r9
     4a8:	8f 90       	pop	r8
     4aa:	7f 90       	pop	r7
     4ac:	6f 90       	pop	r6
     4ae:	5f 90       	pop	r5
     4b0:	4f 90       	pop	r4
     4b2:	3f 90       	pop	r3
     4b4:	08 95       	ret

000004b6 <vTaskDelete>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	void vTaskDelete( TaskHandle_t xTaskToDelete )
	{
     4b6:	0f 93       	push	r16
     4b8:	1f 93       	push	r17
     4ba:	cf 93       	push	r28
     4bc:	df 93       	push	r29
     4be:	ec 01       	movw	r28, r24
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
     4c0:	0f b6       	in	r0, 0x3f	; 63
     4c2:	f8 94       	cli
     4c4:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the calling task that is
			being deleted. */
			pxTCB = prvGetTCBFromHandle( xTaskToDelete );
     4c6:	89 2b       	or	r24, r25
     4c8:	21 f4       	brne	.+8      	; 0x4d2 <vTaskDelete+0x1c>
     4ca:	c0 91 24 01 	lds	r28, 0x0124	; 0x800124 <__data_end>
     4ce:	d0 91 25 01 	lds	r29, 0x0125	; 0x800125 <__data_end+0x1>

			/* Remove task from the ready list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
     4d2:	8e 01       	movw	r16, r28
     4d4:	0e 5f       	subi	r16, 0xFE	; 254
     4d6:	1f 4f       	sbci	r17, 0xFF	; 255
     4d8:	c8 01       	movw	r24, r16
     4da:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
     4de:	8c 89       	ldd	r24, Y+20	; 0x14
     4e0:	9d 89       	ldd	r25, Y+21	; 0x15
     4e2:	89 2b       	or	r24, r25
     4e4:	21 f0       	breq	.+8      	; 0x4ee <vTaskDelete+0x38>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
     4e6:	ce 01       	movw	r24, r28
     4e8:	0c 96       	adiw	r24, 0x0c	; 12
     4ea:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>

			/* Increment the uxTaskNumber also so kernel aware debuggers can
			detect that the task lists need re-generating.  This is done before
			portPRE_TASK_DELETE_HOOK() as in the Windows port that macro will
			not return. */
			uxTaskNumber++;
     4ee:	80 91 2b 01 	lds	r24, 0x012B	; 0x80012b <uxTaskNumber>
     4f2:	8f 5f       	subi	r24, 0xFF	; 255
     4f4:	80 93 2b 01 	sts	0x012B, r24	; 0x80012b <uxTaskNumber>

			if( pxTCB == pxCurrentTCB )
     4f8:	80 91 24 01 	lds	r24, 0x0124	; 0x800124 <__data_end>
     4fc:	90 91 25 01 	lds	r25, 0x0125	; 0x800125 <__data_end+0x1>
     500:	c8 17       	cp	r28, r24
     502:	d9 07       	cpc	r29, r25
     504:	59 f4       	brne	.+22     	; 0x51c <vTaskDelete+0x66>
				/* A task is deleting itself.  This cannot complete within the
				task itself, as a context switch to another task is required.
				Place the task in the termination list.  The idle task will
				check the termination list and free up any memory allocated by
				the scheduler for the TCB and stack of the deleted task. */
				vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );
     506:	b8 01       	movw	r22, r16
     508:	8e e3       	ldi	r24, 0x3E	; 62
     50a:	91 e0       	ldi	r25, 0x01	; 1
     50c:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

				/* Increment the ucTasksDeleted variable so the idle task knows
				there is a task that has been deleted and that it should therefore
				check the xTasksWaitingTermination list. */
				++uxDeletedTasksWaitingCleanUp;
     510:	80 91 3d 01 	lds	r24, 0x013D	; 0x80013d <uxDeletedTasksWaitingCleanUp>
     514:	8f 5f       	subi	r24, 0xFF	; 255
     516:	80 93 3d 01 	sts	0x013D, r24	; 0x80013d <uxDeletedTasksWaitingCleanUp>
     51a:	0e c0       	rjmp	.+28     	; 0x538 <vTaskDelete+0x82>
				required. */
				portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
			}
			else
			{
				--uxCurrentNumberOfTasks;
     51c:	80 91 33 01 	lds	r24, 0x0133	; 0x800133 <uxCurrentNumberOfTasks>
     520:	81 50       	subi	r24, 0x01	; 1
     522:	80 93 33 01 	sts	0x0133, r24	; 0x800133 <uxCurrentNumberOfTasks>

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )
		{
			/* The task can only have been allocated dynamically - free both
			the stack and TCB. */
			vPortFree( pxTCB->pxStack );
     526:	8f 89       	ldd	r24, Y+23	; 0x17
     528:	98 8d       	ldd	r25, Y+24	; 0x18
     52a:	0e 94 28 10 	call	0x2050	; 0x2050 <vPortFree>
			vPortFree( pxTCB );
     52e:	ce 01       	movw	r24, r28
     530:	0e 94 28 10 	call	0x2050	; 0x2050 <vPortFree>
				--uxCurrentNumberOfTasks;
				prvDeleteTCB( pxTCB );

				/* Reset the next expected unblock time in case it referred to
				the task that has just been deleted. */
				prvResetNextTaskUnblockTime();
     534:	0e 94 b5 00 	call	0x16a	; 0x16a <prvResetNextTaskUnblockTime>
			}

			traceTASK_DELETE( pxTCB );
		}
		taskEXIT_CRITICAL();
     538:	0f 90       	pop	r0
     53a:	0f be       	out	0x3f, r0	; 63

		/* Force a reschedule if it is the currently running task that has just
		been deleted. */
		if( xSchedulerRunning != pdFALSE )
     53c:	80 91 2f 01 	lds	r24, 0x012F	; 0x80012f <xSchedulerRunning>
     540:	88 23       	and	r24, r24
     542:	49 f0       	breq	.+18     	; 0x556 <vTaskDelete+0xa0>
		{
			if( pxTCB == pxCurrentTCB )
     544:	80 91 24 01 	lds	r24, 0x0124	; 0x800124 <__data_end>
     548:	90 91 25 01 	lds	r25, 0x0125	; 0x800125 <__data_end+0x1>
     54c:	c8 17       	cp	r28, r24
     54e:	d9 07       	cpc	r29, r25
     550:	11 f4       	brne	.+4      	; 0x556 <vTaskDelete+0xa0>
			{
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
     552:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
     556:	df 91       	pop	r29
     558:	cf 91       	pop	r28
     55a:	1f 91       	pop	r17
     55c:	0f 91       	pop	r16
     55e:	08 95       	ret

00000560 <vTaskResume>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskResume( TaskHandle_t xTaskToResume )
	{
     560:	0f 93       	push	r16
     562:	1f 93       	push	r17
     564:	cf 93       	push	r28
     566:	df 93       	push	r29
		/* It does not make sense to resume the calling task. */
		configASSERT( xTaskToResume );

		/* The parameter cannot be NULL as it is impossible to resume the
		currently executing task. */
		if( ( pxTCB != pxCurrentTCB ) && ( pxTCB != NULL ) )
     568:	20 91 24 01 	lds	r18, 0x0124	; 0x800124 <__data_end>
     56c:	30 91 25 01 	lds	r19, 0x0125	; 0x800125 <__data_end+0x1>
     570:	82 17       	cp	r24, r18
     572:	93 07       	cpc	r25, r19
     574:	b9 f1       	breq	.+110    	; 0x5e4 <vTaskResume+0x84>
     576:	00 97       	sbiw	r24, 0x00	; 0
     578:	a9 f1       	breq	.+106    	; 0x5e4 <vTaskResume+0x84>
		{
			taskENTER_CRITICAL();
     57a:	0f b6       	in	r0, 0x3f	; 63
     57c:	f8 94       	cli
     57e:	0f 92       	push	r0

		/* It does not make sense to check if the calling task is suspended. */
		configASSERT( xTask );

		/* Is the task being resumed actually in the suspended list? */
		if( listIS_CONTAINED_WITHIN( &xSuspendedTaskList, &( pxTCB->xStateListItem ) ) != pdFALSE )
     580:	fc 01       	movw	r30, r24
     582:	22 85       	ldd	r18, Z+10	; 0x0a
     584:	33 85       	ldd	r19, Z+11	; 0x0b
     586:	24 53       	subi	r18, 0x34	; 52
     588:	31 40       	sbci	r19, 0x01	; 1
     58a:	51 f5       	brne	.+84     	; 0x5e0 <vTaskResume+0x80>
		{
			/* Has the task already been resumed from within an ISR? */
			if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) == pdFALSE )
     58c:	fc 01       	movw	r30, r24
     58e:	24 89       	ldd	r18, Z+20	; 0x14
     590:	35 89       	ldd	r19, Z+21	; 0x15
     592:	f1 e0       	ldi	r31, 0x01	; 1
     594:	27 34       	cpi	r18, 0x47	; 71
     596:	3f 07       	cpc	r19, r31
     598:	19 f1       	breq	.+70     	; 0x5e0 <vTaskResume+0x80>
			{
				/* Is it in the suspended list because it is in the	Suspended
				state, or because is is blocked with no timeout? */
				if( listIS_CONTAINED_WITHIN( NULL, &( pxTCB->xEventListItem ) ) != pdFALSE ) /*lint !e961.  The cast is only redundant when NULL is used. */
     59a:	23 2b       	or	r18, r19
     59c:	09 f5       	brne	.+66     	; 0x5e0 <vTaskResume+0x80>
     59e:	ec 01       	movw	r28, r24
				{
					traceTASK_RESUME( pxTCB );

					/* The ready list can be accessed even if the scheduler is
					suspended because this is inside a critical section. */
					( void ) uxListRemove(  &( pxTCB->xStateListItem ) );
     5a0:	8c 01       	movw	r16, r24
     5a2:	0e 5f       	subi	r16, 0xFE	; 254
     5a4:	1f 4f       	sbci	r17, 0xFF	; 255
     5a6:	c8 01       	movw	r24, r16
     5a8:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
     5ac:	8e 89       	ldd	r24, Y+22	; 0x16
     5ae:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     5b2:	98 17       	cp	r25, r24
     5b4:	10 f4       	brcc	.+4      	; 0x5ba <vTaskResume+0x5a>
     5b6:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     5ba:	29 e0       	ldi	r18, 0x09	; 9
     5bc:	82 9f       	mul	r24, r18
     5be:	c0 01       	movw	r24, r0
     5c0:	11 24       	eor	r1, r1
     5c2:	b8 01       	movw	r22, r16
     5c4:	8a 59       	subi	r24, 0x9A	; 154
     5c6:	9e 4f       	sbci	r25, 0xFE	; 254
     5c8:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

					/* A higher priority task may have just been resumed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
     5cc:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     5d0:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     5d4:	9e 89       	ldd	r25, Y+22	; 0x16
     5d6:	86 89       	ldd	r24, Z+22	; 0x16
     5d8:	98 17       	cp	r25, r24
     5da:	10 f0       	brcs	.+4      	; 0x5e0 <vTaskResume+0x80>
					{
						/* This yield may not cause the task just resumed to run,
						but will leave the lists in the correct state for the
						next yield. */
						taskYIELD_IF_USING_PREEMPTION();
     5dc:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     5e0:	0f 90       	pop	r0
     5e2:	0f be       	out	0x3f, r0	; 63
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
     5e4:	df 91       	pop	r29
     5e6:	cf 91       	pop	r28
     5e8:	1f 91       	pop	r17
     5ea:	0f 91       	pop	r16
     5ec:	08 95       	ret

000005ee <xTaskResumeFromISR>:
/*-----------------------------------------------------------*/

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
     5ee:	ef 92       	push	r14
     5f0:	ff 92       	push	r15
     5f2:	1f 93       	push	r17
     5f4:	cf 93       	push	r28
     5f6:	df 93       	push	r29
     5f8:	ec 01       	movw	r28, r24

		/* It does not make sense to check if the calling task is suspended. */
		configASSERT( xTask );

		/* Is the task being resumed actually in the suspended list? */
		if( listIS_CONTAINED_WITHIN( &xSuspendedTaskList, &( pxTCB->xStateListItem ) ) != pdFALSE )
     5fa:	8a 85       	ldd	r24, Y+10	; 0x0a
     5fc:	9b 85       	ldd	r25, Y+11	; 0x0b
     5fe:	84 53       	subi	r24, 0x34	; 52
     600:	91 40       	sbci	r25, 0x01	; 1
     602:	99 f4       	brne	.+38     	; 0x62a <xTaskResumeFromISR+0x3c>
		{
			/* Has the task already been resumed from within an ISR? */
			if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) == pdFALSE )
     604:	8c 89       	ldd	r24, Y+20	; 0x14
     606:	9d 89       	ldd	r25, Y+21	; 0x15
     608:	21 e0       	ldi	r18, 0x01	; 1
     60a:	87 34       	cpi	r24, 0x47	; 71
     60c:	92 07       	cpc	r25, r18
     60e:	69 f0       	breq	.+26     	; 0x62a <xTaskResumeFromISR+0x3c>
			{
				/* Is it in the suspended list because it is in the	Suspended
				state, or because is is blocked with no timeout? */
				if( listIS_CONTAINED_WITHIN( NULL, &( pxTCB->xEventListItem ) ) != pdFALSE ) /*lint !e961.  The cast is only redundant when NULL is used. */
     610:	89 2b       	or	r24, r25
     612:	59 f4       	brne	.+22     	; 0x62a <xTaskResumeFromISR+0x3c>
			if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
			{
				traceTASK_RESUME_FROM_ISR( pxTCB );

				/* Check the ready lists can be accessed. */
				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
     614:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
     618:	88 23       	and	r24, r24
     61a:	49 f0       	breq	.+18     	; 0x62e <xTaskResumeFromISR+0x40>
				else
				{
					/* The delayed or ready lists cannot be accessed so the task
					is held in the pending ready list until the scheduler is
					unsuspended. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
     61c:	be 01       	movw	r22, r28
     61e:	64 5f       	subi	r22, 0xF4	; 244
     620:	7f 4f       	sbci	r23, 0xFF	; 255
     622:	87 e4       	ldi	r24, 0x47	; 71
     624:	91 e0       	ldi	r25, 0x01	; 1
     626:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
     62a:	10 e0       	ldi	r17, 0x00	; 0
				mtCOVERAGE_TEST_MARKER();
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xYieldRequired;
     62c:	21 c0       	rjmp	.+66     	; 0x670 <xTaskResumeFromISR+0x82>
				/* Check the ready lists can be accessed. */
				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
				{
					/* Ready lists can be accessed so move the task from the
					suspended list to the ready list directly. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
     62e:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     632:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
     636:	11 e0       	ldi	r17, 0x01	; 1
     638:	9e 89       	ldd	r25, Y+22	; 0x16
     63a:	86 89       	ldd	r24, Z+22	; 0x16
     63c:	98 17       	cp	r25, r24
     63e:	08 f4       	brcc	.+2      	; 0x642 <xTaskResumeFromISR+0x54>
     640:	10 e0       	ldi	r17, 0x00	; 0
					else
					{
						mtCOVERAGE_TEST_MARKER();
					}

					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
     642:	7e 01       	movw	r14, r28
     644:	82 e0       	ldi	r24, 0x02	; 2
     646:	e8 0e       	add	r14, r24
     648:	f1 1c       	adc	r15, r1
     64a:	c7 01       	movw	r24, r14
     64c:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
     650:	8e 89       	ldd	r24, Y+22	; 0x16
     652:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     656:	98 17       	cp	r25, r24
     658:	10 f4       	brcc	.+4      	; 0x65e <xTaskResumeFromISR+0x70>
     65a:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     65e:	29 e0       	ldi	r18, 0x09	; 9
     660:	82 9f       	mul	r24, r18
     662:	c0 01       	movw	r24, r0
     664:	11 24       	eor	r1, r1
     666:	b7 01       	movw	r22, r14
     668:	8a 59       	subi	r24, 0x9A	; 154
     66a:	9e 4f       	sbci	r25, 0xFE	; 254
     66c:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xYieldRequired;
	}
     670:	81 2f       	mov	r24, r17
     672:	df 91       	pop	r29
     674:	cf 91       	pop	r28
     676:	1f 91       	pop	r17
     678:	ff 90       	pop	r15
     67a:	ef 90       	pop	r14
     67c:	08 95       	ret

0000067e <vTaskStartScheduler>:

#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
/*-----------------------------------------------------------*/

void vTaskStartScheduler( void )
{
     67e:	ef 92       	push	r14
     680:	ff 92       	push	r15
     682:	0f 93       	push	r16
		}
	}
	#else
	{
		/* The Idle task is being created using dynamically allocated RAM. */
		xReturn = xTaskCreate(	prvIdleTask,
     684:	87 e2       	ldi	r24, 0x27	; 39
     686:	e8 2e       	mov	r14, r24
     688:	81 e0       	ldi	r24, 0x01	; 1
     68a:	f8 2e       	mov	r15, r24
     68c:	00 e0       	ldi	r16, 0x00	; 0
     68e:	20 e0       	ldi	r18, 0x00	; 0
     690:	30 e0       	ldi	r19, 0x00	; 0
     692:	45 e5       	ldi	r20, 0x55	; 85
     694:	50 e0       	ldi	r21, 0x00	; 0
     696:	6f e1       	ldi	r22, 0x1F	; 31
     698:	71 e0       	ldi	r23, 0x01	; 1
     69a:	8c e2       	ldi	r24, 0x2C	; 44
     69c:	91 e0       	ldi	r25, 0x01	; 1
     69e:	0e 94 5a 01 	call	0x2b4	; 0x2b4 <xTaskCreate>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	#endif /* configUSE_TIMERS */

	if( xReturn == pdPASS )
     6a2:	81 30       	cpi	r24, 0x01	; 1
     6a4:	91 f4       	brne	.+36     	; 0x6ca <vTaskStartScheduler+0x4c>
		/* Interrupts are turned off here, to ensure a tick does not occur
		before or during the call to xPortStartScheduler().  The stacks of
		the created tasks contain a status word with interrupts switched on
		so interrupts will automatically get re-enabled when the first task
		starts to run. */
		portDISABLE_INTERRUPTS();
     6a6:	f8 94       	cli
			structure specific to the task that will run first. */
			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
		}
		#endif /* configUSE_NEWLIB_REENTRANT */

		xNextTaskUnblockTime = portMAX_DELAY;
     6a8:	2f ef       	ldi	r18, 0xFF	; 255
     6aa:	3f ef       	ldi	r19, 0xFF	; 255
     6ac:	30 93 2a 01 	sts	0x012A, r19	; 0x80012a <xNextTaskUnblockTime+0x1>
     6b0:	20 93 29 01 	sts	0x0129, r18	; 0x800129 <xNextTaskUnblockTime>
		xSchedulerRunning = pdTRUE;
     6b4:	80 93 2f 01 	sts	0x012F, r24	; 0x80012f <xSchedulerRunning>
		xTickCount = ( TickType_t ) configINITIAL_TICK_COUNT;
     6b8:	10 92 32 01 	sts	0x0132, r1	; 0x800132 <xTickCount+0x1>
     6bc:	10 92 31 01 	sts	0x0131, r1	; 0x800131 <xTickCount>
	}

	/* Prevent compiler warnings if INCLUDE_xTaskGetIdleTaskHandle is set to 0,
	meaning xIdleTaskHandle is not used anywhere else. */
	( void ) xIdleTaskHandle;
}
     6c0:	0f 91       	pop	r16
     6c2:	ff 90       	pop	r15
     6c4:	ef 90       	pop	r14

		traceTASK_SWITCHED_IN();

		/* Setting up the timer tick is hardware specific and thus in the
		portable interface. */
		if( xPortStartScheduler() != pdFALSE )
     6c6:	0c 94 a3 10 	jmp	0x2146	; 0x2146 <xPortStartScheduler>
	}

	/* Prevent compiler warnings if INCLUDE_xTaskGetIdleTaskHandle is set to 0,
	meaning xIdleTaskHandle is not used anywhere else. */
	( void ) xIdleTaskHandle;
}
     6ca:	0f 91       	pop	r16
     6cc:	ff 90       	pop	r15
     6ce:	ef 90       	pop	r14
     6d0:	08 95       	ret

000006d2 <vTaskEndScheduler>:
void vTaskEndScheduler( void )
{
	/* Stop the scheduler interrupts and call the portable scheduler end
	routine so the original ISRs can be restored if necessary.  The port
	layer must ensure interrupts enable	bit is left in the correct state. */
	portDISABLE_INTERRUPTS();
     6d2:	f8 94       	cli
	xSchedulerRunning = pdFALSE;
     6d4:	10 92 2f 01 	sts	0x012F, r1	; 0x80012f <xSchedulerRunning>
	vPortEndScheduler();
     6d8:	0c 94 e3 10 	jmp	0x21c6	; 0x21c6 <vPortEndScheduler>

000006dc <vTaskSuspendAll>:
{
	/* A critical section is not required as the variable is of type
	BaseType_t.  Please read Richard Barry's reply in the following link to a
	post in the FreeRTOS support forum before reporting this as a bug! -
	http://goo.gl/wu4acr */
	++uxSchedulerSuspended;
     6dc:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
     6e0:	8f 5f       	subi	r24, 0xFF	; 255
     6e2:	80 93 26 01 	sts	0x0126, r24	; 0x800126 <uxSchedulerSuspended>
     6e6:	08 95       	ret

000006e8 <xTaskGetTickCount>:
TickType_t xTaskGetTickCount( void )
{
TickType_t xTicks;

	/* Critical section required if running on a 16 bit processor. */
	portTICK_TYPE_ENTER_CRITICAL();
     6e8:	0f b6       	in	r0, 0x3f	; 63
     6ea:	f8 94       	cli
     6ec:	0f 92       	push	r0
	{
		xTicks = xTickCount;
     6ee:	80 91 31 01 	lds	r24, 0x0131	; 0x800131 <xTickCount>
     6f2:	90 91 32 01 	lds	r25, 0x0132	; 0x800132 <xTickCount+0x1>
	}
	portTICK_TYPE_EXIT_CRITICAL();
     6f6:	0f 90       	pop	r0
     6f8:	0f be       	out	0x3f, r0	; 63

	return xTicks;
}
     6fa:	08 95       	ret

000006fc <xTaskGetTickCountFromISR>:
	link: https://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();
	{
		xReturn = xTickCount;
     6fc:	80 91 31 01 	lds	r24, 0x0131	; 0x800131 <xTickCount>
     700:	90 91 32 01 	lds	r25, 0x0132	; 0x800132 <xTickCount+0x1>
	}
	portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     704:	08 95       	ret

00000706 <uxTaskGetNumberOfTasks>:

UBaseType_t uxTaskGetNumberOfTasks( void )
{
	/* A critical section is not required because the variables are of type
	BaseType_t. */
	return uxCurrentNumberOfTasks;
     706:	80 91 33 01 	lds	r24, 0x0133	; 0x800133 <uxCurrentNumberOfTasks>
}
     70a:	08 95       	ret

0000070c <pcTaskGetName>:
{
TCB_t *pxTCB;

	/* If null is passed in here then the name of the calling task is being
	queried. */
	pxTCB = prvGetTCBFromHandle( xTaskToQuery );
     70c:	00 97       	sbiw	r24, 0x00	; 0
     70e:	21 f4       	brne	.+8      	; 0x718 <pcTaskGetName+0xc>
     710:	80 91 24 01 	lds	r24, 0x0124	; 0x800124 <__data_end>
     714:	90 91 25 01 	lds	r25, 0x0125	; 0x800125 <__data_end+0x1>
	configASSERT( pxTCB );
	return &( pxTCB->pcTaskName[ 0 ] );
}
     718:	49 96       	adiw	r24, 0x19	; 25
     71a:	08 95       	ret

0000071c <xTaskIncrementTick>:

#endif /* INCLUDE_xTaskAbortDelay */
/*----------------------------------------------------------*/

BaseType_t xTaskIncrementTick( void )
{
     71c:	cf 92       	push	r12
     71e:	df 92       	push	r13
     720:	ef 92       	push	r14
     722:	ff 92       	push	r15
     724:	0f 93       	push	r16
     726:	1f 93       	push	r17
     728:	cf 93       	push	r28
     72a:	df 93       	push	r29

	/* Called by the portable layer each time a tick interrupt occurs.
	Increments the tick then checks to see if the new tick value will cause any
	tasks to be unblocked. */
	traceTASK_INCREMENT_TICK( xTickCount );
	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
     72c:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
     730:	81 11       	cpse	r24, r1
     732:	8c c0       	rjmp	.+280    	; 0x84c <xTaskIncrementTick+0x130>
	{
		/* Minor optimisation.  The tick count cannot change in this
		block. */
		const TickType_t xConstTickCount = xTickCount + ( TickType_t ) 1;
     734:	00 91 31 01 	lds	r16, 0x0131	; 0x800131 <xTickCount>
     738:	10 91 32 01 	lds	r17, 0x0132	; 0x800132 <xTickCount+0x1>
     73c:	0f 5f       	subi	r16, 0xFF	; 255
     73e:	1f 4f       	sbci	r17, 0xFF	; 255

		/* Increment the RTOS tick, switching the delayed and overflowed
		delayed lists if it wraps to 0. */
		xTickCount = xConstTickCount;
     740:	10 93 32 01 	sts	0x0132, r17	; 0x800132 <xTickCount+0x1>
     744:	00 93 31 01 	sts	0x0131, r16	; 0x800131 <xTickCount>

		if( xConstTickCount == ( TickType_t ) 0U ) /*lint !e774 'if' does not always evaluate to false as it is looking for an overflow. */
     748:	01 15       	cp	r16, r1
     74a:	11 05       	cpc	r17, r1
     74c:	b9 f4       	brne	.+46     	; 0x77c <xTaskIncrementTick+0x60>
		{
			taskSWITCH_DELAYED_LISTS();
     74e:	80 91 52 01 	lds	r24, 0x0152	; 0x800152 <pxDelayedTaskList>
     752:	90 91 53 01 	lds	r25, 0x0153	; 0x800153 <pxDelayedTaskList+0x1>
     756:	20 91 50 01 	lds	r18, 0x0150	; 0x800150 <pxOverflowDelayedTaskList>
     75a:	30 91 51 01 	lds	r19, 0x0151	; 0x800151 <pxOverflowDelayedTaskList+0x1>
     75e:	30 93 53 01 	sts	0x0153, r19	; 0x800153 <pxDelayedTaskList+0x1>
     762:	20 93 52 01 	sts	0x0152, r18	; 0x800152 <pxDelayedTaskList>
     766:	90 93 51 01 	sts	0x0151, r25	; 0x800151 <pxOverflowDelayedTaskList+0x1>
     76a:	80 93 50 01 	sts	0x0150, r24	; 0x800150 <pxOverflowDelayedTaskList>
     76e:	80 91 2c 01 	lds	r24, 0x012C	; 0x80012c <xNumOfOverflows>
     772:	8f 5f       	subi	r24, 0xFF	; 255
     774:	80 93 2c 01 	sts	0x012C, r24	; 0x80012c <xNumOfOverflows>
     778:	0e 94 b5 00 	call	0x16a	; 0x16a <prvResetNextTaskUnblockTime>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
     77c:	80 91 29 01 	lds	r24, 0x0129	; 0x800129 <xNextTaskUnblockTime>
     780:	90 91 2a 01 	lds	r25, 0x012A	; 0x80012a <xNextTaskUnblockTime+0x1>
     784:	c0 e0       	ldi	r28, 0x00	; 0
     786:	08 17       	cp	r16, r24
     788:	19 07       	cpc	r17, r25
     78a:	08 f4       	brcc	.+2      	; 0x78e <xTaskIncrementTick+0x72>
     78c:	4f c0       	rjmp	.+158    	; 0x82c <xTaskIncrementTick+0x110>
						mtCOVERAGE_TEST_MARKER();
					}

					/* Place the unblocked task into the appropriate ready
					list. */
					prvAddTaskToReadyList( pxTCB );
     78e:	d9 e0       	ldi	r29, 0x09	; 9
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
		{
			for( ;; )
			{
				if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
     790:	e0 91 52 01 	lds	r30, 0x0152	; 0x800152 <pxDelayedTaskList>
     794:	f0 91 53 01 	lds	r31, 0x0153	; 0x800153 <pxDelayedTaskList+0x1>
     798:	80 81       	ld	r24, Z
     79a:	81 11       	cpse	r24, r1
     79c:	03 c0       	rjmp	.+6      	; 0x7a4 <xTaskIncrementTick+0x88>
					/* The delayed list is empty.  Set xNextTaskUnblockTime
					to the maximum possible value so it is extremely
					unlikely that the
					if( xTickCount >= xNextTaskUnblockTime ) test will pass
					next time through. */
					xNextTaskUnblockTime = portMAX_DELAY; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     79e:	8f ef       	ldi	r24, 0xFF	; 255
     7a0:	9f ef       	ldi	r25, 0xFF	; 255
     7a2:	11 c0       	rjmp	.+34     	; 0x7c6 <xTaskIncrementTick+0xaa>
				{
					/* The delayed list is not empty, get the value of the
					item at the head of the delayed list.  This is the time
					at which the task at the head of the delayed list must
					be removed from the Blocked state. */
					pxTCB = listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
     7a4:	e0 91 52 01 	lds	r30, 0x0152	; 0x800152 <pxDelayedTaskList>
     7a8:	f0 91 53 01 	lds	r31, 0x0153	; 0x800153 <pxDelayedTaskList+0x1>
     7ac:	05 80       	ldd	r0, Z+5	; 0x05
     7ae:	f6 81       	ldd	r31, Z+6	; 0x06
     7b0:	e0 2d       	mov	r30, r0
     7b2:	e6 80       	ldd	r14, Z+6	; 0x06
     7b4:	f7 80       	ldd	r15, Z+7	; 0x07
					xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xStateListItem ) );
     7b6:	d7 01       	movw	r26, r14
     7b8:	12 96       	adiw	r26, 0x02	; 2
     7ba:	8d 91       	ld	r24, X+
     7bc:	9c 91       	ld	r25, X
     7be:	13 97       	sbiw	r26, 0x03	; 3

					if( xConstTickCount < xItemValue )
     7c0:	08 17       	cp	r16, r24
     7c2:	19 07       	cpc	r17, r25
     7c4:	28 f4       	brcc	.+10     	; 0x7d0 <xTaskIncrementTick+0xb4>
						/* It is not time to unblock this item yet, but the
						item value is the time at which the task at the head
						of the blocked list must be removed from the Blocked
						state -	so record the item value in
						xNextTaskUnblockTime. */
						xNextTaskUnblockTime = xItemValue;
     7c6:	90 93 2a 01 	sts	0x012A, r25	; 0x80012a <xNextTaskUnblockTime+0x1>
     7ca:	80 93 29 01 	sts	0x0129, r24	; 0x800129 <xNextTaskUnblockTime>
						break; /*lint !e9011 Code structure here is deedmed easier to understand with multiple breaks. */
     7ce:	2e c0       	rjmp	.+92     	; 0x82c <xTaskIncrementTick+0x110>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* It is time to remove the item from the Blocked state. */
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
     7d0:	67 01       	movw	r12, r14
     7d2:	b2 e0       	ldi	r27, 0x02	; 2
     7d4:	cb 0e       	add	r12, r27
     7d6:	d1 1c       	adc	r13, r1
     7d8:	c6 01       	movw	r24, r12
     7da:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>

					/* Is the task waiting on an event also?  If so remove
					it from the event list. */
					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
     7de:	f7 01       	movw	r30, r14
     7e0:	84 89       	ldd	r24, Z+20	; 0x14
     7e2:	95 89       	ldd	r25, Z+21	; 0x15
     7e4:	89 2b       	or	r24, r25
     7e6:	21 f0       	breq	.+8      	; 0x7f0 <xTaskIncrementTick+0xd4>
					{
						( void ) uxListRemove( &( pxTCB->xEventListItem ) );
     7e8:	c7 01       	movw	r24, r14
     7ea:	0c 96       	adiw	r24, 0x0c	; 12
     7ec:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
						mtCOVERAGE_TEST_MARKER();
					}

					/* Place the unblocked task into the appropriate ready
					list. */
					prvAddTaskToReadyList( pxTCB );
     7f0:	d7 01       	movw	r26, r14
     7f2:	56 96       	adiw	r26, 0x16	; 22
     7f4:	8c 91       	ld	r24, X
     7f6:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     7fa:	98 17       	cp	r25, r24
     7fc:	10 f4       	brcc	.+4      	; 0x802 <xTaskIncrementTick+0xe6>
     7fe:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     802:	d8 9f       	mul	r29, r24
     804:	c0 01       	movw	r24, r0
     806:	11 24       	eor	r1, r1
     808:	b6 01       	movw	r22, r12
     80a:	8a 59       	subi	r24, 0x9A	; 154
     80c:	9e 4f       	sbci	r25, 0xFE	; 254
     80e:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
					{
						/* Preemption is on, but a context switch should
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
     812:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     816:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     81a:	d7 01       	movw	r26, r14
     81c:	56 96       	adiw	r26, 0x16	; 22
     81e:	9c 91       	ld	r25, X
     820:	86 89       	ldd	r24, Z+22	; 0x16
     822:	98 17       	cp	r25, r24
     824:	08 f4       	brcc	.+2      	; 0x828 <xTaskIncrementTick+0x10c>
     826:	b4 cf       	rjmp	.-152    	; 0x790 <xTaskIncrementTick+0x74>
						{
							xSwitchRequired = pdTRUE;
     828:	c1 e0       	ldi	r28, 0x01	; 1
     82a:	b2 cf       	rjmp	.-156    	; 0x790 <xTaskIncrementTick+0x74>
		/* Tasks of equal priority to the currently running task will share
		processing time (time slice) if preemption is on, and the application
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
     82c:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     830:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     834:	e6 89       	ldd	r30, Z+22	; 0x16
     836:	b9 e0       	ldi	r27, 0x09	; 9
     838:	eb 9f       	mul	r30, r27
     83a:	f0 01       	movw	r30, r0
     83c:	11 24       	eor	r1, r1
     83e:	ea 59       	subi	r30, 0x9A	; 154
     840:	fe 4f       	sbci	r31, 0xFE	; 254
     842:	80 81       	ld	r24, Z
     844:	82 30       	cpi	r24, 0x02	; 2
     846:	40 f0       	brcs	.+16     	; 0x858 <xTaskIncrementTick+0x13c>
			{
				xSwitchRequired = pdTRUE;
     848:	c1 e0       	ldi	r28, 0x01	; 1
     84a:	06 c0       	rjmp	.+12     	; 0x858 <xTaskIncrementTick+0x13c>
		}
		#endif /* configUSE_TICK_HOOK */
	}
	else
	{
		++uxPendedTicks;
     84c:	80 91 2e 01 	lds	r24, 0x012E	; 0x80012e <uxPendedTicks>
     850:	8f 5f       	subi	r24, 0xFF	; 255
     852:	80 93 2e 01 	sts	0x012E, r24	; 0x80012e <uxPendedTicks>

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
     856:	c0 e0       	ldi	r28, 0x00	; 0
		#endif
	}

	#if ( configUSE_PREEMPTION == 1 )
	{
		if( xYieldPending != pdFALSE )
     858:	80 91 2d 01 	lds	r24, 0x012D	; 0x80012d <xYieldPending>
     85c:	81 11       	cpse	r24, r1
		{
			xSwitchRequired = pdTRUE;
     85e:	c1 e0       	ldi	r28, 0x01	; 1
		}
	}
	#endif /* configUSE_PREEMPTION */

	return xSwitchRequired;
}
     860:	8c 2f       	mov	r24, r28
     862:	df 91       	pop	r29
     864:	cf 91       	pop	r28
     866:	1f 91       	pop	r17
     868:	0f 91       	pop	r16
     86a:	ff 90       	pop	r15
     86c:	ef 90       	pop	r14
     86e:	df 90       	pop	r13
     870:	cf 90       	pop	r12
     872:	08 95       	ret

00000874 <xTaskResumeAll>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
     874:	ef 92       	push	r14
     876:	ff 92       	push	r15
     878:	0f 93       	push	r16
     87a:	1f 93       	push	r17
     87c:	cf 93       	push	r28
     87e:	df 93       	push	r29
	/* It is possible that an ISR caused a task to be removed from an event
	list while the scheduler was suspended.  If this was the case then the
	removed task will have been added to the xPendingReadyList.  Once the
	scheduler has been resumed it is safe to move all the pending ready
	tasks from this list into their appropriate ready list. */
	taskENTER_CRITICAL();
     880:	0f b6       	in	r0, 0x3f	; 63
     882:	f8 94       	cli
     884:	0f 92       	push	r0
	{
		--uxSchedulerSuspended;
     886:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
     88a:	81 50       	subi	r24, 0x01	; 1
     88c:	80 93 26 01 	sts	0x0126, r24	; 0x800126 <uxSchedulerSuspended>

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
     890:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
     894:	88 23       	and	r24, r24
     896:	11 f0       	breq	.+4      	; 0x89c <xTaskResumeAll+0x28>
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
TCB_t *pxTCB = NULL;
BaseType_t xAlreadyYielded = pdFALSE;
     898:	80 e0       	ldi	r24, 0x00	; 0
     89a:	52 c0       	rjmp	.+164    	; 0x940 <__stack+0x41>
	{
		--uxSchedulerSuspended;

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
     89c:	80 91 33 01 	lds	r24, 0x0133	; 0x800133 <uxCurrentNumberOfTasks>
     8a0:	88 23       	and	r24, r24
     8a2:	d1 f3       	breq	.-12     	; 0x898 <xTaskResumeAll+0x24>
     8a4:	c0 e0       	ldi	r28, 0x00	; 0
     8a6:	d0 e0       	ldi	r29, 0x00	; 0
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
				{
					pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
					prvAddTaskToReadyList( pxTCB );
     8a8:	89 e0       	ldi	r24, 0x09	; 9
     8aa:	f8 2e       	mov	r15, r24

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
					{
						xYieldPending = pdTRUE;
     8ac:	ee 24       	eor	r14, r14
     8ae:	e3 94       	inc	r14
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
     8b0:	80 91 47 01 	lds	r24, 0x0147	; 0x800147 <xPendingReadyList>
     8b4:	88 23       	and	r24, r24
     8b6:	51 f1       	breq	.+84     	; 0x90c <__stack+0xd>
				{
					pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
     8b8:	e0 91 4c 01 	lds	r30, 0x014C	; 0x80014c <xPendingReadyList+0x5>
     8bc:	f0 91 4d 01 	lds	r31, 0x014D	; 0x80014d <xPendingReadyList+0x6>
     8c0:	c6 81       	ldd	r28, Z+6	; 0x06
     8c2:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
     8c4:	ce 01       	movw	r24, r28
     8c6:	0c 96       	adiw	r24, 0x0c	; 12
     8c8:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
     8cc:	8e 01       	movw	r16, r28
     8ce:	0e 5f       	subi	r16, 0xFE	; 254
     8d0:	1f 4f       	sbci	r17, 0xFF	; 255
     8d2:	c8 01       	movw	r24, r16
     8d4:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
     8d8:	8e 89       	ldd	r24, Y+22	; 0x16
     8da:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     8de:	98 17       	cp	r25, r24
     8e0:	10 f4       	brcc	.+4      	; 0x8e6 <xTaskResumeAll+0x72>
     8e2:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     8e6:	f8 9e       	mul	r15, r24
     8e8:	c0 01       	movw	r24, r0
     8ea:	11 24       	eor	r1, r1
     8ec:	b8 01       	movw	r22, r16
     8ee:	8a 59       	subi	r24, 0x9A	; 154
     8f0:	9e 4f       	sbci	r25, 0xFE	; 254
     8f2:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
     8f6:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     8fa:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     8fe:	9e 89       	ldd	r25, Y+22	; 0x16
     900:	86 89       	ldd	r24, Z+22	; 0x16
     902:	98 17       	cp	r25, r24
     904:	a8 f2       	brcs	.-86     	; 0x8b0 <xTaskResumeAll+0x3c>
					{
						xYieldPending = pdTRUE;
     906:	e0 92 2d 01 	sts	0x012D, r14	; 0x80012d <xYieldPending>
     90a:	d2 cf       	rjmp	.-92     	; 0x8b0 <xTaskResumeAll+0x3c>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( pxTCB != NULL )
     90c:	cd 2b       	or	r28, r29
     90e:	11 f0       	breq	.+4      	; 0x914 <__stack+0x15>
					which may have prevented the next unblock time from being
					re-calculated, in which case re-calculate it now.  Mainly
					important for low power tickless implementations, where
					this can prevent an unnecessary exit from low power
					state. */
					prvResetNextTaskUnblockTime();
     910:	0e 94 b5 00 	call	0x16a	; 0x16a <prvResetNextTaskUnblockTime>
				/* If any ticks occurred while the scheduler was suspended then
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				{
					UBaseType_t uxPendedCounts = uxPendedTicks; /* Non-volatile copy. */
     914:	c0 91 2e 01 	lds	r28, 0x012E	; 0x80012e <uxPendedTicks>

					if( uxPendedCounts > ( UBaseType_t ) 0U )
     918:	cc 23       	and	r28, r28
     91a:	51 f0       	breq	.+20     	; 0x930 <__stack+0x31>
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
							{
								xYieldPending = pdTRUE;
     91c:	d1 e0       	ldi	r29, 0x01	; 1

					if( uxPendedCounts > ( UBaseType_t ) 0U )
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
     91e:	0e 94 8e 03 	call	0x71c	; 0x71c <xTaskIncrementTick>
     922:	81 11       	cpse	r24, r1
							{
								xYieldPending = pdTRUE;
     924:	d0 93 2d 01 	sts	0x012D, r29	; 0x80012d <xYieldPending>
							}
							else
							{
								mtCOVERAGE_TEST_MARKER();
							}
							--uxPendedCounts;
     928:	c1 50       	subi	r28, 0x01	; 1
						} while( uxPendedCounts > ( UBaseType_t ) 0U );
     92a:	c9 f7       	brne	.-14     	; 0x91e <__stack+0x1f>

						uxPendedTicks = 0;
     92c:	10 92 2e 01 	sts	0x012E, r1	; 0x80012e <uxPendedTicks>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( xYieldPending != pdFALSE )
     930:	80 91 2d 01 	lds	r24, 0x012D	; 0x80012d <xYieldPending>
     934:	88 23       	and	r24, r24
     936:	09 f4       	brne	.+2      	; 0x93a <__stack+0x3b>
     938:	af cf       	rjmp	.-162    	; 0x898 <xTaskResumeAll+0x24>
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
					}
					#endif
					taskYIELD_IF_USING_PREEMPTION();
     93a:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>

				if( xYieldPending != pdFALSE )
				{
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
     93e:	81 e0       	ldi	r24, 0x01	; 1
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
	taskEXIT_CRITICAL();
     940:	0f 90       	pop	r0
     942:	0f be       	out	0x3f, r0	; 63

	return xAlreadyYielded;
}
     944:	df 91       	pop	r29
     946:	cf 91       	pop	r28
     948:	1f 91       	pop	r17
     94a:	0f 91       	pop	r16
     94c:	ff 90       	pop	r15
     94e:	ef 90       	pop	r14
     950:	08 95       	ret

00000952 <vTaskDelayUntil>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
     952:	0f 93       	push	r16
     954:	1f 93       	push	r17
     956:	cf 93       	push	r28
     958:	df 93       	push	r29
     95a:	8c 01       	movw	r16, r24
     95c:	eb 01       	movw	r28, r22

		configASSERT( pxPreviousWakeTime );
		configASSERT( ( xTimeIncrement > 0U ) );
		configASSERT( uxSchedulerSuspended == 0 );

		vTaskSuspendAll();
     95e:	0e 94 6e 03 	call	0x6dc	; 0x6dc <vTaskSuspendAll>
		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
     962:	40 91 31 01 	lds	r20, 0x0131	; 0x800131 <xTickCount>
     966:	50 91 32 01 	lds	r21, 0x0132	; 0x800132 <xTickCount+0x1>

			/* Generate the tick time at which the task wants to wake. */
			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
     96a:	f8 01       	movw	r30, r16
     96c:	20 81       	ld	r18, Z
     96e:	31 81       	ldd	r19, Z+1	; 0x01
     970:	c9 01       	movw	r24, r18
     972:	8c 0f       	add	r24, r28
     974:	9d 1f       	adc	r25, r29

			if( xConstTickCount < *pxPreviousWakeTime )
     976:	42 17       	cp	r20, r18
     978:	53 07       	cpc	r21, r19
     97a:	20 f4       	brcc	.+8      	; 0x984 <vTaskDelayUntil+0x32>
				/* The tick count has overflowed since this function was
				lasted called.  In this case the only time we should ever
				actually delay is if the wake time has also	overflowed,
				and the wake time is greater than the tick time.  When this
				is the case it is as if neither time had overflowed. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
     97c:	82 17       	cp	r24, r18
     97e:	93 07       	cpc	r25, r19
     980:	40 f4       	brcc	.+16     	; 0x992 <vTaskDelayUntil+0x40>
     982:	03 c0       	rjmp	.+6      	; 0x98a <vTaskDelayUntil+0x38>
			else
			{
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
     984:	82 17       	cp	r24, r18
     986:	93 07       	cpc	r25, r19
     988:	30 f0       	brcs	.+12     	; 0x996 <vTaskDelayUntil+0x44>
#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
	TickType_t xTimeToWake;
	BaseType_t xAlreadyYielded, xShouldDelay = pdFALSE;
     98a:	21 e0       	ldi	r18, 0x01	; 1
     98c:	48 17       	cp	r20, r24
     98e:	59 07       	cpc	r21, r25
     990:	18 f0       	brcs	.+6      	; 0x998 <vTaskDelayUntil+0x46>
     992:	20 e0       	ldi	r18, 0x00	; 0
     994:	01 c0       	rjmp	.+2      	; 0x998 <vTaskDelayUntil+0x46>
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
				{
					xShouldDelay = pdTRUE;
     996:	21 e0       	ldi	r18, 0x01	; 1
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
     998:	f8 01       	movw	r30, r16
     99a:	91 83       	std	Z+1, r25	; 0x01
     99c:	80 83       	st	Z, r24

			if( xShouldDelay != pdFALSE )
     99e:	22 23       	and	r18, r18
     9a0:	29 f0       	breq	.+10     	; 0x9ac <vTaskDelayUntil+0x5a>
			{
				traceTASK_DELAY_UNTIL( xTimeToWake );

				/* prvAddCurrentTaskToDelayedList() needs the block time, not
				the time to wake, so subtract the current tick count. */
				prvAddCurrentTaskToDelayedList( xTimeToWake - xConstTickCount, pdFALSE );
     9a2:	60 e0       	ldi	r22, 0x00	; 0
     9a4:	84 1b       	sub	r24, r20
     9a6:	95 0b       	sbc	r25, r21
     9a8:	0e 94 d0 00 	call	0x1a0	; 0x1a0 <prvAddCurrentTaskToDelayedList>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		xAlreadyYielded = xTaskResumeAll();
     9ac:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
     9b0:	81 11       	cpse	r24, r1
     9b2:	02 c0       	rjmp	.+4      	; 0x9b8 <vTaskDelayUntil+0x66>
		{
			portYIELD_WITHIN_API();
     9b4:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
     9b8:	df 91       	pop	r29
     9ba:	cf 91       	pop	r28
     9bc:	1f 91       	pop	r17
     9be:	0f 91       	pop	r16
     9c0:	08 95       	ret

000009c2 <vTaskDelay>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelay == 1 )

	void vTaskDelay( const TickType_t xTicksToDelay )
	{
     9c2:	cf 93       	push	r28
     9c4:	df 93       	push	r29
     9c6:	ec 01       	movw	r28, r24
	BaseType_t xAlreadyYielded = pdFALSE;

		/* A delay time of zero just forces a reschedule. */
		if( xTicksToDelay > ( TickType_t ) 0U )
     9c8:	89 2b       	or	r24, r25
     9ca:	19 f4       	brne	.+6      	; 0x9d2 <vTaskDelay+0x10>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     9cc:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
     9d0:	0a c0       	rjmp	.+20     	; 0x9e6 <vTaskDelay+0x24>

		/* A delay time of zero just forces a reschedule. */
		if( xTicksToDelay > ( TickType_t ) 0U )
		{
			configASSERT( uxSchedulerSuspended == 0 );
			vTaskSuspendAll();
     9d2:	0e 94 6e 03 	call	0x6dc	; 0x6dc <vTaskSuspendAll>
				list or removed from the blocked list until the scheduler
				is resumed.

				This task cannot be in an event list as it is the currently
				executing task. */
				prvAddCurrentTaskToDelayedList( xTicksToDelay, pdFALSE );
     9d6:	60 e0       	ldi	r22, 0x00	; 0
     9d8:	ce 01       	movw	r24, r28
     9da:	0e 94 d0 00 	call	0x1a0	; 0x1a0 <prvAddCurrentTaskToDelayedList>
			}
			xAlreadyYielded = xTaskResumeAll();
     9de:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
			mtCOVERAGE_TEST_MARKER();
		}

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
     9e2:	88 23       	and	r24, r24
     9e4:	99 f3       	breq	.-26     	; 0x9cc <vTaskDelay+0xa>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
     9e6:	df 91       	pop	r29
     9e8:	cf 91       	pop	r28
     9ea:	08 95       	ret

000009ec <vTaskSwitchContext>:
#endif /* configUSE_APPLICATION_TASK_TAG */
/*-----------------------------------------------------------*/

void vTaskSwitchContext( void )
{
	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
     9ec:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
     9f0:	88 23       	and	r24, r24
     9f2:	21 f0       	breq	.+8      	; 0x9fc <vTaskSwitchContext+0x10>
	{
		/* The scheduler is currently suspended - do not allow a context
		switch. */
		xYieldPending = pdTRUE;
     9f4:	81 e0       	ldi	r24, 0x01	; 1
     9f6:	80 93 2d 01 	sts	0x012D, r24	; 0x80012d <xYieldPending>
     9fa:	08 95       	ret
	}
	else
	{
		xYieldPending = pdFALSE;
     9fc:	10 92 2d 01 	sts	0x012D, r1	; 0x80012d <xYieldPending>
		}
		#endif

		/* Select a new task to run using either the generic C or port
		optimised asm code. */
		taskSELECT_HIGHEST_PRIORITY_TASK(); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
     a00:	80 91 30 01 	lds	r24, 0x0130	; 0x800130 <uxTopReadyPriority>
     a04:	69 e0       	ldi	r22, 0x09	; 9
     a06:	48 2f       	mov	r20, r24
     a08:	50 e0       	ldi	r21, 0x00	; 0
     a0a:	64 9f       	mul	r22, r20
     a0c:	90 01       	movw	r18, r0
     a0e:	65 9f       	mul	r22, r21
     a10:	30 0d       	add	r19, r0
     a12:	11 24       	eor	r1, r1
     a14:	f9 01       	movw	r30, r18
     a16:	ea 59       	subi	r30, 0x9A	; 154
     a18:	fe 4f       	sbci	r31, 0xFE	; 254
     a1a:	90 81       	ld	r25, Z
     a1c:	91 11       	cpse	r25, r1
     a1e:	02 c0       	rjmp	.+4      	; 0xa24 <vTaskSwitchContext+0x38>
     a20:	81 50       	subi	r24, 0x01	; 1
     a22:	f1 cf       	rjmp	.-30     	; 0xa06 <vTaskSwitchContext+0x1a>
     a24:	a1 81       	ldd	r26, Z+1	; 0x01
     a26:	b2 81       	ldd	r27, Z+2	; 0x02
     a28:	12 96       	adiw	r26, 0x02	; 2
     a2a:	0d 90       	ld	r0, X+
     a2c:	bc 91       	ld	r27, X
     a2e:	a0 2d       	mov	r26, r0
     a30:	b2 83       	std	Z+2, r27	; 0x02
     a32:	a1 83       	std	Z+1, r26	; 0x01
     a34:	27 59       	subi	r18, 0x97	; 151
     a36:	3e 4f       	sbci	r19, 0xFE	; 254
     a38:	a2 17       	cp	r26, r18
     a3a:	b3 07       	cpc	r27, r19
     a3c:	31 f4       	brne	.+12     	; 0xa4a <vTaskSwitchContext+0x5e>
     a3e:	12 96       	adiw	r26, 0x02	; 2
     a40:	2d 91       	ld	r18, X+
     a42:	3c 91       	ld	r19, X
     a44:	13 97       	sbiw	r26, 0x03	; 3
     a46:	32 83       	std	Z+2, r19	; 0x02
     a48:	21 83       	std	Z+1, r18	; 0x01
     a4a:	99 e0       	ldi	r25, 0x09	; 9
     a4c:	94 9f       	mul	r25, r20
     a4e:	f0 01       	movw	r30, r0
     a50:	95 9f       	mul	r25, r21
     a52:	f0 0d       	add	r31, r0
     a54:	11 24       	eor	r1, r1
     a56:	ea 59       	subi	r30, 0x9A	; 154
     a58:	fe 4f       	sbci	r31, 0xFE	; 254
     a5a:	01 80       	ldd	r0, Z+1	; 0x01
     a5c:	f2 81       	ldd	r31, Z+2	; 0x02
     a5e:	e0 2d       	mov	r30, r0
     a60:	26 81       	ldd	r18, Z+6	; 0x06
     a62:	37 81       	ldd	r19, Z+7	; 0x07
     a64:	30 93 25 01 	sts	0x0125, r19	; 0x800125 <__data_end+0x1>
     a68:	20 93 24 01 	sts	0x0124, r18	; 0x800124 <__data_end>
     a6c:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     a70:	08 95       	ret

00000a72 <vTaskSuspend>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskSuspend( TaskHandle_t xTaskToSuspend )
	{
     a72:	0f 93       	push	r16
     a74:	1f 93       	push	r17
     a76:	cf 93       	push	r28
     a78:	df 93       	push	r29
     a7a:	ec 01       	movw	r28, r24
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
     a7c:	0f b6       	in	r0, 0x3f	; 63
     a7e:	f8 94       	cli
     a80:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the running task that is
			being suspended. */
			pxTCB = prvGetTCBFromHandle( xTaskToSuspend );
     a82:	89 2b       	or	r24, r25
     a84:	21 f4       	brne	.+8      	; 0xa8e <vTaskSuspend+0x1c>
     a86:	c0 91 24 01 	lds	r28, 0x0124	; 0x800124 <__data_end>
     a8a:	d0 91 25 01 	lds	r29, 0x0125	; 0x800125 <__data_end+0x1>

			traceTASK_SUSPEND( pxTCB );

			/* Remove task from the ready/delayed list and place in the
			suspended list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
     a8e:	8e 01       	movw	r16, r28
     a90:	0e 5f       	subi	r16, 0xFE	; 254
     a92:	1f 4f       	sbci	r17, 0xFF	; 255
     a94:	c8 01       	movw	r24, r16
     a96:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
     a9a:	8c 89       	ldd	r24, Y+20	; 0x14
     a9c:	9d 89       	ldd	r25, Y+21	; 0x15
     a9e:	89 2b       	or	r24, r25
     aa0:	21 f0       	breq	.+8      	; 0xaaa <vTaskSuspend+0x38>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
     aa2:	ce 01       	movw	r24, r28
     aa4:	0c 96       	adiw	r24, 0x0c	; 12
     aa6:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			vListInsertEnd( &xSuspendedTaskList, &( pxTCB->xStateListItem ) );
     aaa:	b8 01       	movw	r22, r16
     aac:	84 e3       	ldi	r24, 0x34	; 52
     aae:	91 e0       	ldi	r25, 0x01	; 1
     ab0:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

			#if( configUSE_TASK_NOTIFICATIONS == 1 )
			{
				if( pxTCB->ucNotifyState == taskWAITING_NOTIFICATION )
     ab4:	8d a1       	ldd	r24, Y+37	; 0x25
     ab6:	81 30       	cpi	r24, 0x01	; 1
     ab8:	09 f4       	brne	.+2      	; 0xabc <vTaskSuspend+0x4a>
				{
					/* The task was blocked to wait for a notification, but is
					now suspended, so no notification was received. */
					pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
     aba:	1d a2       	std	Y+37, r1	; 0x25
				}
			}
			#endif
		}
		taskEXIT_CRITICAL();
     abc:	0f 90       	pop	r0
     abe:	0f be       	out	0x3f, r0	; 63

		if( xSchedulerRunning != pdFALSE )
     ac0:	80 91 2f 01 	lds	r24, 0x012F	; 0x80012f <xSchedulerRunning>
     ac4:	88 23       	and	r24, r24
     ac6:	39 f0       	breq	.+14     	; 0xad6 <vTaskSuspend+0x64>
		{
			/* Reset the next expected unblock time in case it referred to the
			task that is now in the Suspended state. */
			taskENTER_CRITICAL();
     ac8:	0f b6       	in	r0, 0x3f	; 63
     aca:	f8 94       	cli
     acc:	0f 92       	push	r0
			{
				prvResetNextTaskUnblockTime();
     ace:	0e 94 b5 00 	call	0x16a	; 0x16a <prvResetNextTaskUnblockTime>
			}
			taskEXIT_CRITICAL();
     ad2:	0f 90       	pop	r0
     ad4:	0f be       	out	0x3f, r0	; 63
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( pxTCB == pxCurrentTCB )
     ad6:	80 91 24 01 	lds	r24, 0x0124	; 0x800124 <__data_end>
     ada:	90 91 25 01 	lds	r25, 0x0125	; 0x800125 <__data_end+0x1>
     ade:	c8 17       	cp	r28, r24
     ae0:	d9 07       	cpc	r29, r25
     ae2:	c1 f4       	brne	.+48     	; 0xb14 <vTaskSuspend+0xa2>
		{
			if( xSchedulerRunning != pdFALSE )
     ae4:	80 91 2f 01 	lds	r24, 0x012F	; 0x80012f <xSchedulerRunning>
     ae8:	88 23       	and	r24, r24
     aea:	19 f0       	breq	.+6      	; 0xaf2 <vTaskSuspend+0x80>
			{
				/* The current task has just been suspended. */
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
     aec:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
     af0:	11 c0       	rjmp	.+34     	; 0xb14 <vTaskSuspend+0xa2>
			else
			{
				/* The scheduler is not running, but the task that was pointed
				to by pxCurrentTCB has just been suspended and pxCurrentTCB
				must be adjusted to point to a different task. */
				if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == uxCurrentNumberOfTasks ) /*lint !e931 Right has no side effect, just volatile. */
     af2:	90 91 34 01 	lds	r25, 0x0134	; 0x800134 <xSuspendedTaskList>
     af6:	80 91 33 01 	lds	r24, 0x0133	; 0x800133 <uxCurrentNumberOfTasks>
     afa:	98 13       	cpse	r25, r24
     afc:	05 c0       	rjmp	.+10     	; 0xb08 <vTaskSuspend+0x96>
				{
					/* No other tasks are ready, so set pxCurrentTCB back to
					NULL so when the next task is created pxCurrentTCB will
					be set to point to it no matter what its relative priority
					is. */
					pxCurrentTCB = NULL;
     afe:	10 92 25 01 	sts	0x0125, r1	; 0x800125 <__data_end+0x1>
     b02:	10 92 24 01 	sts	0x0124, r1	; 0x800124 <__data_end>
     b06:	06 c0       	rjmp	.+12     	; 0xb14 <vTaskSuspend+0xa2>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
     b08:	df 91       	pop	r29
     b0a:	cf 91       	pop	r28
     b0c:	1f 91       	pop	r17
     b0e:	0f 91       	pop	r16
					is. */
					pxCurrentTCB = NULL;
				}
				else
				{
					vTaskSwitchContext();
     b10:	0c 94 f6 04 	jmp	0x9ec	; 0x9ec <vTaskSwitchContext>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
     b14:	df 91       	pop	r29
     b16:	cf 91       	pop	r28
     b18:	1f 91       	pop	r17
     b1a:	0f 91       	pop	r16
     b1c:	08 95       	ret

00000b1e <vTaskPlaceOnEventList>:
	}
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
{
     b1e:	cf 93       	push	r28
     b20:	df 93       	push	r29
     b22:	eb 01       	movw	r28, r22

	/* Place the event list item of the TCB in the appropriate event list.
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
     b24:	60 91 24 01 	lds	r22, 0x0124	; 0x800124 <__data_end>
     b28:	70 91 25 01 	lds	r23, 0x0125	; 0x800125 <__data_end+0x1>
     b2c:	64 5f       	subi	r22, 0xF4	; 244
     b2e:	7f 4f       	sbci	r23, 0xFF	; 255
     b30:	0e 94 d4 0d 	call	0x1ba8	; 0x1ba8 <vListInsert>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
     b34:	61 e0       	ldi	r22, 0x01	; 1
     b36:	ce 01       	movw	r24, r28
}
     b38:	df 91       	pop	r29
     b3a:	cf 91       	pop	r28
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
     b3c:	0c 94 d0 00 	jmp	0x1a0	; 0x1a0 <prvAddCurrentTaskToDelayedList>

00000b40 <vTaskPlaceOnUnorderedEventList>:
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait )
{
     b40:	cf 93       	push	r28
     b42:	df 93       	push	r29
     b44:	ea 01       	movw	r28, r20
	configASSERT( uxSchedulerSuspended != 0 );

	/* Store the item value in the event list item.  It is safe to access the
	event list item here as interrupts won't access the event list item of a
	task that is not in the Blocked state. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
     b46:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     b4a:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     b4e:	70 68       	ori	r23, 0x80	; 128
     b50:	75 87       	std	Z+13, r23	; 0x0d
     b52:	64 87       	std	Z+12, r22	; 0x0c
	/* Place the event list item of the TCB at the end of the appropriate event
	list.  It is safe to access the event list here because it is part of an
	event group implementation - and interrupts don't access event groups
	directly (instead they access them indirectly by pending function calls to
	the task level). */
	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
     b54:	60 91 24 01 	lds	r22, 0x0124	; 0x800124 <__data_end>
     b58:	70 91 25 01 	lds	r23, 0x0125	; 0x800125 <__data_end+0x1>
     b5c:	64 5f       	subi	r22, 0xF4	; 244
     b5e:	7f 4f       	sbci	r23, 0xFF	; 255
     b60:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
     b64:	61 e0       	ldi	r22, 0x01	; 1
     b66:	ce 01       	movw	r24, r28
}
     b68:	df 91       	pop	r29
     b6a:	cf 91       	pop	r28
	event group implementation - and interrupts don't access event groups
	directly (instead they access them indirectly by pending function calls to
	the task level). */
	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
     b6c:	0c 94 d0 00 	jmp	0x1a0	; 0x1a0 <prvAddCurrentTaskToDelayedList>

00000b70 <xTaskRemoveFromEventList>:

#endif /* configUSE_TIMERS */
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
{
     b70:	0f 93       	push	r16
     b72:	1f 93       	push	r17
     b74:	cf 93       	push	r28
     b76:	df 93       	push	r29
	get called - the lock count on the queue will get modified instead.  This
	means exclusive access to the event list is guaranteed here.

	This function assumes that a check has already been made to ensure that
	pxEventList is not empty. */
	pxUnblockedTCB = listGET_OWNER_OF_HEAD_ENTRY( pxEventList ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
     b78:	dc 01       	movw	r26, r24
     b7a:	15 96       	adiw	r26, 0x05	; 5
     b7c:	ed 91       	ld	r30, X+
     b7e:	fc 91       	ld	r31, X
     b80:	16 97       	sbiw	r26, 0x06	; 6
     b82:	c6 81       	ldd	r28, Z+6	; 0x06
     b84:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
     b86:	8e 01       	movw	r16, r28
     b88:	04 5f       	subi	r16, 0xF4	; 244
     b8a:	1f 4f       	sbci	r17, 0xFF	; 255
     b8c:	c8 01       	movw	r24, r16
     b8e:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>

	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
     b92:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
     b96:	81 11       	cpse	r24, r1
     b98:	14 c0       	rjmp	.+40     	; 0xbc2 <xTaskRemoveFromEventList+0x52>
	{
		( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
     b9a:	0a 50       	subi	r16, 0x0A	; 10
     b9c:	11 09       	sbc	r17, r1
     b9e:	c8 01       	movw	r24, r16
     ba0:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
		prvAddTaskToReadyList( pxUnblockedTCB );
     ba4:	8e 89       	ldd	r24, Y+22	; 0x16
     ba6:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     baa:	98 17       	cp	r25, r24
     bac:	10 f4       	brcc	.+4      	; 0xbb2 <xTaskRemoveFromEventList+0x42>
     bae:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     bb2:	b9 e0       	ldi	r27, 0x09	; 9
     bb4:	8b 9f       	mul	r24, r27
     bb6:	c0 01       	movw	r24, r0
     bb8:	11 24       	eor	r1, r1
     bba:	b8 01       	movw	r22, r16
     bbc:	8a 59       	subi	r24, 0x9A	; 154
     bbe:	9e 4f       	sbci	r25, 0xFE	; 254
     bc0:	03 c0       	rjmp	.+6      	; 0xbc8 <xTaskRemoveFromEventList+0x58>
	}
	else
	{
		/* The delayed and ready lists cannot be accessed, so hold this task
		pending until the scheduler is resumed. */
		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
     bc2:	b8 01       	movw	r22, r16
     bc4:	87 e4       	ldi	r24, 0x47	; 71
     bc6:	91 e0       	ldi	r25, 0x01	; 1
     bc8:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
	}

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
     bcc:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     bd0:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     bd4:	9e 89       	ldd	r25, Y+22	; 0x16
     bd6:	86 89       	ldd	r24, Z+22	; 0x16
     bd8:	89 17       	cp	r24, r25
     bda:	20 f4       	brcc	.+8      	; 0xbe4 <xTaskRemoveFromEventList+0x74>
		it should force a context switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
     bdc:	81 e0       	ldi	r24, 0x01	; 1
     bde:	80 93 2d 01 	sts	0x012D, r24	; 0x80012d <xYieldPending>
     be2:	01 c0       	rjmp	.+2      	; 0xbe6 <xTaskRemoveFromEventList+0x76>
	}
	else
	{
		xReturn = pdFALSE;
     be4:	80 e0       	ldi	r24, 0x00	; 0
		prvResetNextTaskUnblockTime();
	}
	#endif

	return xReturn;
}
     be6:	df 91       	pop	r29
     be8:	cf 91       	pop	r28
     bea:	1f 91       	pop	r17
     bec:	0f 91       	pop	r16
     bee:	08 95       	ret

00000bf0 <vTaskRemoveFromUnorderedEventList>:
/*-----------------------------------------------------------*/

void vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue )
{
     bf0:	0f 93       	push	r16
     bf2:	1f 93       	push	r17
     bf4:	cf 93       	push	r28
     bf6:	df 93       	push	r29
	/* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by
	the event flags implementation. */
	configASSERT( uxSchedulerSuspended != pdFALSE );

	/* Store the new item value in the event list. */
	listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
     bf8:	70 68       	ori	r23, 0x80	; 128
     bfa:	fc 01       	movw	r30, r24
     bfc:	71 83       	std	Z+1, r23	; 0x01
     bfe:	60 83       	st	Z, r22

	/* Remove the event list form the event flag.  Interrupts do not access
	event flags. */
	pxUnblockedTCB = listGET_LIST_ITEM_OWNER( pxEventListItem ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
     c00:	c6 81       	ldd	r28, Z+6	; 0x06
     c02:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( pxEventListItem );
     c04:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>

	/* Remove the task from the delayed list and add it to the ready list.  The
	scheduler is suspended so interrupts will not be accessing the ready
	lists. */
	( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
     c08:	8e 01       	movw	r16, r28
     c0a:	0e 5f       	subi	r16, 0xFE	; 254
     c0c:	1f 4f       	sbci	r17, 0xFF	; 255
     c0e:	c8 01       	movw	r24, r16
     c10:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
	prvAddTaskToReadyList( pxUnblockedTCB );
     c14:	8e 89       	ldd	r24, Y+22	; 0x16
     c16:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     c1a:	98 17       	cp	r25, r24
     c1c:	10 f4       	brcc	.+4      	; 0xc22 <vTaskRemoveFromUnorderedEventList+0x32>
     c1e:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     c22:	f9 e0       	ldi	r31, 0x09	; 9
     c24:	8f 9f       	mul	r24, r31
     c26:	c0 01       	movw	r24, r0
     c28:	11 24       	eor	r1, r1
     c2a:	b8 01       	movw	r22, r16
     c2c:	8a 59       	subi	r24, 0x9A	; 154
     c2e:	9e 4f       	sbci	r25, 0xFE	; 254
     c30:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
     c34:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     c38:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     c3c:	9e 89       	ldd	r25, Y+22	; 0x16
     c3e:	86 89       	ldd	r24, Z+22	; 0x16
     c40:	89 17       	cp	r24, r25
     c42:	18 f4       	brcc	.+6      	; 0xc4a <vTaskRemoveFromUnorderedEventList+0x5a>
	{
		/* The unblocked task has a priority above that of the calling task, so
		a context switch is required.  This function is called with the
		scheduler suspended so xYieldPending is set so the context switch
		occurs immediately that the scheduler is resumed (unsuspended). */
		xYieldPending = pdTRUE;
     c44:	81 e0       	ldi	r24, 0x01	; 1
     c46:	80 93 2d 01 	sts	0x012D, r24	; 0x80012d <xYieldPending>
	}
}
     c4a:	df 91       	pop	r29
     c4c:	cf 91       	pop	r28
     c4e:	1f 91       	pop	r17
     c50:	0f 91       	pop	r16
     c52:	08 95       	ret

00000c54 <vTaskSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
{
	configASSERT( pxTimeOut );
	taskENTER_CRITICAL();
     c54:	0f b6       	in	r0, 0x3f	; 63
     c56:	f8 94       	cli
     c58:	0f 92       	push	r0
	{
		pxTimeOut->xOverflowCount = xNumOfOverflows;
     c5a:	20 91 2c 01 	lds	r18, 0x012C	; 0x80012c <xNumOfOverflows>
     c5e:	fc 01       	movw	r30, r24
     c60:	20 83       	st	Z, r18
		pxTimeOut->xTimeOnEntering = xTickCount;
     c62:	20 91 31 01 	lds	r18, 0x0131	; 0x800131 <xTickCount>
     c66:	30 91 32 01 	lds	r19, 0x0132	; 0x800132 <xTickCount+0x1>
     c6a:	32 83       	std	Z+2, r19	; 0x02
     c6c:	21 83       	std	Z+1, r18	; 0x01
	}
	taskEXIT_CRITICAL();
     c6e:	0f 90       	pop	r0
     c70:	0f be       	out	0x3f, r0	; 63
     c72:	08 95       	ret

00000c74 <vTaskInternalSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskInternalSetTimeOutState( TimeOut_t * const pxTimeOut )
{
	/* For internal use only as it does not use a critical section. */
	pxTimeOut->xOverflowCount = xNumOfOverflows;
     c74:	20 91 2c 01 	lds	r18, 0x012C	; 0x80012c <xNumOfOverflows>
     c78:	fc 01       	movw	r30, r24
     c7a:	20 83       	st	Z, r18
	pxTimeOut->xTimeOnEntering = xTickCount;
     c7c:	20 91 31 01 	lds	r18, 0x0131	; 0x800131 <xTickCount>
     c80:	30 91 32 01 	lds	r19, 0x0132	; 0x800132 <xTickCount+0x1>
     c84:	32 83       	std	Z+2, r19	; 0x02
     c86:	21 83       	std	Z+1, r18	; 0x01
     c88:	08 95       	ret

00000c8a <xTaskCheckForTimeOut>:
}
/*-----------------------------------------------------------*/

BaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait )
{
     c8a:	cf 93       	push	r28
     c8c:	df 93       	push	r29
BaseType_t xReturn;

	configASSERT( pxTimeOut );
	configASSERT( pxTicksToWait );

	taskENTER_CRITICAL();
     c8e:	0f b6       	in	r0, 0x3f	; 63
     c90:	f8 94       	cli
     c92:	0f 92       	push	r0
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
     c94:	40 91 31 01 	lds	r20, 0x0131	; 0x800131 <xTickCount>
     c98:	50 91 32 01 	lds	r21, 0x0132	; 0x800132 <xTickCount+0x1>
			}
			else
		#endif

		#if ( INCLUDE_vTaskSuspend == 1 )
			if( *pxTicksToWait == portMAX_DELAY )
     c9c:	db 01       	movw	r26, r22
     c9e:	2d 91       	ld	r18, X+
     ca0:	3c 91       	ld	r19, X
     ca2:	2f 3f       	cpi	r18, 0xFF	; 255
     ca4:	bf ef       	ldi	r27, 0xFF	; 255
     ca6:	3b 07       	cpc	r19, r27
     ca8:	d9 f0       	breq	.+54     	; 0xce0 <xTaskCheckForTimeOut+0x56>

	taskENTER_CRITICAL();
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
		const TickType_t xElapsedTime = xConstTickCount - pxTimeOut->xTimeOnEntering;
     caa:	ec 01       	movw	r28, r24
     cac:	e9 81       	ldd	r30, Y+1	; 0x01
     cae:	fa 81       	ldd	r31, Y+2	; 0x02
				xReturn = pdFALSE;
			}
			else
		#endif

		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) /*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
     cb0:	a0 91 2c 01 	lds	r26, 0x012C	; 0x80012c <xNumOfOverflows>
     cb4:	b8 81       	ld	r27, Y
     cb6:	ba 17       	cp	r27, r26
     cb8:	19 f0       	breq	.+6      	; 0xcc0 <xTaskCheckForTimeOut+0x36>
     cba:	4e 17       	cp	r20, r30
     cbc:	5f 07       	cpc	r21, r31
     cbe:	90 f4       	brcc	.+36     	; 0xce4 <xTaskCheckForTimeOut+0x5a>

	taskENTER_CRITICAL();
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
		const TickType_t xElapsedTime = xConstTickCount - pxTimeOut->xTimeOnEntering;
     cc0:	4e 1b       	sub	r20, r30
     cc2:	5f 0b       	sbc	r21, r31
     cc4:	fb 01       	movw	r30, r22
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
		}
		else if( xElapsedTime < *pxTicksToWait ) /*lint !e961 Explicit casting is only redundant with some compilers, whereas others require it to prevent integer conversion errors. */
     cc6:	42 17       	cp	r20, r18
     cc8:	53 07       	cpc	r21, r19
     cca:	38 f4       	brcc	.+14     	; 0xcda <xTaskCheckForTimeOut+0x50>
		{
			/* Not a genuine timeout. Adjust parameters for time remaining. */
			*pxTicksToWait -= xElapsedTime;
     ccc:	24 1b       	sub	r18, r20
     cce:	35 0b       	sbc	r19, r21
     cd0:	31 83       	std	Z+1, r19	; 0x01
     cd2:	20 83       	st	Z, r18
			vTaskInternalSetTimeOutState( pxTimeOut );
     cd4:	0e 94 3a 06 	call	0xc74	; 0xc74 <vTaskInternalSetTimeOutState>
     cd8:	03 c0       	rjmp	.+6      	; 0xce0 <xTaskCheckForTimeOut+0x56>
			xReturn = pdFALSE;
		}
		else
		{
			*pxTicksToWait = 0;
     cda:	11 82       	std	Z+1, r1	; 0x01
     cdc:	10 82       	st	Z, r1
     cde:	02 c0       	rjmp	.+4      	; 0xce4 <xTaskCheckForTimeOut+0x5a>
			if( *pxTicksToWait == portMAX_DELAY )
			{
				/* If INCLUDE_vTaskSuspend is set to 1 and the block time
				specified is the maximum block time then the task should block
				indefinitely, and therefore never time out. */
				xReturn = pdFALSE;
     ce0:	80 e0       	ldi	r24, 0x00	; 0
     ce2:	01 c0       	rjmp	.+2      	; 0xce6 <xTaskCheckForTimeOut+0x5c>
			/* The tick count is greater than the time at which
			vTaskSetTimeout() was called, but has also overflowed since
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
     ce4:	81 e0       	ldi	r24, 0x01	; 1
		{
			*pxTicksToWait = 0;
			xReturn = pdTRUE;
		}
	}
	taskEXIT_CRITICAL();
     ce6:	0f 90       	pop	r0
     ce8:	0f be       	out	0x3f, r0	; 63

	return xReturn;
}
     cea:	df 91       	pop	r29
     cec:	cf 91       	pop	r28
     cee:	08 95       	ret

00000cf0 <vTaskMissedYield>:
/*-----------------------------------------------------------*/

void vTaskMissedYield( void )
{
	xYieldPending = pdTRUE;
     cf0:	81 e0       	ldi	r24, 0x01	; 1
     cf2:	80 93 2d 01 	sts	0x012D, r24	; 0x80012d <xYieldPending>
     cf6:	08 95       	ret

00000cf8 <uxTaskResetEventItemValue>:

TickType_t uxTaskResetEventItemValue( void )
{
TickType_t uxReturn;

	uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );
     cf8:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     cfc:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     d00:	84 85       	ldd	r24, Z+12	; 0x0c
     d02:	95 85       	ldd	r25, Z+13	; 0x0d

	/* Reset the event list item to its normal value - so it can be used with
	queues and semaphores. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     d04:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     d08:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     d0c:	a0 91 24 01 	lds	r26, 0x0124	; 0x800124 <__data_end>
     d10:	b0 91 25 01 	lds	r27, 0x0125	; 0x800125 <__data_end+0x1>
     d14:	56 96       	adiw	r26, 0x16	; 22
     d16:	4c 91       	ld	r20, X
     d18:	24 e0       	ldi	r18, 0x04	; 4
     d1a:	30 e0       	ldi	r19, 0x00	; 0
     d1c:	24 1b       	sub	r18, r20
     d1e:	31 09       	sbc	r19, r1
     d20:	35 87       	std	Z+13, r19	; 0x0d
     d22:	24 87       	std	Z+12, r18	; 0x0c

	return uxReturn;
}
     d24:	08 95       	ret

00000d26 <ulTaskNotifyTake>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait )
	{
     d26:	0f 93       	push	r16
     d28:	1f 93       	push	r17
     d2a:	18 2f       	mov	r17, r24
     d2c:	cb 01       	movw	r24, r22
	uint32_t ulReturn;

		taskENTER_CRITICAL();
     d2e:	0f b6       	in	r0, 0x3f	; 63
     d30:	f8 94       	cli
     d32:	0f 92       	push	r0
		{
			/* Only block if the notification count is not already non-zero. */
			if( pxCurrentTCB->ulNotifiedValue == 0UL )
     d34:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     d38:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     d3c:	41 a1       	ldd	r20, Z+33	; 0x21
     d3e:	52 a1       	ldd	r21, Z+34	; 0x22
     d40:	63 a1       	ldd	r22, Z+35	; 0x23
     d42:	74 a1       	ldd	r23, Z+36	; 0x24
     d44:	45 2b       	or	r20, r21
     d46:	46 2b       	or	r20, r22
     d48:	47 2b       	or	r20, r23
     d4a:	69 f4       	brne	.+26     	; 0xd66 <ulTaskNotifyTake+0x40>
			{
				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
     d4c:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     d50:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     d54:	21 e0       	ldi	r18, 0x01	; 1
     d56:	25 a3       	std	Z+37, r18	; 0x25

				if( xTicksToWait > ( TickType_t ) 0 )
     d58:	00 97       	sbiw	r24, 0x00	; 0
     d5a:	29 f0       	breq	.+10     	; 0xd66 <ulTaskNotifyTake+0x40>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
     d5c:	61 e0       	ldi	r22, 0x01	; 1
     d5e:	0e 94 d0 00 	call	0x1a0	; 0x1a0 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
     d62:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
     d66:	0f 90       	pop	r0
     d68:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
     d6a:	0f b6       	in	r0, 0x3f	; 63
     d6c:	f8 94       	cli
     d6e:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_TAKE();
			ulReturn = pxCurrentTCB->ulNotifiedValue;
     d70:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     d74:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     d78:	61 a1       	ldd	r22, Z+33	; 0x21
     d7a:	72 a1       	ldd	r23, Z+34	; 0x22
     d7c:	83 a1       	ldd	r24, Z+35	; 0x23
     d7e:	94 a1       	ldd	r25, Z+36	; 0x24

			if( ulReturn != 0UL )
     d80:	61 15       	cp	r22, r1
     d82:	71 05       	cpc	r23, r1
     d84:	81 05       	cpc	r24, r1
     d86:	91 05       	cpc	r25, r1
     d88:	a9 f0       	breq	.+42     	; 0xdb4 <ulTaskNotifyTake+0x8e>
			{
				if( xClearCountOnExit != pdFALSE )
				{
					pxCurrentTCB->ulNotifiedValue = 0UL;
     d8a:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     d8e:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
			traceTASK_NOTIFY_TAKE();
			ulReturn = pxCurrentTCB->ulNotifiedValue;

			if( ulReturn != 0UL )
			{
				if( xClearCountOnExit != pdFALSE )
     d92:	11 23       	and	r17, r17
     d94:	29 f0       	breq	.+10     	; 0xda0 <ulTaskNotifyTake+0x7a>
				{
					pxCurrentTCB->ulNotifiedValue = 0UL;
     d96:	11 a2       	std	Z+33, r1	; 0x21
     d98:	12 a2       	std	Z+34, r1	; 0x22
     d9a:	13 a2       	std	Z+35, r1	; 0x23
     d9c:	14 a2       	std	Z+36, r1	; 0x24
     d9e:	0a c0       	rjmp	.+20     	; 0xdb4 <ulTaskNotifyTake+0x8e>
				}
				else
				{
					pxCurrentTCB->ulNotifiedValue = ulReturn - ( uint32_t ) 1;
     da0:	8b 01       	movw	r16, r22
     da2:	9c 01       	movw	r18, r24
     da4:	01 50       	subi	r16, 0x01	; 1
     da6:	11 09       	sbc	r17, r1
     da8:	21 09       	sbc	r18, r1
     daa:	31 09       	sbc	r19, r1
     dac:	01 a3       	std	Z+33, r16	; 0x21
     dae:	12 a3       	std	Z+34, r17	; 0x22
     db0:	23 a3       	std	Z+35, r18	; 0x23
     db2:	34 a3       	std	Z+36, r19	; 0x24
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
     db4:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     db8:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     dbc:	15 a2       	std	Z+37, r1	; 0x25
		}
		taskEXIT_CRITICAL();
     dbe:	0f 90       	pop	r0
     dc0:	0f be       	out	0x3f, r0	; 63

		return ulReturn;
	}
     dc2:	1f 91       	pop	r17
     dc4:	0f 91       	pop	r16
     dc6:	08 95       	ret

00000dc8 <xTaskNotifyWait>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait )
	{
     dc8:	4f 92       	push	r4
     dca:	5f 92       	push	r5
     dcc:	6f 92       	push	r6
     dce:	7f 92       	push	r7
     dd0:	8f 92       	push	r8
     dd2:	9f 92       	push	r9
     dd4:	af 92       	push	r10
     dd6:	bf 92       	push	r11
     dd8:	ef 92       	push	r14
     dda:	ff 92       	push	r15
     ddc:	0f 93       	push	r16
     dde:	1f 93       	push	r17
     de0:	49 01       	movw	r8, r18
     de2:	5a 01       	movw	r10, r20
	BaseType_t xReturn;

		taskENTER_CRITICAL();
     de4:	0f b6       	in	r0, 0x3f	; 63
     de6:	f8 94       	cli
     de8:	0f 92       	push	r0
		{
			/* Only block if a notification is not already pending. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
     dea:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     dee:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     df2:	25 a1       	ldd	r18, Z+37	; 0x25
     df4:	22 30       	cpi	r18, 0x02	; 2
     df6:	39 f1       	breq	.+78     	; 0xe46 <xTaskNotifyWait+0x7e>
			{
				/* Clear bits in the task's notification value as bits may get
				set	by the notifying task or interrupt.  This can be used to
				clear the value to zero. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnEntry;
     df8:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     dfc:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     e00:	21 a1       	ldd	r18, Z+33	; 0x21
     e02:	32 a1       	ldd	r19, Z+34	; 0x22
     e04:	43 a1       	ldd	r20, Z+35	; 0x23
     e06:	54 a1       	ldd	r21, Z+36	; 0x24
     e08:	2b 01       	movw	r4, r22
     e0a:	3c 01       	movw	r6, r24
     e0c:	40 94       	com	r4
     e0e:	50 94       	com	r5
     e10:	60 94       	com	r6
     e12:	70 94       	com	r7
     e14:	d3 01       	movw	r26, r6
     e16:	c2 01       	movw	r24, r4
     e18:	82 23       	and	r24, r18
     e1a:	93 23       	and	r25, r19
     e1c:	a4 23       	and	r26, r20
     e1e:	b5 23       	and	r27, r21
     e20:	81 a3       	std	Z+33, r24	; 0x21
     e22:	92 a3       	std	Z+34, r25	; 0x22
     e24:	a3 a3       	std	Z+35, r26	; 0x23
     e26:	b4 a3       	std	Z+36, r27	; 0x24

				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
     e28:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     e2c:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     e30:	81 e0       	ldi	r24, 0x01	; 1
     e32:	85 a3       	std	Z+37, r24	; 0x25

				if( xTicksToWait > ( TickType_t ) 0 )
     e34:	e1 14       	cp	r14, r1
     e36:	f1 04       	cpc	r15, r1
     e38:	31 f0       	breq	.+12     	; 0xe46 <xTaskNotifyWait+0x7e>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
     e3a:	61 e0       	ldi	r22, 0x01	; 1
     e3c:	c7 01       	movw	r24, r14
     e3e:	0e 94 d0 00 	call	0x1a0	; 0x1a0 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
     e42:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
     e46:	0f 90       	pop	r0
     e48:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
     e4a:	0f b6       	in	r0, 0x3f	; 63
     e4c:	f8 94       	cli
     e4e:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_WAIT();

			if( pulNotificationValue != NULL )
     e50:	01 15       	cp	r16, r1
     e52:	11 05       	cpc	r17, r1
     e54:	69 f0       	breq	.+26     	; 0xe70 <xTaskNotifyWait+0xa8>
			{
				/* Output the current notification value, which may or may not
				have changed. */
				*pulNotificationValue = pxCurrentTCB->ulNotifiedValue;
     e56:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     e5a:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     e5e:	81 a1       	ldd	r24, Z+33	; 0x21
     e60:	92 a1       	ldd	r25, Z+34	; 0x22
     e62:	a3 a1       	ldd	r26, Z+35	; 0x23
     e64:	b4 a1       	ldd	r27, Z+36	; 0x24
     e66:	f8 01       	movw	r30, r16
     e68:	80 83       	st	Z, r24
     e6a:	91 83       	std	Z+1, r25	; 0x01
     e6c:	a2 83       	std	Z+2, r26	; 0x02
     e6e:	b3 83       	std	Z+3, r27	; 0x03

			/* If ucNotifyValue is set then either the task never entered the
			blocked state (because a notification was already pending) or the
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
     e70:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     e74:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     e78:	85 a1       	ldd	r24, Z+37	; 0x25
     e7a:	82 30       	cpi	r24, 0x02	; 2
     e7c:	c1 f4       	brne	.+48     	; 0xeae <xTaskNotifyWait+0xe6>
			}
			else
			{
				/* A notification was already pending or a notification was
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
     e7e:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     e82:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     e86:	41 a1       	ldd	r20, Z+33	; 0x21
     e88:	52 a1       	ldd	r21, Z+34	; 0x22
     e8a:	63 a1       	ldd	r22, Z+35	; 0x23
     e8c:	74 a1       	ldd	r23, Z+36	; 0x24
     e8e:	d5 01       	movw	r26, r10
     e90:	c4 01       	movw	r24, r8
     e92:	80 95       	com	r24
     e94:	90 95       	com	r25
     e96:	a0 95       	com	r26
     e98:	b0 95       	com	r27
     e9a:	84 23       	and	r24, r20
     e9c:	95 23       	and	r25, r21
     e9e:	a6 23       	and	r26, r22
     ea0:	b7 23       	and	r27, r23
     ea2:	81 a3       	std	Z+33, r24	; 0x21
     ea4:	92 a3       	std	Z+34, r25	; 0x22
     ea6:	a3 a3       	std	Z+35, r26	; 0x23
     ea8:	b4 a3       	std	Z+36, r27	; 0x24
				xReturn = pdTRUE;
     eaa:	81 e0       	ldi	r24, 0x01	; 1
     eac:	01 c0       	rjmp	.+2      	; 0xeb0 <xTaskNotifyWait+0xe8>
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
			{
				/* A notification was not received. */
				xReturn = pdFALSE;
     eae:	80 e0       	ldi	r24, 0x00	; 0
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
				xReturn = pdTRUE;
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
     eb0:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     eb4:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     eb8:	15 a2       	std	Z+37, r1	; 0x25
		}
		taskEXIT_CRITICAL();
     eba:	0f 90       	pop	r0
     ebc:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
     ebe:	1f 91       	pop	r17
     ec0:	0f 91       	pop	r16
     ec2:	ff 90       	pop	r15
     ec4:	ef 90       	pop	r14
     ec6:	bf 90       	pop	r11
     ec8:	af 90       	pop	r10
     eca:	9f 90       	pop	r9
     ecc:	8f 90       	pop	r8
     ece:	7f 90       	pop	r7
     ed0:	6f 90       	pop	r6
     ed2:	5f 90       	pop	r5
     ed4:	4f 90       	pop	r4
     ed6:	08 95       	ret

00000ed8 <xTaskGenericNotify>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue )
	{
     ed8:	0f 93       	push	r16
     eda:	1f 93       	push	r17
     edc:	cf 93       	push	r28
     ede:	df 93       	push	r29
     ee0:	fc 01       	movw	r30, r24
	uint8_t ucOriginalNotifyState;

		configASSERT( xTaskToNotify );
		pxTCB = xTaskToNotify;

		taskENTER_CRITICAL();
     ee2:	0f b6       	in	r0, 0x3f	; 63
     ee4:	f8 94       	cli
     ee6:	0f 92       	push	r0
		{
			if( pulPreviousNotificationValue != NULL )
     ee8:	01 15       	cp	r16, r1
     eea:	11 05       	cpc	r17, r1
     eec:	49 f0       	breq	.+18     	; 0xf00 <xTaskGenericNotify+0x28>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
     eee:	81 a1       	ldd	r24, Z+33	; 0x21
     ef0:	92 a1       	ldd	r25, Z+34	; 0x22
     ef2:	a3 a1       	ldd	r26, Z+35	; 0x23
     ef4:	b4 a1       	ldd	r27, Z+36	; 0x24
     ef6:	e8 01       	movw	r28, r16
     ef8:	88 83       	st	Y, r24
     efa:	99 83       	std	Y+1, r25	; 0x01
     efc:	aa 83       	std	Y+2, r26	; 0x02
     efe:	bb 83       	std	Y+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
     f00:	35 a1       	ldd	r19, Z+37	; 0x25

			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
     f02:	82 e0       	ldi	r24, 0x02	; 2
     f04:	85 a3       	std	Z+37, r24	; 0x25

			switch( eAction )
     f06:	22 30       	cpi	r18, 0x02	; 2
     f08:	89 f0       	breq	.+34     	; 0xf2c <xTaskGenericNotify+0x54>
     f0a:	58 f4       	brcc	.+22     	; 0xf22 <xTaskGenericNotify+0x4a>
     f0c:	21 30       	cpi	r18, 0x01	; 1
     f0e:	01 f5       	brne	.+64     	; 0xf50 <xTaskGenericNotify+0x78>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
     f10:	81 a1       	ldd	r24, Z+33	; 0x21
     f12:	92 a1       	ldd	r25, Z+34	; 0x22
     f14:	a3 a1       	ldd	r26, Z+35	; 0x23
     f16:	b4 a1       	ldd	r27, Z+36	; 0x24
     f18:	48 2b       	or	r20, r24
     f1a:	59 2b       	or	r21, r25
     f1c:	6a 2b       	or	r22, r26
     f1e:	7b 2b       	or	r23, r27
     f20:	13 c0       	rjmp	.+38     	; 0xf48 <xTaskGenericNotify+0x70>

			ucOriginalNotifyState = pxTCB->ucNotifyState;

			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;

			switch( eAction )
     f22:	23 30       	cpi	r18, 0x03	; 3
     f24:	89 f0       	breq	.+34     	; 0xf48 <xTaskGenericNotify+0x70>
     f26:	24 30       	cpi	r18, 0x04	; 4
     f28:	69 f0       	breq	.+26     	; 0xf44 <xTaskGenericNotify+0x6c>
     f2a:	12 c0       	rjmp	.+36     	; 0xf50 <xTaskGenericNotify+0x78>
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
					break;

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
     f2c:	81 a1       	ldd	r24, Z+33	; 0x21
     f2e:	92 a1       	ldd	r25, Z+34	; 0x22
     f30:	a3 a1       	ldd	r26, Z+35	; 0x23
     f32:	b4 a1       	ldd	r27, Z+36	; 0x24
     f34:	01 96       	adiw	r24, 0x01	; 1
     f36:	a1 1d       	adc	r26, r1
     f38:	b1 1d       	adc	r27, r1
     f3a:	81 a3       	std	Z+33, r24	; 0x21
     f3c:	92 a3       	std	Z+34, r25	; 0x22
     f3e:	a3 a3       	std	Z+35, r26	; 0x23
     f40:	b4 a3       	std	Z+36, r27	; 0x24
					break;
     f42:	06 c0       	rjmp	.+12     	; 0xf50 <xTaskGenericNotify+0x78>
				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
					break;

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
     f44:	32 30       	cpi	r19, 0x02	; 2
     f46:	49 f1       	breq	.+82     	; 0xf9a <xTaskGenericNotify+0xc2>
					{
						pxTCB->ulNotifiedValue = ulValue;
     f48:	41 a3       	std	Z+33, r20	; 0x21
     f4a:	52 a3       	std	Z+34, r21	; 0x22
     f4c:	63 a3       	std	Z+35, r22	; 0x23
     f4e:	74 a3       	std	Z+36, r23	; 0x24

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
     f50:	31 30       	cpi	r19, 0x01	; 1
     f52:	09 f5       	brne	.+66     	; 0xf96 <xTaskGenericNotify+0xbe>
     f54:	ef 01       	movw	r28, r30
			{
				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
     f56:	8f 01       	movw	r16, r30
     f58:	0e 5f       	subi	r16, 0xFE	; 254
     f5a:	1f 4f       	sbci	r17, 0xFF	; 255
     f5c:	c8 01       	movw	r24, r16
     f5e:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
				prvAddTaskToReadyList( pxTCB );
     f62:	8e 89       	ldd	r24, Y+22	; 0x16
     f64:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
     f68:	98 17       	cp	r25, r24
     f6a:	10 f4       	brcc	.+4      	; 0xf70 <xTaskGenericNotify+0x98>
     f6c:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
     f70:	29 e0       	ldi	r18, 0x09	; 9
     f72:	82 9f       	mul	r24, r18
     f74:	c0 01       	movw	r24, r0
     f76:	11 24       	eor	r1, r1
     f78:	b8 01       	movw	r22, r16
     f7a:	8a 59       	subi	r24, 0x9A	; 154
     f7c:	9e 4f       	sbci	r25, 0xFE	; 254
     f7e:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
     f82:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
     f86:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
     f8a:	9e 89       	ldd	r25, Y+22	; 0x16
     f8c:	86 89       	ldd	r24, Z+22	; 0x16
     f8e:	89 17       	cp	r24, r25
     f90:	10 f4       	brcc	.+4      	; 0xf96 <xTaskGenericNotify+0xbe>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					taskYIELD_IF_USING_PREEMPTION();
     f92:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
     f96:	81 e0       	ldi	r24, 0x01	; 1
     f98:	01 c0       	rjmp	.+2      	; 0xf9c <xTaskGenericNotify+0xc4>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
     f9a:	80 e0       	ldi	r24, 0x00	; 0
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
     f9c:	0f 90       	pop	r0
     f9e:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
     fa0:	df 91       	pop	r29
     fa2:	cf 91       	pop	r28
     fa4:	1f 91       	pop	r17
     fa6:	0f 91       	pop	r16
     fa8:	08 95       	ret

00000faa <xTaskGenericNotifyFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
	{
     faa:	ef 92       	push	r14
     fac:	ff 92       	push	r15
     fae:	0f 93       	push	r16
     fb0:	1f 93       	push	r17
     fb2:	cf 93       	push	r28
     fb4:	df 93       	push	r29
     fb6:	fc 01       	movw	r30, r24

		pxTCB = xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( pulPreviousNotificationValue != NULL )
     fb8:	01 15       	cp	r16, r1
     fba:	11 05       	cpc	r17, r1
     fbc:	49 f0       	breq	.+18     	; 0xfd0 <xTaskGenericNotifyFromISR+0x26>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
     fbe:	81 a1       	ldd	r24, Z+33	; 0x21
     fc0:	92 a1       	ldd	r25, Z+34	; 0x22
     fc2:	a3 a1       	ldd	r26, Z+35	; 0x23
     fc4:	b4 a1       	ldd	r27, Z+36	; 0x24
     fc6:	e8 01       	movw	r28, r16
     fc8:	88 83       	st	Y, r24
     fca:	99 83       	std	Y+1, r25	; 0x01
     fcc:	aa 83       	std	Y+2, r26	; 0x02
     fce:	bb 83       	std	Y+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
     fd0:	35 a1       	ldd	r19, Z+37	; 0x25
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
     fd2:	82 e0       	ldi	r24, 0x02	; 2
     fd4:	85 a3       	std	Z+37, r24	; 0x25

			switch( eAction )
     fd6:	22 30       	cpi	r18, 0x02	; 2
     fd8:	89 f0       	breq	.+34     	; 0xffc <xTaskGenericNotifyFromISR+0x52>
     fda:	58 f4       	brcc	.+22     	; 0xff2 <xTaskGenericNotifyFromISR+0x48>
     fdc:	21 30       	cpi	r18, 0x01	; 1
     fde:	01 f5       	brne	.+64     	; 0x1020 <xTaskGenericNotifyFromISR+0x76>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
     fe0:	81 a1       	ldd	r24, Z+33	; 0x21
     fe2:	92 a1       	ldd	r25, Z+34	; 0x22
     fe4:	a3 a1       	ldd	r26, Z+35	; 0x23
     fe6:	b4 a1       	ldd	r27, Z+36	; 0x24
     fe8:	48 2b       	or	r20, r24
     fea:	59 2b       	or	r21, r25
     fec:	6a 2b       	or	r22, r26
     fee:	7b 2b       	or	r23, r27
     ff0:	13 c0       	rjmp	.+38     	; 0x1018 <xTaskGenericNotifyFromISR+0x6e>
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;

			switch( eAction )
     ff2:	23 30       	cpi	r18, 0x03	; 3
     ff4:	89 f0       	breq	.+34     	; 0x1018 <xTaskGenericNotifyFromISR+0x6e>
     ff6:	24 30       	cpi	r18, 0x04	; 4
     ff8:	69 f0       	breq	.+26     	; 0x1014 <xTaskGenericNotifyFromISR+0x6a>
     ffa:	12 c0       	rjmp	.+36     	; 0x1020 <xTaskGenericNotifyFromISR+0x76>
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
					break;

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
     ffc:	81 a1       	ldd	r24, Z+33	; 0x21
     ffe:	92 a1       	ldd	r25, Z+34	; 0x22
    1000:	a3 a1       	ldd	r26, Z+35	; 0x23
    1002:	b4 a1       	ldd	r27, Z+36	; 0x24
    1004:	01 96       	adiw	r24, 0x01	; 1
    1006:	a1 1d       	adc	r26, r1
    1008:	b1 1d       	adc	r27, r1
    100a:	81 a3       	std	Z+33, r24	; 0x21
    100c:	92 a3       	std	Z+34, r25	; 0x22
    100e:	a3 a3       	std	Z+35, r26	; 0x23
    1010:	b4 a3       	std	Z+36, r27	; 0x24
					break;
    1012:	06 c0       	rjmp	.+12     	; 0x1020 <xTaskGenericNotifyFromISR+0x76>
				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
					break;

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    1014:	32 30       	cpi	r19, 0x02	; 2
    1016:	d9 f1       	breq	.+118    	; 0x108e <xTaskGenericNotifyFromISR+0xe4>
					{
						pxTCB->ulNotifiedValue = ulValue;
    1018:	41 a3       	std	Z+33, r20	; 0x21
    101a:	52 a3       	std	Z+34, r21	; 0x22
    101c:	63 a3       	std	Z+35, r22	; 0x23
    101e:	74 a3       	std	Z+36, r23	; 0x24

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    1020:	31 30       	cpi	r19, 0x01	; 1
    1022:	11 f0       	breq	.+4      	; 0x1028 <xTaskGenericNotifyFromISR+0x7e>
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
	{
    1024:	81 e0       	ldi	r24, 0x01	; 1
    1026:	34 c0       	rjmp	.+104    	; 0x1090 <xTaskGenericNotifyFromISR+0xe6>
    1028:	ef 01       	movw	r28, r30
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    102a:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
    102e:	81 11       	cpse	r24, r1
    1030:	15 c0       	rjmp	.+42     	; 0x105c <xTaskGenericNotifyFromISR+0xb2>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1032:	8f 01       	movw	r16, r30
    1034:	0e 5f       	subi	r16, 0xFE	; 254
    1036:	1f 4f       	sbci	r17, 0xFF	; 255
    1038:	c8 01       	movw	r24, r16
    103a:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    103e:	8e 89       	ldd	r24, Y+22	; 0x16
    1040:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
    1044:	98 17       	cp	r25, r24
    1046:	10 f4       	brcc	.+4      	; 0x104c <xTaskGenericNotifyFromISR+0xa2>
    1048:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
    104c:	e9 e0       	ldi	r30, 0x09	; 9
    104e:	8e 9f       	mul	r24, r30
    1050:	c0 01       	movw	r24, r0
    1052:	11 24       	eor	r1, r1
    1054:	b8 01       	movw	r22, r16
    1056:	8a 59       	subi	r24, 0x9A	; 154
    1058:	9e 4f       	sbci	r25, 0xFE	; 254
    105a:	05 c0       	rjmp	.+10     	; 0x1066 <xTaskGenericNotifyFromISR+0xbc>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    105c:	bf 01       	movw	r22, r30
    105e:	64 5f       	subi	r22, 0xF4	; 244
    1060:	7f 4f       	sbci	r23, 0xFF	; 255
    1062:	87 e4       	ldi	r24, 0x47	; 71
    1064:	91 e0       	ldi	r25, 0x01	; 1
    1066:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    106a:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
    106e:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
    1072:	9e 89       	ldd	r25, Y+22	; 0x16
    1074:	86 89       	ldd	r24, Z+22	; 0x16
    1076:	89 17       	cp	r24, r25
    1078:	a8 f6       	brcc	.-86     	; 0x1024 <xTaskGenericNotifyFromISR+0x7a>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    107a:	e1 14       	cp	r14, r1
    107c:	f1 04       	cpc	r15, r1
    107e:	19 f0       	breq	.+6      	; 0x1086 <xTaskGenericNotifyFromISR+0xdc>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    1080:	81 e0       	ldi	r24, 0x01	; 1
    1082:	e7 01       	movw	r28, r14
    1084:	88 83       	st	Y, r24
					}

					/* Mark that a yield is pending in case the user is not
					using the "xHigherPriorityTaskWoken" parameter to an ISR
					safe FreeRTOS function. */
					xYieldPending = pdTRUE;
    1086:	81 e0       	ldi	r24, 0x01	; 1
    1088:	80 93 2d 01 	sts	0x012D, r24	; 0x80012d <xYieldPending>
    108c:	01 c0       	rjmp	.+2      	; 0x1090 <xTaskGenericNotifyFromISR+0xe6>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    108e:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xReturn;
	}
    1090:	df 91       	pop	r29
    1092:	cf 91       	pop	r28
    1094:	1f 91       	pop	r17
    1096:	0f 91       	pop	r16
    1098:	ff 90       	pop	r15
    109a:	ef 90       	pop	r14
    109c:	08 95       	ret

0000109e <vTaskNotifyGiveFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken )
	{
    109e:	ef 92       	push	r14
    10a0:	ff 92       	push	r15
    10a2:	0f 93       	push	r16
    10a4:	1f 93       	push	r17
    10a6:	cf 93       	push	r28
    10a8:	df 93       	push	r29
    10aa:	fc 01       	movw	r30, r24

		pxTCB = xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			ucOriginalNotifyState = pxTCB->ucNotifyState;
    10ac:	25 a1       	ldd	r18, Z+37	; 0x25
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    10ae:	82 e0       	ldi	r24, 0x02	; 2
    10b0:	85 a3       	std	Z+37, r24	; 0x25

			/* 'Giving' is equivalent to incrementing a count in a counting
			semaphore. */
			( pxTCB->ulNotifiedValue )++;
    10b2:	81 a1       	ldd	r24, Z+33	; 0x21
    10b4:	92 a1       	ldd	r25, Z+34	; 0x22
    10b6:	a3 a1       	ldd	r26, Z+35	; 0x23
    10b8:	b4 a1       	ldd	r27, Z+36	; 0x24
    10ba:	01 96       	adiw	r24, 0x01	; 1
    10bc:	a1 1d       	adc	r26, r1
    10be:	b1 1d       	adc	r27, r1
    10c0:	81 a3       	std	Z+33, r24	; 0x21
    10c2:	92 a3       	std	Z+34, r25	; 0x22
    10c4:	a3 a3       	std	Z+35, r26	; 0x23
    10c6:	b4 a3       	std	Z+36, r27	; 0x24

			traceTASK_NOTIFY_GIVE_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    10c8:	21 30       	cpi	r18, 0x01	; 1
    10ca:	a1 f5       	brne	.+104    	; 0x1134 <vTaskNotifyGiveFromISR+0x96>
    10cc:	8b 01       	movw	r16, r22
    10ce:	ef 01       	movw	r28, r30
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    10d0:	80 91 26 01 	lds	r24, 0x0126	; 0x800126 <uxSchedulerSuspended>
    10d4:	81 11       	cpse	r24, r1
    10d6:	16 c0       	rjmp	.+44     	; 0x1104 <vTaskNotifyGiveFromISR+0x66>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    10d8:	7f 01       	movw	r14, r30
    10da:	22 e0       	ldi	r18, 0x02	; 2
    10dc:	e2 0e       	add	r14, r18
    10de:	f1 1c       	adc	r15, r1
    10e0:	c7 01       	movw	r24, r14
    10e2:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    10e6:	8e 89       	ldd	r24, Y+22	; 0x16
    10e8:	90 91 30 01 	lds	r25, 0x0130	; 0x800130 <uxTopReadyPriority>
    10ec:	98 17       	cp	r25, r24
    10ee:	10 f4       	brcc	.+4      	; 0x10f4 <vTaskNotifyGiveFromISR+0x56>
    10f0:	80 93 30 01 	sts	0x0130, r24	; 0x800130 <uxTopReadyPriority>
    10f4:	e9 e0       	ldi	r30, 0x09	; 9
    10f6:	8e 9f       	mul	r24, r30
    10f8:	c0 01       	movw	r24, r0
    10fa:	11 24       	eor	r1, r1
    10fc:	b7 01       	movw	r22, r14
    10fe:	8a 59       	subi	r24, 0x9A	; 154
    1100:	9e 4f       	sbci	r25, 0xFE	; 254
    1102:	05 c0       	rjmp	.+10     	; 0x110e <vTaskNotifyGiveFromISR+0x70>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    1104:	bf 01       	movw	r22, r30
    1106:	64 5f       	subi	r22, 0xF4	; 244
    1108:	7f 4f       	sbci	r23, 0xFF	; 255
    110a:	87 e4       	ldi	r24, 0x47	; 71
    110c:	91 e0       	ldi	r25, 0x01	; 1
    110e:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    1112:	e0 91 24 01 	lds	r30, 0x0124	; 0x800124 <__data_end>
    1116:	f0 91 25 01 	lds	r31, 0x0125	; 0x800125 <__data_end+0x1>
    111a:	9e 89       	ldd	r25, Y+22	; 0x16
    111c:	86 89       	ldd	r24, Z+22	; 0x16
    111e:	89 17       	cp	r24, r25
    1120:	48 f4       	brcc	.+18     	; 0x1134 <vTaskNotifyGiveFromISR+0x96>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    1122:	01 15       	cp	r16, r1
    1124:	11 05       	cpc	r17, r1
    1126:	19 f0       	breq	.+6      	; 0x112e <vTaskNotifyGiveFromISR+0x90>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    1128:	81 e0       	ldi	r24, 0x01	; 1
    112a:	f8 01       	movw	r30, r16
    112c:	80 83       	st	Z, r24
					}

					/* Mark that a yield is pending in case the user is not
					using the "xHigherPriorityTaskWoken" parameter in an ISR
					safe FreeRTOS function. */
					xYieldPending = pdTRUE;
    112e:	81 e0       	ldi	r24, 0x01	; 1
    1130:	80 93 2d 01 	sts	0x012D, r24	; 0x80012d <xYieldPending>
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
	}
    1134:	df 91       	pop	r29
    1136:	cf 91       	pop	r28
    1138:	1f 91       	pop	r17
    113a:	0f 91       	pop	r16
    113c:	ff 90       	pop	r15
    113e:	ef 90       	pop	r14
    1140:	08 95       	ret

00001142 <xTaskNotifyStateClear>:
	TCB_t *pxTCB;
	BaseType_t xReturn;

		/* If null is passed in here then it is the calling task that is having
		its notification state cleared. */
		pxTCB = prvGetTCBFromHandle( xTask );
    1142:	00 97       	sbiw	r24, 0x00	; 0
    1144:	21 f4       	brne	.+8      	; 0x114e <xTaskNotifyStateClear+0xc>
    1146:	80 91 24 01 	lds	r24, 0x0124	; 0x800124 <__data_end>
    114a:	90 91 25 01 	lds	r25, 0x0125	; 0x800125 <__data_end+0x1>

		taskENTER_CRITICAL();
    114e:	0f b6       	in	r0, 0x3f	; 63
    1150:	f8 94       	cli
    1152:	0f 92       	push	r0
		{
			if( pxTCB->ucNotifyState == taskNOTIFICATION_RECEIVED )
    1154:	fc 01       	movw	r30, r24
    1156:	25 a1       	ldd	r18, Z+37	; 0x25
    1158:	22 30       	cpi	r18, 0x02	; 2
    115a:	19 f4       	brne	.+6      	; 0x1162 <xTaskNotifyStateClear+0x20>
			{
				pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    115c:	15 a2       	std	Z+37, r1	; 0x25
				xReturn = pdPASS;
    115e:	81 e0       	ldi	r24, 0x01	; 1
    1160:	01 c0       	rjmp	.+2      	; 0x1164 <xTaskNotifyStateClear+0x22>
			}
			else
			{
				xReturn = pdFAIL;
    1162:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		taskEXIT_CRITICAL();
    1164:	0f 90       	pop	r0
    1166:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    1168:	08 95       	ret

0000116a <prvIsQueueEmpty>:

static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
    116a:	0f b6       	in	r0, 0x3f	; 63
    116c:	f8 94       	cli
    116e:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
    1170:	fc 01       	movw	r30, r24
    1172:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
    1174:	0f 90       	pop	r0
    1176:	0f be       	out	0x3f, r0	; 63

	return xReturn;
    1178:	81 e0       	ldi	r24, 0x01	; 1
    117a:	91 11       	cpse	r25, r1
    117c:	80 e0       	ldi	r24, 0x00	; 0
}
    117e:	08 95       	ret

00001180 <prvCopyDataToQueue>:

#endif /* configUSE_MUTEXES */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
    1180:	0f 93       	push	r16
    1182:	1f 93       	push	r17
    1184:	cf 93       	push	r28
    1186:	df 93       	push	r29
    1188:	ec 01       	movw	r28, r24
    118a:	04 2f       	mov	r16, r20
BaseType_t xReturn = pdFALSE;
UBaseType_t uxMessagesWaiting;

	/* This function is called from a critical section. */

	uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    118c:	1a 8d       	ldd	r17, Y+26	; 0x1a

	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
    118e:	4c 8d       	ldd	r20, Y+28	; 0x1c
    1190:	44 23       	and	r20, r20
    1192:	b1 f1       	breq	.+108    	; 0x1200 <prvCopyDataToQueue+0x80>
    1194:	50 e0       	ldi	r21, 0x00	; 0
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_MUTEXES */
	}
	else if( xPosition == queueSEND_TO_BACK )
    1196:	01 11       	cpse	r16, r1
    1198:	15 c0       	rjmp	.+42     	; 0x11c4 <prvCopyDataToQueue+0x44>
	{
		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 !e9087 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0.  Cast to void required by function signature and safe as no alignment requirement and copy length specified in bytes. */
    119a:	8a 81       	ldd	r24, Y+2	; 0x02
    119c:	9b 81       	ldd	r25, Y+3	; 0x03
    119e:	0e 94 2a 12 	call	0x2454	; 0x2454 <memcpy>
		pxQueue->pcWriteTo += pxQueue->uxItemSize; /*lint !e9016 Pointer arithmetic on char types ok, especially in this use case where it is the clearest way of conveying intent. */
    11a2:	2c 8d       	ldd	r18, Y+28	; 0x1c
    11a4:	8a 81       	ldd	r24, Y+2	; 0x02
    11a6:	9b 81       	ldd	r25, Y+3	; 0x03
    11a8:	82 0f       	add	r24, r18
    11aa:	91 1d       	adc	r25, r1
    11ac:	9b 83       	std	Y+3, r25	; 0x03
    11ae:	8a 83       	std	Y+2, r24	; 0x02
		if( pxQueue->pcWriteTo >= pxQueue->u.xQueue.pcTail ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
    11b0:	2c 81       	ldd	r18, Y+4	; 0x04
    11b2:	3d 81       	ldd	r19, Y+5	; 0x05
    11b4:	82 17       	cp	r24, r18
    11b6:	93 07       	cpc	r25, r19
    11b8:	18 f1       	brcs	.+70     	; 0x1200 <prvCopyDataToQueue+0x80>
		{
			pxQueue->pcWriteTo = pxQueue->pcHead;
    11ba:	88 81       	ld	r24, Y
    11bc:	99 81       	ldd	r25, Y+1	; 0x01
    11be:	9b 83       	std	Y+3, r25	; 0x03
    11c0:	8a 83       	std	Y+2, r24	; 0x02
    11c2:	1e c0       	rjmp	.+60     	; 0x1200 <prvCopyDataToQueue+0x80>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	else
	{
		( void ) memcpy( ( void * ) pxQueue->u.xQueue.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e9087 !e418 MISRA exception as the casts are only redundant for some ports.  Cast to void required by function signature and safe as no alignment requirement and copy length specified in bytes.  Assert checks null pointer only used when length is 0. */
    11c4:	8e 81       	ldd	r24, Y+6	; 0x06
    11c6:	9f 81       	ldd	r25, Y+7	; 0x07
    11c8:	0e 94 2a 12 	call	0x2454	; 0x2454 <memcpy>
		pxQueue->u.xQueue.pcReadFrom -= pxQueue->uxItemSize;
    11cc:	8c 8d       	ldd	r24, Y+28	; 0x1c
    11ce:	90 e0       	ldi	r25, 0x00	; 0
    11d0:	91 95       	neg	r25
    11d2:	81 95       	neg	r24
    11d4:	91 09       	sbc	r25, r1
    11d6:	2e 81       	ldd	r18, Y+6	; 0x06
    11d8:	3f 81       	ldd	r19, Y+7	; 0x07
    11da:	28 0f       	add	r18, r24
    11dc:	39 1f       	adc	r19, r25
    11de:	3f 83       	std	Y+7, r19	; 0x07
    11e0:	2e 83       	std	Y+6, r18	; 0x06
		if( pxQueue->u.xQueue.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
    11e2:	48 81       	ld	r20, Y
    11e4:	59 81       	ldd	r21, Y+1	; 0x01
    11e6:	24 17       	cp	r18, r20
    11e8:	35 07       	cpc	r19, r21
    11ea:	30 f4       	brcc	.+12     	; 0x11f8 <prvCopyDataToQueue+0x78>
		{
			pxQueue->u.xQueue.pcReadFrom = ( pxQueue->u.xQueue.pcTail - pxQueue->uxItemSize );
    11ec:	2c 81       	ldd	r18, Y+4	; 0x04
    11ee:	3d 81       	ldd	r19, Y+5	; 0x05
    11f0:	82 0f       	add	r24, r18
    11f2:	93 1f       	adc	r25, r19
    11f4:	9f 83       	std	Y+7, r25	; 0x07
    11f6:	8e 83       	std	Y+6, r24	; 0x06
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( xPosition == queueOVERWRITE )
    11f8:	02 30       	cpi	r16, 0x02	; 2
    11fa:	11 f4       	brne	.+4      	; 0x1200 <prvCopyDataToQueue+0x80>
		{
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    11fc:	11 11       	cpse	r17, r1
			{
				/* An item is not being added but overwritten, so subtract
				one from the recorded number of items in the queue so when
				one is added again below the number of recorded items remains
				correct. */
				--uxMessagesWaiting;
    11fe:	11 50       	subi	r17, 0x01	; 1
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}

	pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
    1200:	1f 5f       	subi	r17, 0xFF	; 255
    1202:	1a 8f       	std	Y+26, r17	; 0x1a

	return xReturn;
}
    1204:	80 e0       	ldi	r24, 0x00	; 0
    1206:	df 91       	pop	r29
    1208:	cf 91       	pop	r28
    120a:	1f 91       	pop	r17
    120c:	0f 91       	pop	r16
    120e:	08 95       	ret

00001210 <prvCopyDataFromQueue>:
/*-----------------------------------------------------------*/

static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
{
    1210:	fc 01       	movw	r30, r24
    1212:	cb 01       	movw	r24, r22
	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
    1214:	44 8d       	ldd	r20, Z+28	; 0x1c
    1216:	44 23       	and	r20, r20
    1218:	a1 f0       	breq	.+40     	; 0x1242 <prvCopyDataFromQueue+0x32>
	{
		pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize; /*lint !e9016 Pointer arithmetic on char types ok, especially in this use case where it is the clearest way of conveying intent. */
    121a:	50 e0       	ldi	r21, 0x00	; 0
    121c:	26 81       	ldd	r18, Z+6	; 0x06
    121e:	37 81       	ldd	r19, Z+7	; 0x07
    1220:	24 0f       	add	r18, r20
    1222:	35 1f       	adc	r19, r21
    1224:	37 83       	std	Z+7, r19	; 0x07
    1226:	26 83       	std	Z+6, r18	; 0x06
		if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail ) /*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
    1228:	64 81       	ldd	r22, Z+4	; 0x04
    122a:	75 81       	ldd	r23, Z+5	; 0x05
    122c:	26 17       	cp	r18, r22
    122e:	37 07       	cpc	r19, r23
    1230:	20 f0       	brcs	.+8      	; 0x123a <prvCopyDataFromQueue+0x2a>
		{
			pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
    1232:	20 81       	ld	r18, Z
    1234:	31 81       	ldd	r19, Z+1	; 0x01
    1236:	37 83       	std	Z+7, r19	; 0x07
    1238:	26 83       	std	Z+6, r18	; 0x06
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 !e9087 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0.  Cast to void required by function signature and safe as no alignment requirement and copy length specified in bytes. */
    123a:	66 81       	ldd	r22, Z+6	; 0x06
    123c:	77 81       	ldd	r23, Z+7	; 0x07
    123e:	0c 94 2a 12 	jmp	0x2454	; 0x2454 <memcpy>
    1242:	08 95       	ret

00001244 <prvUnlockQueue>:
	}
}
/*-----------------------------------------------------------*/

static void prvUnlockQueue( Queue_t * const pxQueue )
{
    1244:	ef 92       	push	r14
    1246:	ff 92       	push	r15
    1248:	1f 93       	push	r17
    124a:	cf 93       	push	r28
    124c:	df 93       	push	r29
    124e:	ec 01       	movw	r28, r24

	/* The lock counts contains the number of extra data items placed or
	removed from the queue while the queue was locked.  When a queue is
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
    1250:	0f b6       	in	r0, 0x3f	; 63
    1252:	f8 94       	cli
    1254:	0f 92       	push	r0
	{
		int8_t cTxLock = pxQueue->cTxLock;
    1256:	1e 8d       	ldd	r17, Y+30	; 0x1e
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    1258:	7c 01       	movw	r14, r24
    125a:	81 e1       	ldi	r24, 0x11	; 17
    125c:	e8 0e       	add	r14, r24
    125e:	f1 1c       	adc	r15, r1
	taskENTER_CRITICAL();
	{
		int8_t cTxLock = pxQueue->cTxLock;

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
    1260:	11 16       	cp	r1, r17
    1262:	5c f4       	brge	.+22     	; 0x127a <prvUnlockQueue+0x36>
			}
			#else /* configUSE_QUEUE_SETS */
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1264:	89 89       	ldd	r24, Y+17	; 0x11
    1266:	88 23       	and	r24, r24
    1268:	41 f0       	breq	.+16     	; 0x127a <prvUnlockQueue+0x36>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    126a:	c7 01       	movw	r24, r14
    126c:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    1270:	81 11       	cpse	r24, r1
					{
						/* The task waiting has a higher priority so record that
						a context switch is required. */
						vTaskMissedYield();
    1272:	0e 94 78 06 	call	0xcf0	; 0xcf0 <vTaskMissedYield>
    1276:	11 50       	subi	r17, 0x01	; 1
    1278:	f3 cf       	rjmp	.-26     	; 0x1260 <prvUnlockQueue+0x1c>
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
		}

		pxQueue->cTxLock = queueUNLOCKED;
    127a:	8f ef       	ldi	r24, 0xFF	; 255
    127c:	8e 8f       	std	Y+30, r24	; 0x1e
	}
	taskEXIT_CRITICAL();
    127e:	0f 90       	pop	r0
    1280:	0f be       	out	0x3f, r0	; 63

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
    1282:	0f b6       	in	r0, 0x3f	; 63
    1284:	f8 94       	cli
    1286:	0f 92       	push	r0
	{
		int8_t cRxLock = pxQueue->cRxLock;
    1288:	1d 8d       	ldd	r17, Y+29	; 0x1d

		while( cRxLock > queueLOCKED_UNMODIFIED )
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    128a:	7e 01       	movw	r14, r28
    128c:	88 e0       	ldi	r24, 0x08	; 8
    128e:	e8 0e       	add	r14, r24
    1290:	f1 1c       	adc	r15, r1
	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		int8_t cRxLock = pxQueue->cRxLock;

		while( cRxLock > queueLOCKED_UNMODIFIED )
    1292:	11 16       	cp	r1, r17
    1294:	5c f4       	brge	.+22     	; 0x12ac <prvUnlockQueue+0x68>
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    1296:	88 85       	ldd	r24, Y+8	; 0x08
    1298:	88 23       	and	r24, r24
    129a:	41 f0       	breq	.+16     	; 0x12ac <prvUnlockQueue+0x68>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    129c:	c7 01       	movw	r24, r14
    129e:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    12a2:	81 11       	cpse	r24, r1
				{
					vTaskMissedYield();
    12a4:	0e 94 78 06 	call	0xcf0	; 0xcf0 <vTaskMissedYield>
    12a8:	11 50       	subi	r17, 0x01	; 1
    12aa:	f3 cf       	rjmp	.-26     	; 0x1292 <prvUnlockQueue+0x4e>
			{
				break;
			}
		}

		pxQueue->cRxLock = queueUNLOCKED;
    12ac:	8f ef       	ldi	r24, 0xFF	; 255
    12ae:	8d 8f       	std	Y+29, r24	; 0x1d
	}
	taskEXIT_CRITICAL();
    12b0:	0f 90       	pop	r0
    12b2:	0f be       	out	0x3f, r0	; 63
}
    12b4:	df 91       	pop	r29
    12b6:	cf 91       	pop	r28
    12b8:	1f 91       	pop	r17
    12ba:	ff 90       	pop	r15
    12bc:	ef 90       	pop	r14
    12be:	08 95       	ret

000012c0 <xQueueGenericReset>:
	}														\
	taskEXIT_CRITICAL()
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
{
    12c0:	cf 93       	push	r28
    12c2:	df 93       	push	r29
    12c4:	ec 01       	movw	r28, r24
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
    12c6:	0f b6       	in	r0, 0x3f	; 63
    12c8:	f8 94       	cli
    12ca:	0f 92       	push	r0
	{
		pxQueue->u.xQueue.pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */
    12cc:	48 81       	ld	r20, Y
    12ce:	59 81       	ldd	r21, Y+1	; 0x01
    12d0:	8b 8d       	ldd	r24, Y+27	; 0x1b
    12d2:	7c 8d       	ldd	r23, Y+28	; 0x1c
    12d4:	9a 01       	movw	r18, r20
    12d6:	87 9f       	mul	r24, r23
    12d8:	20 0d       	add	r18, r0
    12da:	31 1d       	adc	r19, r1
    12dc:	11 24       	eor	r1, r1
    12de:	3d 83       	std	Y+5, r19	; 0x05
    12e0:	2c 83       	std	Y+4, r18	; 0x04
		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
    12e2:	1a 8e       	std	Y+26, r1	; 0x1a
		pxQueue->pcWriteTo = pxQueue->pcHead;
    12e4:	5b 83       	std	Y+3, r21	; 0x03
    12e6:	4a 83       	std	Y+2, r20	; 0x02
		pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - 1U ) * pxQueue->uxItemSize ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */
    12e8:	90 e0       	ldi	r25, 0x00	; 0
    12ea:	01 97       	sbiw	r24, 0x01	; 1
    12ec:	78 9f       	mul	r23, r24
    12ee:	90 01       	movw	r18, r0
    12f0:	79 9f       	mul	r23, r25
    12f2:	30 0d       	add	r19, r0
    12f4:	11 24       	eor	r1, r1
    12f6:	ca 01       	movw	r24, r20
    12f8:	82 0f       	add	r24, r18
    12fa:	93 1f       	adc	r25, r19
    12fc:	9f 83       	std	Y+7, r25	; 0x07
    12fe:	8e 83       	std	Y+6, r24	; 0x06
		pxQueue->cRxLock = queueUNLOCKED;
    1300:	8f ef       	ldi	r24, 0xFF	; 255
    1302:	8d 8f       	std	Y+29, r24	; 0x1d
		pxQueue->cTxLock = queueUNLOCKED;
    1304:	8e 8f       	std	Y+30, r24	; 0x1e

		if( xNewQueue == pdFALSE )
    1306:	61 11       	cpse	r22, r1
    1308:	0c c0       	rjmp	.+24     	; 0x1322 <xQueueGenericReset+0x62>
			/* If there are tasks blocked waiting to read from the queue, then
			the tasks will remain blocked as after this function exits the queue
			will still be empty.  If there are tasks blocked waiting to write to
			the queue, then one should be unblocked as after this function exits
			it will be possible to write to it. */
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    130a:	88 85       	ldd	r24, Y+8	; 0x08
    130c:	88 23       	and	r24, r24
    130e:	89 f0       	breq	.+34     	; 0x1332 <xQueueGenericReset+0x72>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    1310:	ce 01       	movw	r24, r28
    1312:	08 96       	adiw	r24, 0x08	; 8
    1314:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    1318:	88 23       	and	r24, r24
    131a:	59 f0       	breq	.+22     	; 0x1332 <xQueueGenericReset+0x72>
				{
					queueYIELD_IF_USING_PREEMPTION();
    131c:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
    1320:	08 c0       	rjmp	.+16     	; 0x1332 <xQueueGenericReset+0x72>
			}
		}
		else
		{
			/* Ensure the event queues start in the correct state. */
			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
    1322:	ce 01       	movw	r24, r28
    1324:	08 96       	adiw	r24, 0x08	; 8
    1326:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
    132a:	ce 01       	movw	r24, r28
    132c:	41 96       	adiw	r24, 0x11	; 17
    132e:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
		}
	}
	taskEXIT_CRITICAL();
    1332:	0f 90       	pop	r0
    1334:	0f be       	out	0x3f, r0	; 63

	/* A value is returned for calling semantic consistency with previous
	versions. */
	return pdPASS;
}
    1336:	81 e0       	ldi	r24, 0x01	; 1
    1338:	df 91       	pop	r29
    133a:	cf 91       	pop	r28
    133c:	08 95       	ret

0000133e <xQueueGenericCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
	{
    133e:	0f 93       	push	r16
    1340:	1f 93       	push	r17
    1342:	cf 93       	push	r28
    1344:	df 93       	push	r29
    1346:	08 2f       	mov	r16, r24
    1348:	16 2f       	mov	r17, r22
	size_t xQueueSizeInBytes;
	uint8_t *pucQueueStorage;

		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
    134a:	66 23       	and	r22, r22
    134c:	21 f0       	breq	.+8      	; 0x1356 <xQueueGenericCreate+0x18>
		}
		else
		{
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    134e:	86 9f       	mul	r24, r22
    1350:	c0 01       	movw	r24, r0
    1352:	11 24       	eor	r1, r1
    1354:	02 c0       	rjmp	.+4      	; 0x135a <xQueueGenericCreate+0x1c>
		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
		{
			/* There is not going to be a queue storage area. */
			xQueueSizeInBytes = ( size_t ) 0;
    1356:	80 e0       	ldi	r24, 0x00	; 0
    1358:	90 e0       	ldi	r25, 0x00	; 0
		alignment requirements of the Queue_t structure - which in this case
		is an int8_t *.  Therefore, whenever the stack alignment requirements
		are greater than or equal to the pointer to char requirements the cast
		is safe.  In other cases alignment requirements are not strict (one or
		two bytes). */
		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes ); /*lint !e9087 !e9079 see comment above. */
    135a:	4f 96       	adiw	r24, 0x1f	; 31
    135c:	0e 94 f6 0f 	call	0x1fec	; 0x1fec <pvPortMalloc>
    1360:	ec 01       	movw	r28, r24

		if( pxNewQueue != NULL )
    1362:	00 97       	sbiw	r24, 0x00	; 0
    1364:	71 f0       	breq	.+28     	; 0x1382 <xQueueGenericCreate+0x44>
{
	/* Remove compiler warnings about unused parameters should
	configUSE_TRACE_FACILITY not be set to 1. */
	( void ) ucQueueType;

	if( uxItemSize == ( UBaseType_t ) 0 )
    1366:	11 11       	cpse	r17, r1
    1368:	03 c0       	rjmp	.+6      	; 0x1370 <xQueueGenericCreate+0x32>
	{
		/* No RAM was allocated for the queue storage area, but PC head cannot
		be set to NULL because NULL is used as a key to say the queue is used as
		a mutex.  Therefore just set pcHead to point to the queue as a benign
		value that is known to be within the memory map. */
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
    136a:	99 83       	std	Y+1, r25	; 0x01
    136c:	88 83       	st	Y, r24
    136e:	03 c0       	rjmp	.+6      	; 0x1376 <xQueueGenericCreate+0x38>
	}
	else
	{
		/* Set the head to the start of the queue storage area. */
		pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;
    1370:	4f 96       	adiw	r24, 0x1f	; 31
    1372:	99 83       	std	Y+1, r25	; 0x01
    1374:	88 83       	st	Y, r24
	}

	/* Initialise the queue members as described where the queue type is
	defined. */
	pxNewQueue->uxLength = uxQueueLength;
    1376:	0b 8f       	std	Y+27, r16	; 0x1b
	pxNewQueue->uxItemSize = uxItemSize;
    1378:	1c 8f       	std	Y+28, r17	; 0x1c
	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
    137a:	61 e0       	ldi	r22, 0x01	; 1
    137c:	ce 01       	movw	r24, r28
    137e:	0e 94 60 09 	call	0x12c0	; 0x12c0 <xQueueGenericReset>
			traceQUEUE_CREATE_FAILED( ucQueueType );
			mtCOVERAGE_TEST_MARKER();
		}

		return pxNewQueue;
	}
    1382:	ce 01       	movw	r24, r28
    1384:	df 91       	pop	r29
    1386:	cf 91       	pop	r28
    1388:	1f 91       	pop	r17
    138a:	0f 91       	pop	r16
    138c:	08 95       	ret

0000138e <xQueueGenericSend>:

#endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
{
    138e:	af 92       	push	r10
    1390:	bf 92       	push	r11
    1392:	cf 92       	push	r12
    1394:	df 92       	push	r13
    1396:	ff 92       	push	r15
    1398:	0f 93       	push	r16
    139a:	1f 93       	push	r17
    139c:	cf 93       	push	r28
    139e:	df 93       	push	r29
    13a0:	00 d0       	rcall	.+0      	; 0x13a2 <xQueueGenericSend+0x14>
    13a2:	00 d0       	rcall	.+0      	; 0x13a4 <xQueueGenericSend+0x16>
    13a4:	1f 92       	push	r1
    13a6:	cd b7       	in	r28, 0x3d	; 61
    13a8:	de b7       	in	r29, 0x3e	; 62
    13aa:	8c 01       	movw	r16, r24
    13ac:	6b 01       	movw	r12, r22
    13ae:	5d 83       	std	Y+5, r21	; 0x05
    13b0:	4c 83       	std	Y+4, r20	; 0x04
    13b2:	f2 2e       	mov	r15, r18
BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
    13b4:	80 e0       	ldi	r24, 0x00	; 0
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
    13b6:	58 01       	movw	r10, r16
    13b8:	98 e0       	ldi	r25, 0x08	; 8
    13ba:	a9 0e       	add	r10, r25
    13bc:	b1 1c       	adc	r11, r1
	/*lint -save -e904 This function relaxes the coding standard somewhat to
	allow return statements within the function itself.  This is done in the
	interest of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    13be:	0f b6       	in	r0, 0x3f	; 63
    13c0:	f8 94       	cli
    13c2:	0f 92       	push	r0
		{
			/* Is there room on the queue now?  The running task must be the
			highest priority task wanting to access the queue.  If the head item
			in the queue is to be overwritten then it does not matter if the
			queue is full. */
			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
    13c4:	f8 01       	movw	r30, r16
    13c6:	22 8d       	ldd	r18, Z+26	; 0x1a
    13c8:	93 8d       	ldd	r25, Z+27	; 0x1b
    13ca:	29 17       	cp	r18, r25
    13cc:	18 f0       	brcs	.+6      	; 0x13d4 <xQueueGenericSend+0x46>
    13ce:	f2 e0       	ldi	r31, 0x02	; 2
    13d0:	ff 12       	cpse	r15, r31
    13d2:	14 c0       	rjmp	.+40     	; 0x13fc <xQueueGenericSend+0x6e>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
    13d4:	4f 2d       	mov	r20, r15
    13d6:	b6 01       	movw	r22, r12
    13d8:	c8 01       	movw	r24, r16
    13da:	0e 94 c0 08 	call	0x1180	; 0x1180 <prvCopyDataToQueue>

					/* If there was a task waiting for data to arrive on the
					queue then unblock it now. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    13de:	f8 01       	movw	r30, r16
    13e0:	91 89       	ldd	r25, Z+17	; 0x11
    13e2:	99 23       	and	r25, r25
    13e4:	21 f0       	breq	.+8      	; 0x13ee <xQueueGenericSend+0x60>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    13e6:	c8 01       	movw	r24, r16
    13e8:	41 96       	adiw	r24, 0x11	; 17
    13ea:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    13ee:	81 11       	cpse	r24, r1
						{
							/* The unblocked task has a priority higher than
							our own so yield immediately.  Yes it is ok to do
							this from within the critical section - the kernel
							takes care of that. */
							queueYIELD_IF_USING_PREEMPTION();
    13f0:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif /* configUSE_QUEUE_SETS */

				taskEXIT_CRITICAL();
    13f4:	0f 90       	pop	r0
    13f6:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    13f8:	81 e0       	ldi	r24, 0x01	; 1
    13fa:	50 c0       	rjmp	.+160    	; 0x149c <xQueueGenericSend+0x10e>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    13fc:	2c 81       	ldd	r18, Y+4	; 0x04
    13fe:	3d 81       	ldd	r19, Y+5	; 0x05
    1400:	23 2b       	or	r18, r19
    1402:	19 f4       	brne	.+6      	; 0x140a <xQueueGenericSend+0x7c>
				{
					/* The queue was full and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    1404:	0f 90       	pop	r0
    1406:	0f be       	out	0x3f, r0	; 63
    1408:	48 c0       	rjmp	.+144    	; 0x149a <xQueueGenericSend+0x10c>
					/* Return to the original privilege level before exiting
					the function. */
					traceQUEUE_SEND_FAILED( pxQueue );
					return errQUEUE_FULL;
				}
				else if( xEntryTimeSet == pdFALSE )
    140a:	81 11       	cpse	r24, r1
    140c:	04 c0       	rjmp	.+8      	; 0x1416 <xQueueGenericSend+0x88>
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    140e:	ce 01       	movw	r24, r28
    1410:	01 96       	adiw	r24, 0x01	; 1
    1412:	0e 94 3a 06 	call	0xc74	; 0xc74 <vTaskInternalSetTimeOutState>
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    1416:	0f 90       	pop	r0
    1418:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    141a:	0e 94 6e 03 	call	0x6dc	; 0x6dc <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    141e:	0f b6       	in	r0, 0x3f	; 63
    1420:	f8 94       	cli
    1422:	0f 92       	push	r0
    1424:	f8 01       	movw	r30, r16
    1426:	85 8d       	ldd	r24, Z+29	; 0x1d
    1428:	8f 3f       	cpi	r24, 0xFF	; 255
    142a:	09 f4       	brne	.+2      	; 0x142e <xQueueGenericSend+0xa0>
    142c:	15 8e       	std	Z+29, r1	; 0x1d
    142e:	f8 01       	movw	r30, r16
    1430:	86 8d       	ldd	r24, Z+30	; 0x1e
    1432:	8f 3f       	cpi	r24, 0xFF	; 255
    1434:	09 f4       	brne	.+2      	; 0x1438 <xQueueGenericSend+0xaa>
    1436:	16 8e       	std	Z+30, r1	; 0x1e
    1438:	0f 90       	pop	r0
    143a:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    143c:	be 01       	movw	r22, r28
    143e:	6c 5f       	subi	r22, 0xFC	; 252
    1440:	7f 4f       	sbci	r23, 0xFF	; 255
    1442:	ce 01       	movw	r24, r28
    1444:	01 96       	adiw	r24, 0x01	; 1
    1446:	0e 94 45 06 	call	0xc8a	; 0xc8a <xTaskCheckForTimeOut>
    144a:	81 11       	cpse	r24, r1
    144c:	21 c0       	rjmp	.+66     	; 0x1490 <xQueueGenericSend+0x102>

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
    144e:	0f b6       	in	r0, 0x3f	; 63
    1450:	f8 94       	cli
    1452:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
    1454:	f8 01       	movw	r30, r16
    1456:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
    1458:	0f 90       	pop	r0
    145a:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
    145c:	83 8d       	ldd	r24, Z+27	; 0x1b
    145e:	98 13       	cpse	r25, r24
    1460:	11 c0       	rjmp	.+34     	; 0x1484 <xQueueGenericSend+0xf6>
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
    1462:	6c 81       	ldd	r22, Y+4	; 0x04
    1464:	7d 81       	ldd	r23, Y+5	; 0x05
    1466:	c5 01       	movw	r24, r10
    1468:	0e 94 8f 05 	call	0xb1e	; 0xb1e <vTaskPlaceOnEventList>
				/* Unlocking the queue means queue events can effect the
				event list.  It is possible that interrupts occurring now
				remove this task from the event list again - but as the
				scheduler is suspended the task will go onto the pending
				ready last instead of the actual ready list. */
				prvUnlockQueue( pxQueue );
    146c:	c8 01       	movw	r24, r16
    146e:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				/* Resuming the scheduler will move tasks from the pending
				ready list into the ready list - so it is feasible that this
				task is already in a ready list before it yields - in which
				case the yield will not cause a context switch unless there
				is also a higher priority task in the pending ready list. */
				if( xTaskResumeAll() == pdFALSE )
    1472:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    1476:	88 23       	and	r24, r24
    1478:	11 f0       	breq	.+4      	; 0x147e <xQueueGenericSend+0xf0>
    147a:	81 e0       	ldi	r24, 0x01	; 1
    147c:	a0 cf       	rjmp	.-192    	; 0x13be <xQueueGenericSend+0x30>
				{
					portYIELD_WITHIN_API();
    147e:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
    1482:	fb cf       	rjmp	.-10     	; 0x147a <xQueueGenericSend+0xec>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
    1484:	c8 01       	movw	r24, r16
    1486:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				( void ) xTaskResumeAll();
    148a:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    148e:	f5 cf       	rjmp	.-22     	; 0x147a <xQueueGenericSend+0xec>
			}
		}
		else
		{
			/* The timeout has expired. */
			prvUnlockQueue( pxQueue );
    1490:	c8 01       	movw	r24, r16
    1492:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
			( void ) xTaskResumeAll();
    1496:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>

			traceQUEUE_SEND_FAILED( pxQueue );
			return errQUEUE_FULL;
    149a:	80 e0       	ldi	r24, 0x00	; 0
		}
	} /*lint -restore */
}
    149c:	0f 90       	pop	r0
    149e:	0f 90       	pop	r0
    14a0:	0f 90       	pop	r0
    14a2:	0f 90       	pop	r0
    14a4:	0f 90       	pop	r0
    14a6:	df 91       	pop	r29
    14a8:	cf 91       	pop	r28
    14aa:	1f 91       	pop	r17
    14ac:	0f 91       	pop	r16
    14ae:	ff 90       	pop	r15
    14b0:	df 90       	pop	r13
    14b2:	cf 90       	pop	r12
    14b4:	bf 90       	pop	r11
    14b6:	af 90       	pop	r10
    14b8:	08 95       	ret

000014ba <xQueueGenericSendFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
{
    14ba:	ef 92       	push	r14
    14bc:	ff 92       	push	r15
    14be:	1f 93       	push	r17
    14c0:	cf 93       	push	r28
    14c2:	df 93       	push	r29
    14c4:	ec 01       	movw	r28, r24
	read, instead return a flag to say whether a context switch is required or
	not (i.e. has a task with a higher priority than us been woken by this
	post). */
	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
    14c6:	9a 8d       	ldd	r25, Y+26	; 0x1a
    14c8:	8b 8d       	ldd	r24, Y+27	; 0x1b
    14ca:	98 17       	cp	r25, r24
    14cc:	10 f0       	brcs	.+4      	; 0x14d2 <xQueueGenericSendFromISR+0x18>
    14ce:	22 30       	cpi	r18, 0x02	; 2
    14d0:	e1 f4       	brne	.+56     	; 0x150a <xQueueGenericSendFromISR+0x50>
    14d2:	7a 01       	movw	r14, r20
		{
			const int8_t cTxLock = pxQueue->cTxLock;
    14d4:	1e 8d       	ldd	r17, Y+30	; 0x1e
			/* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a
			semaphore or mutex.  That means prvCopyDataToQueue() cannot result
			in a task disinheriting a priority and prvCopyDataToQueue() can be
			called here even though the disinherit function does not check if
			the scheduler is suspended before accessing the ready lists. */
			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
    14d6:	42 2f       	mov	r20, r18
    14d8:	ce 01       	movw	r24, r28
    14da:	0e 94 c0 08 	call	0x1180	; 0x1180 <prvCopyDataToQueue>

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
    14de:	1f 3f       	cpi	r17, 0xFF	; 255
    14e0:	81 f4       	brne	.+32     	; 0x1502 <xQueueGenericSendFromISR+0x48>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    14e2:	89 89       	ldd	r24, Y+17	; 0x11
    14e4:	88 23       	and	r24, r24
    14e6:	79 f0       	breq	.+30     	; 0x1506 <xQueueGenericSendFromISR+0x4c>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    14e8:	ce 01       	movw	r24, r28
    14ea:	41 96       	adiw	r24, 0x11	; 17
    14ec:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    14f0:	88 23       	and	r24, r24
    14f2:	49 f0       	breq	.+18     	; 0x1506 <xQueueGenericSendFromISR+0x4c>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
    14f4:	e1 14       	cp	r14, r1
    14f6:	f1 04       	cpc	r15, r1
    14f8:	31 f0       	breq	.+12     	; 0x1506 <xQueueGenericSendFromISR+0x4c>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
    14fa:	81 e0       	ldi	r24, 0x01	; 1
    14fc:	f7 01       	movw	r30, r14
    14fe:	80 83       	st	Z, r24
    1500:	05 c0       	rjmp	.+10     	; 0x150c <xQueueGenericSendFromISR+0x52>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
    1502:	1f 5f       	subi	r17, 0xFF	; 255
    1504:	1e 8f       	std	Y+30, r17	; 0x1e
			}

			xReturn = pdPASS;
    1506:	81 e0       	ldi	r24, 0x01	; 1
    1508:	01 c0       	rjmp	.+2      	; 0x150c <xQueueGenericSendFromISR+0x52>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
    150a:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    150c:	df 91       	pop	r29
    150e:	cf 91       	pop	r28
    1510:	1f 91       	pop	r17
    1512:	ff 90       	pop	r15
    1514:	ef 90       	pop	r14
    1516:	08 95       	ret

00001518 <xQueueGiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
{
    1518:	cf 93       	push	r28
    151a:	df 93       	push	r29
    151c:	fc 01       	movw	r30, r24
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    151e:	92 8d       	ldd	r25, Z+26	; 0x1a

		/* When the queue is used to implement a semaphore no data is ever
		moved through the queue but it is still valid to see if the queue 'has
		space'. */
		if( uxMessagesWaiting < pxQueue->uxLength )
    1520:	83 8d       	ldd	r24, Z+27	; 0x1b
    1522:	98 17       	cp	r25, r24
    1524:	c0 f4       	brcc	.+48     	; 0x1556 <xQueueGiveFromISR+0x3e>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
    1526:	86 8d       	ldd	r24, Z+30	; 0x1e
			holder - and if there is a mutex holder then the mutex cannot be
			given from an ISR.  As this is the ISR version of the function it
			can be assumed there is no mutex holder and no need to determine if
			priority disinheritance is needed.  Simply increase the count of
			messages (semaphores) available. */
			pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
    1528:	9f 5f       	subi	r25, 0xFF	; 255
    152a:	92 8f       	std	Z+26, r25	; 0x1a

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
    152c:	8f 3f       	cpi	r24, 0xFF	; 255
    152e:	79 f4       	brne	.+30     	; 0x154e <xQueueGiveFromISR+0x36>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1530:	81 89       	ldd	r24, Z+17	; 0x11
    1532:	88 23       	and	r24, r24
    1534:	71 f0       	breq	.+28     	; 0x1552 <xQueueGiveFromISR+0x3a>
    1536:	eb 01       	movw	r28, r22
    1538:	cf 01       	movw	r24, r30
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    153a:	41 96       	adiw	r24, 0x11	; 17
    153c:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    1540:	88 23       	and	r24, r24
    1542:	39 f0       	breq	.+14     	; 0x1552 <xQueueGiveFromISR+0x3a>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
    1544:	20 97       	sbiw	r28, 0x00	; 0
    1546:	29 f0       	breq	.+10     	; 0x1552 <xQueueGiveFromISR+0x3a>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
    1548:	81 e0       	ldi	r24, 0x01	; 1
    154a:	88 83       	st	Y, r24
    154c:	05 c0       	rjmp	.+10     	; 0x1558 <xQueueGiveFromISR+0x40>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
    154e:	8f 5f       	subi	r24, 0xFF	; 255
    1550:	86 8f       	std	Z+30, r24	; 0x1e
			}

			xReturn = pdPASS;
    1552:	81 e0       	ldi	r24, 0x01	; 1
    1554:	01 c0       	rjmp	.+2      	; 0x1558 <xQueueGiveFromISR+0x40>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
    1556:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1558:	df 91       	pop	r29
    155a:	cf 91       	pop	r28
    155c:	08 95       	ret

0000155e <xQueueReceive>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
{
    155e:	af 92       	push	r10
    1560:	bf 92       	push	r11
    1562:	cf 92       	push	r12
    1564:	df 92       	push	r13
    1566:	ff 92       	push	r15
    1568:	0f 93       	push	r16
    156a:	1f 93       	push	r17
    156c:	cf 93       	push	r28
    156e:	df 93       	push	r29
    1570:	00 d0       	rcall	.+0      	; 0x1572 <xQueueReceive+0x14>
    1572:	00 d0       	rcall	.+0      	; 0x1574 <xQueueReceive+0x16>
    1574:	1f 92       	push	r1
    1576:	cd b7       	in	r28, 0x3d	; 61
    1578:	de b7       	in	r29, 0x3e	; 62
    157a:	8c 01       	movw	r16, r24
    157c:	6b 01       	movw	r12, r22
    157e:	5d 83       	std	Y+5, r21	; 0x05
    1580:	4c 83       	std	Y+4, r20	; 0x04
BaseType_t xEntryTimeSet = pdFALSE;
    1582:	80 e0       	ldi	r24, 0x00	; 0
			/* The timeout has not expired.  If the queue is still empty place
			the task on the list of tasks waiting to receive from the queue. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    1584:	58 01       	movw	r10, r16
    1586:	91 e1       	ldi	r25, 0x11	; 17
    1588:	a9 0e       	add	r10, r25
    158a:	b1 1c       	adc	r11, r1
	/*lint -save -e904  This function relaxes the coding standard somewhat to
	allow return statements within the function itself.  This is done in the
	interest of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    158c:	0f b6       	in	r0, 0x3f	; 63
    158e:	f8 94       	cli
    1590:	0f 92       	push	r0
		{
			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    1592:	f8 01       	movw	r30, r16
    1594:	f2 8c       	ldd	r15, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    1596:	ff 20       	and	r15, r15
    1598:	a9 f0       	breq	.+42     	; 0x15c4 <xQueueReceive+0x66>
			{
				/* Data available, remove one item. */
				prvCopyDataFromQueue( pxQueue, pvBuffer );
    159a:	b6 01       	movw	r22, r12
    159c:	c8 01       	movw	r24, r16
    159e:	0e 94 08 09 	call	0x1210	; 0x1210 <prvCopyDataFromQueue>
				traceQUEUE_RECEIVE( pxQueue );
				pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
    15a2:	fa 94       	dec	r15
    15a4:	f8 01       	movw	r30, r16
    15a6:	f2 8e       	std	Z+26, r15	; 0x1a

				/* There is now space in the queue, were any tasks waiting to
				post to the queue?  If so, unblock the highest priority waiting
				task. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    15a8:	80 85       	ldd	r24, Z+8	; 0x08
    15aa:	88 23       	and	r24, r24
    15ac:	39 f0       	breq	.+14     	; 0x15bc <xQueueReceive+0x5e>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    15ae:	c8 01       	movw	r24, r16
    15b0:	08 96       	adiw	r24, 0x08	; 8
    15b2:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    15b6:	81 11       	cpse	r24, r1
					{
						queueYIELD_IF_USING_PREEMPTION();
    15b8:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				taskEXIT_CRITICAL();
    15bc:	0f 90       	pop	r0
    15be:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    15c0:	81 e0       	ldi	r24, 0x01	; 1
    15c2:	50 c0       	rjmp	.+160    	; 0x1664 <xQueueReceive+0x106>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    15c4:	2c 81       	ldd	r18, Y+4	; 0x04
    15c6:	3d 81       	ldd	r19, Y+5	; 0x05
    15c8:	23 2b       	or	r18, r19
    15ca:	19 f4       	brne	.+6      	; 0x15d2 <xQueueReceive+0x74>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    15cc:	0f 90       	pop	r0
    15ce:	0f be       	out	0x3f, r0	; 63
    15d0:	48 c0       	rjmp	.+144    	; 0x1662 <xQueueReceive+0x104>
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
				}
				else if( xEntryTimeSet == pdFALSE )
    15d2:	81 11       	cpse	r24, r1
    15d4:	04 c0       	rjmp	.+8      	; 0x15de <xQueueReceive+0x80>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    15d6:	ce 01       	movw	r24, r28
    15d8:	01 96       	adiw	r24, 0x01	; 1
    15da:	0e 94 3a 06 	call	0xc74	; 0xc74 <vTaskInternalSetTimeOutState>
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    15de:	0f 90       	pop	r0
    15e0:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    15e2:	0e 94 6e 03 	call	0x6dc	; 0x6dc <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    15e6:	0f b6       	in	r0, 0x3f	; 63
    15e8:	f8 94       	cli
    15ea:	0f 92       	push	r0
    15ec:	f8 01       	movw	r30, r16
    15ee:	85 8d       	ldd	r24, Z+29	; 0x1d
    15f0:	8f 3f       	cpi	r24, 0xFF	; 255
    15f2:	09 f4       	brne	.+2      	; 0x15f6 <xQueueReceive+0x98>
    15f4:	15 8e       	std	Z+29, r1	; 0x1d
    15f6:	f8 01       	movw	r30, r16
    15f8:	86 8d       	ldd	r24, Z+30	; 0x1e
    15fa:	8f 3f       	cpi	r24, 0xFF	; 255
    15fc:	09 f4       	brne	.+2      	; 0x1600 <xQueueReceive+0xa2>
    15fe:	16 8e       	std	Z+30, r1	; 0x1e
    1600:	0f 90       	pop	r0
    1602:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    1604:	be 01       	movw	r22, r28
    1606:	6c 5f       	subi	r22, 0xFC	; 252
    1608:	7f 4f       	sbci	r23, 0xFF	; 255
    160a:	ce 01       	movw	r24, r28
    160c:	01 96       	adiw	r24, 0x01	; 1
    160e:	0e 94 45 06 	call	0xc8a	; 0xc8a <xTaskCheckForTimeOut>
    1612:	81 11       	cpse	r24, r1
    1614:	1c c0       	rjmp	.+56     	; 0x164e <xQueueReceive+0xf0>
		{
			/* The timeout has not expired.  If the queue is still empty place
			the task on the list of tasks waiting to receive from the queue. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1616:	c8 01       	movw	r24, r16
    1618:	0e 94 b5 08 	call	0x116a	; 0x116a <prvIsQueueEmpty>
    161c:	88 23       	and	r24, r24
    161e:	89 f0       	breq	.+34     	; 0x1642 <xQueueReceive+0xe4>
			{
				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    1620:	6c 81       	ldd	r22, Y+4	; 0x04
    1622:	7d 81       	ldd	r23, Y+5	; 0x05
    1624:	c5 01       	movw	r24, r10
    1626:	0e 94 8f 05 	call	0xb1e	; 0xb1e <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    162a:	c8 01       	movw	r24, r16
    162c:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    1630:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    1634:	88 23       	and	r24, r24
    1636:	11 f0       	breq	.+4      	; 0x163c <xQueueReceive+0xde>
    1638:	81 e0       	ldi	r24, 0x01	; 1
    163a:	a8 cf       	rjmp	.-176    	; 0x158c <xQueueReceive+0x2e>
				{
					portYIELD_WITHIN_API();
    163c:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
    1640:	fb cf       	rjmp	.-10     	; 0x1638 <xQueueReceive+0xda>
			}
			else
			{
				/* The queue contains data again.  Loop back to try and read the
				data. */
				prvUnlockQueue( pxQueue );
    1642:	c8 01       	movw	r24, r16
    1644:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				( void ) xTaskResumeAll();
    1648:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    164c:	f5 cf       	rjmp	.-22     	; 0x1638 <xQueueReceive+0xda>
		}
		else
		{
			/* Timed out.  If there is no data in the queue exit, otherwise loop
			back and attempt to read the data. */
			prvUnlockQueue( pxQueue );
    164e:	c8 01       	movw	r24, r16
    1650:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
			( void ) xTaskResumeAll();
    1654:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>

			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1658:	c8 01       	movw	r24, r16
    165a:	0e 94 b5 08 	call	0x116a	; 0x116a <prvIsQueueEmpty>
    165e:	88 23       	and	r24, r24
    1660:	59 f3       	breq	.-42     	; 0x1638 <xQueueReceive+0xda>
			{
				traceQUEUE_RECEIVE_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    1662:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	} /*lint -restore */
}
    1664:	0f 90       	pop	r0
    1666:	0f 90       	pop	r0
    1668:	0f 90       	pop	r0
    166a:	0f 90       	pop	r0
    166c:	0f 90       	pop	r0
    166e:	df 91       	pop	r29
    1670:	cf 91       	pop	r28
    1672:	1f 91       	pop	r17
    1674:	0f 91       	pop	r16
    1676:	ff 90       	pop	r15
    1678:	df 90       	pop	r13
    167a:	cf 90       	pop	r12
    167c:	bf 90       	pop	r11
    167e:	af 90       	pop	r10
    1680:	08 95       	ret

00001682 <xQueueSemaphoreTake>:
/*-----------------------------------------------------------*/

BaseType_t xQueueSemaphoreTake( QueueHandle_t xQueue, TickType_t xTicksToWait )
{
    1682:	ef 92       	push	r14
    1684:	ff 92       	push	r15
    1686:	0f 93       	push	r16
    1688:	1f 93       	push	r17
    168a:	cf 93       	push	r28
    168c:	df 93       	push	r29
    168e:	00 d0       	rcall	.+0      	; 0x1690 <xQueueSemaphoreTake+0xe>
    1690:	00 d0       	rcall	.+0      	; 0x1692 <xQueueSemaphoreTake+0x10>
    1692:	1f 92       	push	r1
    1694:	cd b7       	in	r28, 0x3d	; 61
    1696:	de b7       	in	r29, 0x3e	; 62
    1698:	8c 01       	movw	r16, r24
    169a:	7d 83       	std	Y+5, r23	; 0x05
    169c:	6c 83       	std	Y+4, r22	; 0x04
BaseType_t xEntryTimeSet = pdFALSE;
    169e:	90 e0       	ldi	r25, 0x00	; 0
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    16a0:	78 01       	movw	r14, r16
    16a2:	81 e1       	ldi	r24, 0x11	; 17
    16a4:	e8 0e       	add	r14, r24
    16a6:	f1 1c       	adc	r15, r1
	/*lint -save -e904 This function relaxes the coding standard somewhat to allow return
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    16a8:	0f b6       	in	r0, 0x3f	; 63
    16aa:	f8 94       	cli
    16ac:	0f 92       	push	r0
		{
			/* Semaphores are queues with an item size of 0, and where the
			number of messages in the queue is the semaphore's count value. */
			const UBaseType_t uxSemaphoreCount = pxQueue->uxMessagesWaiting;
    16ae:	f8 01       	movw	r30, r16
    16b0:	82 8d       	ldd	r24, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxSemaphoreCount > ( UBaseType_t ) 0 )
    16b2:	88 23       	and	r24, r24
    16b4:	81 f0       	breq	.+32     	; 0x16d6 <xQueueSemaphoreTake+0x54>
			{
				traceQUEUE_RECEIVE( pxQueue );

				/* Semaphores are queues with a data size of zero and where the
				messages waiting is the semaphore's count.  Reduce the count. */
				pxQueue->uxMessagesWaiting = uxSemaphoreCount - ( UBaseType_t ) 1;
    16b6:	81 50       	subi	r24, 0x01	; 1
    16b8:	82 8f       	std	Z+26, r24	; 0x1a
				}
				#endif /* configUSE_MUTEXES */

				/* Check to see if other tasks are blocked waiting to give the
				semaphore, and if so, unblock the highest priority such task. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    16ba:	80 85       	ldd	r24, Z+8	; 0x08
    16bc:	88 23       	and	r24, r24
    16be:	39 f0       	breq	.+14     	; 0x16ce <xQueueSemaphoreTake+0x4c>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    16c0:	c8 01       	movw	r24, r16
    16c2:	08 96       	adiw	r24, 0x08	; 8
    16c4:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    16c8:	81 11       	cpse	r24, r1
					{
						queueYIELD_IF_USING_PREEMPTION();
    16ca:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				taskEXIT_CRITICAL();
    16ce:	0f 90       	pop	r0
    16d0:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    16d2:	81 e0       	ldi	r24, 0x01	; 1
    16d4:	50 c0       	rjmp	.+160    	; 0x1776 <xQueueSemaphoreTake+0xf4>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    16d6:	2c 81       	ldd	r18, Y+4	; 0x04
    16d8:	3d 81       	ldd	r19, Y+5	; 0x05
    16da:	23 2b       	or	r18, r19
    16dc:	19 f4       	brne	.+6      	; 0x16e4 <xQueueSemaphoreTake+0x62>
					}
					#endif /* configUSE_MUTEXES */

					/* The semaphore count was 0 and no block time is specified
					(or the block time has expired) so exit now. */
					taskEXIT_CRITICAL();
    16de:	0f 90       	pop	r0
    16e0:	0f be       	out	0x3f, r0	; 63
    16e2:	48 c0       	rjmp	.+144    	; 0x1774 <xQueueSemaphoreTake+0xf2>
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
				}
				else if( xEntryTimeSet == pdFALSE )
    16e4:	91 11       	cpse	r25, r1
    16e6:	04 c0       	rjmp	.+8      	; 0x16f0 <xQueueSemaphoreTake+0x6e>
				{
					/* The semaphore count was 0 and a block time was specified
					so configure the timeout structure ready to block. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    16e8:	ce 01       	movw	r24, r28
    16ea:	01 96       	adiw	r24, 0x01	; 1
    16ec:	0e 94 3a 06 	call	0xc74	; 0xc74 <vTaskInternalSetTimeOutState>
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    16f0:	0f 90       	pop	r0
    16f2:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can give to and take from the semaphore
		now the critical section has been exited. */

		vTaskSuspendAll();
    16f4:	0e 94 6e 03 	call	0x6dc	; 0x6dc <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    16f8:	0f b6       	in	r0, 0x3f	; 63
    16fa:	f8 94       	cli
    16fc:	0f 92       	push	r0
    16fe:	f8 01       	movw	r30, r16
    1700:	85 8d       	ldd	r24, Z+29	; 0x1d
    1702:	8f 3f       	cpi	r24, 0xFF	; 255
    1704:	09 f4       	brne	.+2      	; 0x1708 <xQueueSemaphoreTake+0x86>
    1706:	15 8e       	std	Z+29, r1	; 0x1d
    1708:	f8 01       	movw	r30, r16
    170a:	86 8d       	ldd	r24, Z+30	; 0x1e
    170c:	8f 3f       	cpi	r24, 0xFF	; 255
    170e:	09 f4       	brne	.+2      	; 0x1712 <xQueueSemaphoreTake+0x90>
    1710:	16 8e       	std	Z+30, r1	; 0x1e
    1712:	0f 90       	pop	r0
    1714:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    1716:	be 01       	movw	r22, r28
    1718:	6c 5f       	subi	r22, 0xFC	; 252
    171a:	7f 4f       	sbci	r23, 0xFF	; 255
    171c:	ce 01       	movw	r24, r28
    171e:	01 96       	adiw	r24, 0x01	; 1
    1720:	0e 94 45 06 	call	0xc8a	; 0xc8a <xTaskCheckForTimeOut>
    1724:	81 11       	cpse	r24, r1
    1726:	1c c0       	rjmp	.+56     	; 0x1760 <xQueueSemaphoreTake+0xde>
		{
			/* A block time is specified and not expired.  If the semaphore
			count is 0 then enter the Blocked state to wait for a semaphore to
			become available.  As semaphores are implemented with queues the
			queue being empty is equivalent to the semaphore count being 0. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1728:	c8 01       	movw	r24, r16
    172a:	0e 94 b5 08 	call	0x116a	; 0x116a <prvIsQueueEmpty>
    172e:	88 23       	and	r24, r24
    1730:	89 f0       	breq	.+34     	; 0x1754 <xQueueSemaphoreTake+0xd2>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    1732:	6c 81       	ldd	r22, Y+4	; 0x04
    1734:	7d 81       	ldd	r23, Y+5	; 0x05
    1736:	c7 01       	movw	r24, r14
    1738:	0e 94 8f 05 	call	0xb1e	; 0xb1e <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    173c:	c8 01       	movw	r24, r16
    173e:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    1742:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    1746:	88 23       	and	r24, r24
    1748:	11 f0       	breq	.+4      	; 0x174e <xQueueSemaphoreTake+0xcc>
    174a:	91 e0       	ldi	r25, 0x01	; 1
    174c:	ad cf       	rjmp	.-166    	; 0x16a8 <xQueueSemaphoreTake+0x26>
				{
					portYIELD_WITHIN_API();
    174e:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
    1752:	fb cf       	rjmp	.-10     	; 0x174a <xQueueSemaphoreTake+0xc8>
			}
			else
			{
				/* There was no timeout and the semaphore count was not 0, so
				attempt to take the semaphore again. */
				prvUnlockQueue( pxQueue );
    1754:	c8 01       	movw	r24, r16
    1756:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				( void ) xTaskResumeAll();
    175a:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    175e:	f5 cf       	rjmp	.-22     	; 0x174a <xQueueSemaphoreTake+0xc8>
			}
		}
		else
		{
			/* Timed out. */
			prvUnlockQueue( pxQueue );
    1760:	c8 01       	movw	r24, r16
    1762:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
			( void ) xTaskResumeAll();
    1766:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>

			/* If the semaphore count is 0 exit now as the timeout has
			expired.  Otherwise return to attempt to take the semaphore that is
			known to be available.  As semaphores are implemented by queues the
			queue being empty is equivalent to the semaphore count being 0. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    176a:	c8 01       	movw	r24, r16
    176c:	0e 94 b5 08 	call	0x116a	; 0x116a <prvIsQueueEmpty>
    1770:	88 23       	and	r24, r24
    1772:	59 f3       	breq	.-42     	; 0x174a <xQueueSemaphoreTake+0xc8>
					}
				}
				#endif /* configUSE_MUTEXES */

				traceQUEUE_RECEIVE_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    1774:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	} /*lint -restore */
}
    1776:	0f 90       	pop	r0
    1778:	0f 90       	pop	r0
    177a:	0f 90       	pop	r0
    177c:	0f 90       	pop	r0
    177e:	0f 90       	pop	r0
    1780:	df 91       	pop	r29
    1782:	cf 91       	pop	r28
    1784:	1f 91       	pop	r17
    1786:	0f 91       	pop	r16
    1788:	ff 90       	pop	r15
    178a:	ef 90       	pop	r14
    178c:	08 95       	ret

0000178e <xQueuePeek>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeek( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
{
    178e:	cf 92       	push	r12
    1790:	df 92       	push	r13
    1792:	ef 92       	push	r14
    1794:	ff 92       	push	r15
    1796:	0f 93       	push	r16
    1798:	1f 93       	push	r17
    179a:	cf 93       	push	r28
    179c:	df 93       	push	r29
    179e:	00 d0       	rcall	.+0      	; 0x17a0 <xQueuePeek+0x12>
    17a0:	00 d0       	rcall	.+0      	; 0x17a2 <xQueuePeek+0x14>
    17a2:	1f 92       	push	r1
    17a4:	cd b7       	in	r28, 0x3d	; 61
    17a6:	de b7       	in	r29, 0x3e	; 62
    17a8:	8c 01       	movw	r16, r24
    17aa:	7b 01       	movw	r14, r22
    17ac:	5d 83       	std	Y+5, r21	; 0x05
    17ae:	4c 83       	std	Y+4, r20	; 0x04
BaseType_t xEntryTimeSet = pdFALSE;
    17b0:	80 e0       	ldi	r24, 0x00	; 0
			/* Timeout has not expired yet, check to see if there is data in the
			queue now, and if not enter the Blocked state to wait for data. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    17b2:	68 01       	movw	r12, r16
    17b4:	91 e1       	ldi	r25, 0x11	; 17
    17b6:	c9 0e       	add	r12, r25
    17b8:	d1 1c       	adc	r13, r1
	/*lint -save -e904  This function relaxes the coding standard somewhat to
	allow return statements within the function itself.  This is done in the
	interest of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    17ba:	0f b6       	in	r0, 0x3f	; 63
    17bc:	f8 94       	cli
    17be:	0f 92       	push	r0
		{
			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    17c0:	f8 01       	movw	r30, r16
    17c2:	92 8d       	ldd	r25, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    17c4:	99 23       	and	r25, r25
    17c6:	b9 f0       	breq	.+46     	; 0x17f6 <xQueuePeek+0x68>
			{
				/* Remember the read position so it can be reset after the data
				is read from the queue as this function is only peeking the
				data, not removing it. */
				pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;
    17c8:	c6 80       	ldd	r12, Z+6	; 0x06
    17ca:	d7 80       	ldd	r13, Z+7	; 0x07

				prvCopyDataFromQueue( pxQueue, pvBuffer );
    17cc:	b7 01       	movw	r22, r14
    17ce:	c8 01       	movw	r24, r16
    17d0:	0e 94 08 09 	call	0x1210	; 0x1210 <prvCopyDataFromQueue>
				traceQUEUE_PEEK( pxQueue );

				/* The data is not being removed, so reset the read pointer. */
				pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;
    17d4:	f8 01       	movw	r30, r16
    17d6:	d7 82       	std	Z+7, r13	; 0x07
    17d8:	c6 82       	std	Z+6, r12	; 0x06

				/* The data is being left in the queue, so see if there are
				any other tasks waiting for the data. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    17da:	81 89       	ldd	r24, Z+17	; 0x11
    17dc:	88 23       	and	r24, r24
    17de:	39 f0       	breq	.+14     	; 0x17ee <xQueuePeek+0x60>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    17e0:	c8 01       	movw	r24, r16
    17e2:	41 96       	adiw	r24, 0x11	; 17
    17e4:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    17e8:	81 11       	cpse	r24, r1
					{
						/* The task waiting has a higher priority than this task. */
						queueYIELD_IF_USING_PREEMPTION();
    17ea:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				taskEXIT_CRITICAL();
    17ee:	0f 90       	pop	r0
    17f0:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    17f2:	81 e0       	ldi	r24, 0x01	; 1
    17f4:	50 c0       	rjmp	.+160    	; 0x1896 <xQueuePeek+0x108>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    17f6:	2c 81       	ldd	r18, Y+4	; 0x04
    17f8:	3d 81       	ldd	r19, Y+5	; 0x05
    17fa:	23 2b       	or	r18, r19
    17fc:	19 f4       	brne	.+6      	; 0x1804 <xQueuePeek+0x76>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    17fe:	0f 90       	pop	r0
    1800:	0f be       	out	0x3f, r0	; 63
    1802:	48 c0       	rjmp	.+144    	; 0x1894 <xQueuePeek+0x106>
					traceQUEUE_PEEK_FAILED( pxQueue );
					return errQUEUE_EMPTY;
				}
				else if( xEntryTimeSet == pdFALSE )
    1804:	81 11       	cpse	r24, r1
    1806:	04 c0       	rjmp	.+8      	; 0x1810 <xQueuePeek+0x82>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure ready to enter the blocked
					state. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    1808:	ce 01       	movw	r24, r28
    180a:	01 96       	adiw	r24, 0x01	; 1
    180c:	0e 94 3a 06 	call	0xc74	; 0xc74 <vTaskInternalSetTimeOutState>
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    1810:	0f 90       	pop	r0
    1812:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    1814:	0e 94 6e 03 	call	0x6dc	; 0x6dc <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    1818:	0f b6       	in	r0, 0x3f	; 63
    181a:	f8 94       	cli
    181c:	0f 92       	push	r0
    181e:	f8 01       	movw	r30, r16
    1820:	85 8d       	ldd	r24, Z+29	; 0x1d
    1822:	8f 3f       	cpi	r24, 0xFF	; 255
    1824:	09 f4       	brne	.+2      	; 0x1828 <xQueuePeek+0x9a>
    1826:	15 8e       	std	Z+29, r1	; 0x1d
    1828:	f8 01       	movw	r30, r16
    182a:	86 8d       	ldd	r24, Z+30	; 0x1e
    182c:	8f 3f       	cpi	r24, 0xFF	; 255
    182e:	09 f4       	brne	.+2      	; 0x1832 <xQueuePeek+0xa4>
    1830:	16 8e       	std	Z+30, r1	; 0x1e
    1832:	0f 90       	pop	r0
    1834:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    1836:	be 01       	movw	r22, r28
    1838:	6c 5f       	subi	r22, 0xFC	; 252
    183a:	7f 4f       	sbci	r23, 0xFF	; 255
    183c:	ce 01       	movw	r24, r28
    183e:	01 96       	adiw	r24, 0x01	; 1
    1840:	0e 94 45 06 	call	0xc8a	; 0xc8a <xTaskCheckForTimeOut>
    1844:	81 11       	cpse	r24, r1
    1846:	1c c0       	rjmp	.+56     	; 0x1880 <xQueuePeek+0xf2>
		{
			/* Timeout has not expired yet, check to see if there is data in the
			queue now, and if not enter the Blocked state to wait for data. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1848:	c8 01       	movw	r24, r16
    184a:	0e 94 b5 08 	call	0x116a	; 0x116a <prvIsQueueEmpty>
    184e:	88 23       	and	r24, r24
    1850:	89 f0       	breq	.+34     	; 0x1874 <xQueuePeek+0xe6>
			{
				traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    1852:	6c 81       	ldd	r22, Y+4	; 0x04
    1854:	7d 81       	ldd	r23, Y+5	; 0x05
    1856:	c6 01       	movw	r24, r12
    1858:	0e 94 8f 05 	call	0xb1e	; 0xb1e <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    185c:	c8 01       	movw	r24, r16
    185e:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    1862:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    1866:	88 23       	and	r24, r24
    1868:	11 f0       	breq	.+4      	; 0x186e <xQueuePeek+0xe0>
    186a:	81 e0       	ldi	r24, 0x01	; 1
    186c:	a6 cf       	rjmp	.-180    	; 0x17ba <xQueuePeek+0x2c>
				{
					portYIELD_WITHIN_API();
    186e:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
    1872:	fb cf       	rjmp	.-10     	; 0x186a <xQueuePeek+0xdc>
			}
			else
			{
				/* There is data in the queue now, so don't enter the blocked
				state, instead return to try and obtain the data. */
				prvUnlockQueue( pxQueue );
    1874:	c8 01       	movw	r24, r16
    1876:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
				( void ) xTaskResumeAll();
    187a:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
    187e:	f5 cf       	rjmp	.-22     	; 0x186a <xQueuePeek+0xdc>
		}
		else
		{
			/* The timeout has expired.  If there is still no data in the queue
			exit, otherwise go back and try to read the data again. */
			prvUnlockQueue( pxQueue );
    1880:	c8 01       	movw	r24, r16
    1882:	0e 94 22 09 	call	0x1244	; 0x1244 <prvUnlockQueue>
			( void ) xTaskResumeAll();
    1886:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>

			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    188a:	c8 01       	movw	r24, r16
    188c:	0e 94 b5 08 	call	0x116a	; 0x116a <prvIsQueueEmpty>
    1890:	88 23       	and	r24, r24
    1892:	59 f3       	breq	.-42     	; 0x186a <xQueuePeek+0xdc>
			{
				traceQUEUE_PEEK_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    1894:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	} /*lint -restore */
}
    1896:	0f 90       	pop	r0
    1898:	0f 90       	pop	r0
    189a:	0f 90       	pop	r0
    189c:	0f 90       	pop	r0
    189e:	0f 90       	pop	r0
    18a0:	df 91       	pop	r29
    18a2:	cf 91       	pop	r28
    18a4:	1f 91       	pop	r17
    18a6:	0f 91       	pop	r16
    18a8:	ff 90       	pop	r15
    18aa:	ef 90       	pop	r14
    18ac:	df 90       	pop	r13
    18ae:	cf 90       	pop	r12
    18b0:	08 95       	ret

000018b2 <xQueueReceiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
{
    18b2:	ef 92       	push	r14
    18b4:	ff 92       	push	r15
    18b6:	0f 93       	push	r16
    18b8:	1f 93       	push	r17
    18ba:	cf 93       	push	r28
    18bc:	df 93       	push	r29
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    18be:	fc 01       	movw	r30, r24
    18c0:	02 8d       	ldd	r16, Z+26	; 0x1a

		/* Cannot block in an ISR, so check there is data available. */
		if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    18c2:	00 23       	and	r16, r16
    18c4:	e9 f0       	breq	.+58     	; 0x1900 <xQueueReceiveFromISR+0x4e>
    18c6:	7a 01       	movw	r14, r20
    18c8:	ec 01       	movw	r28, r24
		{
			const int8_t cRxLock = pxQueue->cRxLock;
    18ca:	15 8d       	ldd	r17, Z+29	; 0x1d

			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );

			prvCopyDataFromQueue( pxQueue, pvBuffer );
    18cc:	0e 94 08 09 	call	0x1210	; 0x1210 <prvCopyDataFromQueue>
			pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
    18d0:	01 50       	subi	r16, 0x01	; 1
    18d2:	0a 8f       	std	Y+26, r16	; 0x1a

			/* If the queue is locked the event list will not be modified.
			Instead update the lock count so the task that unlocks the queue
			will know that an ISR has removed data while the queue was
			locked. */
			if( cRxLock == queueUNLOCKED )
    18d4:	1f 3f       	cpi	r17, 0xFF	; 255
    18d6:	81 f4       	brne	.+32     	; 0x18f8 <xQueueReceiveFromISR+0x46>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    18d8:	88 85       	ldd	r24, Y+8	; 0x08
    18da:	88 23       	and	r24, r24
    18dc:	79 f0       	breq	.+30     	; 0x18fc <xQueueReceiveFromISR+0x4a>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    18de:	ce 01       	movw	r24, r28
    18e0:	08 96       	adiw	r24, 0x08	; 8
    18e2:	0e 94 b8 05 	call	0xb70	; 0xb70 <xTaskRemoveFromEventList>
    18e6:	88 23       	and	r24, r24
    18e8:	49 f0       	breq	.+18     	; 0x18fc <xQueueReceiveFromISR+0x4a>
					{
						/* The task waiting has a higher priority than us so
						force a context switch. */
						if( pxHigherPriorityTaskWoken != NULL )
    18ea:	e1 14       	cp	r14, r1
    18ec:	f1 04       	cpc	r15, r1
    18ee:	31 f0       	breq	.+12     	; 0x18fc <xQueueReceiveFromISR+0x4a>
						{
							*pxHigherPriorityTaskWoken = pdTRUE;
    18f0:	81 e0       	ldi	r24, 0x01	; 1
    18f2:	f7 01       	movw	r30, r14
    18f4:	80 83       	st	Z, r24
    18f6:	05 c0       	rjmp	.+10     	; 0x1902 <xQueueReceiveFromISR+0x50>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
    18f8:	1f 5f       	subi	r17, 0xFF	; 255
    18fa:	1d 8f       	std	Y+29, r17	; 0x1d
			}

			xReturn = pdPASS;
    18fc:	81 e0       	ldi	r24, 0x01	; 1
    18fe:	01 c0       	rjmp	.+2      	; 0x1902 <xQueueReceiveFromISR+0x50>
		}
		else
		{
			xReturn = pdFAIL;
    1900:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1902:	df 91       	pop	r29
    1904:	cf 91       	pop	r28
    1906:	1f 91       	pop	r17
    1908:	0f 91       	pop	r16
    190a:	ff 90       	pop	r15
    190c:	ef 90       	pop	r14
    190e:	08 95       	ret

00001910 <xQueuePeekFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
{
    1910:	0f 93       	push	r16
    1912:	1f 93       	push	r17
    1914:	cf 93       	push	r28
    1916:	df 93       	push	r29
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* Cannot block in an ISR, so check there is data available. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    1918:	fc 01       	movw	r30, r24
    191a:	22 8d       	ldd	r18, Z+26	; 0x1a
    191c:	22 23       	and	r18, r18
    191e:	49 f0       	breq	.+18     	; 0x1932 <xQueuePeekFromISR+0x22>
    1920:	ec 01       	movw	r28, r24
		{
			traceQUEUE_PEEK_FROM_ISR( pxQueue );

			/* Remember the read position so it can be reset as nothing is
			actually being removed from the queue. */
			pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;
    1922:	06 81       	ldd	r16, Z+6	; 0x06
    1924:	17 81       	ldd	r17, Z+7	; 0x07
			prvCopyDataFromQueue( pxQueue, pvBuffer );
    1926:	0e 94 08 09 	call	0x1210	; 0x1210 <prvCopyDataFromQueue>
			pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;
    192a:	1f 83       	std	Y+7, r17	; 0x07
    192c:	0e 83       	std	Y+6, r16	; 0x06

			xReturn = pdPASS;
    192e:	81 e0       	ldi	r24, 0x01	; 1
    1930:	01 c0       	rjmp	.+2      	; 0x1934 <xQueuePeekFromISR+0x24>
		}
		else
		{
			xReturn = pdFAIL;
    1932:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1934:	df 91       	pop	r29
    1936:	cf 91       	pop	r28
    1938:	1f 91       	pop	r17
    193a:	0f 91       	pop	r16
    193c:	08 95       	ret

0000193e <uxQueueMessagesWaiting>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	taskENTER_CRITICAL();
    193e:	0f b6       	in	r0, 0x3f	; 63
    1940:	f8 94       	cli
    1942:	0f 92       	push	r0
	{
		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    1944:	fc 01       	movw	r30, r24
    1946:	82 8d       	ldd	r24, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    1948:	0f 90       	pop	r0
    194a:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    194c:	08 95       	ret

0000194e <uxQueueSpacesAvailable>:
UBaseType_t uxReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
    194e:	0f b6       	in	r0, 0x3f	; 63
    1950:	f8 94       	cli
    1952:	0f 92       	push	r0
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    1954:	fc 01       	movw	r30, r24
    1956:	22 8d       	ldd	r18, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    1958:	0f 90       	pop	r0
    195a:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
    195c:	83 8d       	ldd	r24, Z+27	; 0x1b
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    195e:	82 1b       	sub	r24, r18
    1960:	08 95       	ret

00001962 <uxQueueMessagesWaitingFromISR>:
{
UBaseType_t uxReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );
	uxReturn = pxQueue->uxMessagesWaiting;
    1962:	fc 01       	movw	r30, r24
    1964:	82 8d       	ldd	r24, Z+26	; 0x1a

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    1966:	08 95       	ret

00001968 <vQueueDelete>:

	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
	{
		/* The queue can only have been allocated dynamically - free it
		again. */
		vPortFree( pxQueue );
    1968:	0c 94 28 10 	jmp	0x2050	; 0x2050 <vPortFree>

0000196c <xQueueIsQueueEmptyFromISR>:
{
BaseType_t xReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );
	if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
    196c:	fc 01       	movw	r30, r24
    196e:	92 8d       	ldd	r25, Z+26	; 0x1a
	else
	{
		xReturn = pdFALSE;
	}

	return xReturn;
    1970:	81 e0       	ldi	r24, 0x01	; 1
    1972:	91 11       	cpse	r25, r1
    1974:	80 e0       	ldi	r24, 0x00	; 0
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    1976:	08 95       	ret

00001978 <xQueueIsQueueFullFromISR>:
	return xReturn;
}
/*-----------------------------------------------------------*/

BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
{
    1978:	fc 01       	movw	r30, r24
BaseType_t xReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );
	if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
    197a:	92 8d       	ldd	r25, Z+26	; 0x1a
	else
	{
		xReturn = pdFALSE;
	}

	return xReturn;
    197c:	81 e0       	ldi	r24, 0x01	; 1
    197e:	23 8d       	ldd	r18, Z+27	; 0x1b
    1980:	29 13       	cpse	r18, r25
    1982:	80 e0       	ldi	r24, 0x00	; 0
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    1984:	08 95       	ret

00001986 <xQueueCRSend>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRSend( QueueHandle_t xQueue, const void *pvItemToQueue, TickType_t xTicksToWait )
	{
    1986:	cf 93       	push	r28
    1988:	df 93       	push	r29
    198a:	ec 01       	movw	r28, r24
	Queue_t * const pxQueue = xQueue;

		/* If the queue is already full we may have to block.  A critical section
		is required to prevent an interrupt removing something from the queue
		between the check to see if the queue is full and blocking on the queue. */
		portDISABLE_INTERRUPTS();
    198c:	f8 94       	cli

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
    198e:	0f b6       	in	r0, 0x3f	; 63
    1990:	f8 94       	cli
    1992:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
    1994:	8a 8d       	ldd	r24, Y+26	; 0x1a
    1996:	9b 8d       	ldd	r25, Y+27	; 0x1b
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
    1998:	0f 90       	pop	r0
    199a:	0f be       	out	0x3f, r0	; 63
		/* If the queue is already full we may have to block.  A critical section
		is required to prevent an interrupt removing something from the queue
		between the check to see if the queue is full and blocking on the queue. */
		portDISABLE_INTERRUPTS();
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
    199c:	89 13       	cpse	r24, r25
    199e:	0f c0       	rjmp	.+30     	; 0x19be <xQueueCRSend+0x38>
			{
				/* The queue is full - do we want to block or just leave without
				posting? */
				if( xTicksToWait > ( TickType_t ) 0 )
    19a0:	41 15       	cp	r20, r1
    19a2:	51 05       	cpc	r21, r1
    19a4:	49 f0       	breq	.+18     	; 0x19b8 <xQueueCRSend+0x32>
				{
					/* As this is called from a coroutine we cannot block directly, but
					return indicating that we need to block. */
					vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToSend ) );
    19a6:	be 01       	movw	r22, r28
    19a8:	68 5f       	subi	r22, 0xF8	; 248
    19aa:	7f 4f       	sbci	r23, 0xFF	; 255
    19ac:	ca 01       	movw	r24, r20
    19ae:	0e 94 a2 0e 	call	0x1d44	; 0x1d44 <vCoRoutineAddToDelayedList>
					portENABLE_INTERRUPTS();
    19b2:	78 94       	sei
					return errQUEUE_BLOCKED;
    19b4:	8c ef       	ldi	r24, 0xFC	; 252
    19b6:	1b c0       	rjmp	.+54     	; 0x19ee <xQueueCRSend+0x68>
				}
				else
				{
					portENABLE_INTERRUPTS();
    19b8:	78 94       	sei
					return errQUEUE_FULL;
    19ba:	80 e0       	ldi	r24, 0x00	; 0
    19bc:	18 c0       	rjmp	.+48     	; 0x19ee <xQueueCRSend+0x68>
				}
			}
		}
		portENABLE_INTERRUPTS();
    19be:	78 94       	sei

		portDISABLE_INTERRUPTS();
    19c0:	f8 94       	cli
		{
			if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
    19c2:	8a 8d       	ldd	r24, Y+26	; 0x1a
    19c4:	89 17       	cp	r24, r25
    19c6:	88 f4       	brcc	.+34     	; 0x19ea <xQueueCRSend+0x64>
			{
				/* There is room in the queue, copy the data into the queue. */
				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
    19c8:	40 e0       	ldi	r20, 0x00	; 0
    19ca:	ce 01       	movw	r24, r28
    19cc:	0e 94 c0 08 	call	0x1180	; 0x1180 <prvCopyDataToQueue>
				xReturn = pdPASS;

				/* Were any co-routines waiting for data to become available? */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    19d0:	89 89       	ldd	r24, Y+17	; 0x11
    19d2:	81 11       	cpse	r24, r1
    19d4:	02 c0       	rjmp	.+4      	; 0x19da <xQueueCRSend+0x54>
		{
			if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
			{
				/* There is room in the queue, copy the data into the queue. */
				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
				xReturn = pdPASS;
    19d6:	81 e0       	ldi	r24, 0x01	; 1
    19d8:	09 c0       	rjmp	.+18     	; 0x19ec <xQueueCRSend+0x66>
				{
					/* In this instance the co-routine could be placed directly
					into the ready list as we are within a critical section.
					Instead the same pending ready list mechanism is used as if
					the event were caused from within an interrupt. */
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    19da:	ce 01       	movw	r24, r28
    19dc:	41 96       	adiw	r24, 0x11	; 17
    19de:	0e 94 d1 0f 	call	0x1fa2	; 0x1fa2 <xCoRoutineRemoveFromEventList>
    19e2:	88 23       	and	r24, r24
    19e4:	c1 f3       	breq	.-16     	; 0x19d6 <xQueueCRSend+0x50>
					{
						/* The co-routine waiting has a higher priority so record
						that a yield might be appropriate. */
						xReturn = errQUEUE_YIELD;
    19e6:	8b ef       	ldi	r24, 0xFB	; 251
    19e8:	01 c0       	rjmp	.+2      	; 0x19ec <xQueueCRSend+0x66>
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else
			{
				xReturn = errQUEUE_FULL;
    19ea:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		portENABLE_INTERRUPTS();
    19ec:	78 94       	sei

		return xReturn;
	}
    19ee:	df 91       	pop	r29
    19f0:	cf 91       	pop	r28
    19f2:	08 95       	ret

000019f4 <xQueueCRReceive>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRReceive( QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait )
	{
    19f4:	cf 93       	push	r28
    19f6:	df 93       	push	r29
    19f8:	ec 01       	movw	r28, r24
    19fa:	fb 01       	movw	r30, r22
	Queue_t * const pxQueue = xQueue;

		/* If the queue is already empty we may have to block.  A critical section
		is required to prevent an interrupt adding something to the queue
		between the check to see if the queue is empty and blocking on the queue. */
		portDISABLE_INTERRUPTS();
    19fc:	f8 94       	cli
		{
			if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
    19fe:	8a 8d       	ldd	r24, Y+26	; 0x1a
    1a00:	81 11       	cpse	r24, r1
    1a02:	0f c0       	rjmp	.+30     	; 0x1a22 <xQueueCRReceive+0x2e>
			{
				/* There are no messages in the queue, do we want to block or just
				leave with nothing? */
				if( xTicksToWait > ( TickType_t ) 0 )
    1a04:	41 15       	cp	r20, r1
    1a06:	51 05       	cpc	r21, r1
    1a08:	49 f0       	breq	.+18     	; 0x1a1c <xQueueCRReceive+0x28>
				{
					/* As this is a co-routine we cannot block directly, but return
					indicating that we need to block. */
					vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToReceive ) );
    1a0a:	be 01       	movw	r22, r28
    1a0c:	6f 5e       	subi	r22, 0xEF	; 239
    1a0e:	7f 4f       	sbci	r23, 0xFF	; 255
    1a10:	ca 01       	movw	r24, r20
    1a12:	0e 94 a2 0e 	call	0x1d44	; 0x1d44 <vCoRoutineAddToDelayedList>
					portENABLE_INTERRUPTS();
    1a16:	78 94       	sei
					return errQUEUE_BLOCKED;
    1a18:	8c ef       	ldi	r24, 0xFC	; 252
    1a1a:	30 c0       	rjmp	.+96     	; 0x1a7c <xQueueCRReceive+0x88>
				}
				else
				{
					portENABLE_INTERRUPTS();
    1a1c:	78 94       	sei
					return errQUEUE_FULL;
    1a1e:	80 e0       	ldi	r24, 0x00	; 0
    1a20:	2d c0       	rjmp	.+90     	; 0x1a7c <xQueueCRReceive+0x88>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		portENABLE_INTERRUPTS();
    1a22:	78 94       	sei

		portDISABLE_INTERRUPTS();
    1a24:	f8 94       	cli
		{
			if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    1a26:	8a 8d       	ldd	r24, Y+26	; 0x1a
    1a28:	88 23       	and	r24, r24
    1a2a:	31 f1       	breq	.+76     	; 0x1a78 <xQueueCRReceive+0x84>
			{
				/* Data is available from the queue. */
				pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;
    1a2c:	4c 8d       	ldd	r20, Y+28	; 0x1c
    1a2e:	50 e0       	ldi	r21, 0x00	; 0
    1a30:	2e 81       	ldd	r18, Y+6	; 0x06
    1a32:	3f 81       	ldd	r19, Y+7	; 0x07
    1a34:	24 0f       	add	r18, r20
    1a36:	35 1f       	adc	r19, r21
    1a38:	3f 83       	std	Y+7, r19	; 0x07
    1a3a:	2e 83       	std	Y+6, r18	; 0x06
				if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )
    1a3c:	8c 81       	ldd	r24, Y+4	; 0x04
    1a3e:	9d 81       	ldd	r25, Y+5	; 0x05
    1a40:	28 17       	cp	r18, r24
    1a42:	39 07       	cpc	r19, r25
    1a44:	20 f0       	brcs	.+8      	; 0x1a4e <xQueueCRReceive+0x5a>
				{
					pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
    1a46:	88 81       	ld	r24, Y
    1a48:	99 81       	ldd	r25, Y+1	; 0x01
    1a4a:	9f 83       	std	Y+7, r25	; 0x07
    1a4c:	8e 83       	std	Y+6, r24	; 0x06
				}
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
				--( pxQueue->uxMessagesWaiting );
    1a4e:	9a 8d       	ldd	r25, Y+26	; 0x1a
    1a50:	91 50       	subi	r25, 0x01	; 1
    1a52:	9a 8f       	std	Y+26, r25	; 0x1a
				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );
    1a54:	6e 81       	ldd	r22, Y+6	; 0x06
    1a56:	7f 81       	ldd	r23, Y+7	; 0x07
    1a58:	cf 01       	movw	r24, r30
    1a5a:	0e 94 2a 12 	call	0x2454	; 0x2454 <memcpy>

				xReturn = pdPASS;

				/* Were any co-routines waiting for space to become available? */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    1a5e:	88 85       	ldd	r24, Y+8	; 0x08
    1a60:	81 11       	cpse	r24, r1
    1a62:	02 c0       	rjmp	.+4      	; 0x1a68 <xQueueCRReceive+0x74>
					mtCOVERAGE_TEST_MARKER();
				}
				--( pxQueue->uxMessagesWaiting );
				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );

				xReturn = pdPASS;
    1a64:	81 e0       	ldi	r24, 0x01	; 1
    1a66:	09 c0       	rjmp	.+18     	; 0x1a7a <xQueueCRReceive+0x86>
				{
					/* In this instance the co-routine could be placed directly
					into the ready list as we are within a critical section.
					Instead the same pending ready list mechanism is used as if
					the event were caused from within an interrupt. */
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    1a68:	ce 01       	movw	r24, r28
    1a6a:	08 96       	adiw	r24, 0x08	; 8
    1a6c:	0e 94 d1 0f 	call	0x1fa2	; 0x1fa2 <xCoRoutineRemoveFromEventList>
    1a70:	88 23       	and	r24, r24
    1a72:	c1 f3       	breq	.-16     	; 0x1a64 <xQueueCRReceive+0x70>
					{
						xReturn = errQUEUE_YIELD;
    1a74:	8b ef       	ldi	r24, 0xFB	; 251
    1a76:	01 c0       	rjmp	.+2      	; 0x1a7a <xQueueCRReceive+0x86>
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else
			{
				xReturn = pdFAIL;
    1a78:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		portENABLE_INTERRUPTS();
    1a7a:	78 94       	sei

		return xReturn;
	}
    1a7c:	df 91       	pop	r29
    1a7e:	cf 91       	pop	r28
    1a80:	08 95       	ret

00001a82 <xQueueCRSendFromISR>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken )
	{
    1a82:	0f 93       	push	r16
    1a84:	1f 93       	push	r17
    1a86:	cf 93       	push	r28
    1a88:	8c 01       	movw	r16, r24
    1a8a:	c4 2f       	mov	r28, r20
	Queue_t * const pxQueue = xQueue;

		/* Cannot block within an ISR so if there is no space on the queue then
		exit without doing anything. */
		if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
    1a8c:	fc 01       	movw	r30, r24
    1a8e:	92 8d       	ldd	r25, Z+26	; 0x1a
    1a90:	83 8d       	ldd	r24, Z+27	; 0x1b
    1a92:	98 17       	cp	r25, r24
    1a94:	10 f0       	brcs	.+4      	; 0x1a9a <xQueueCRSendFromISR+0x18>
    1a96:	4c 2f       	mov	r20, r28
    1a98:	12 c0       	rjmp	.+36     	; 0x1abe <xQueueCRSendFromISR+0x3c>
		{
			prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
    1a9a:	40 e0       	ldi	r20, 0x00	; 0
    1a9c:	c8 01       	movw	r24, r16
    1a9e:	0e 94 c0 08 	call	0x1180	; 0x1180 <prvCopyDataToQueue>

			/* We only want to wake one co-routine per ISR, so check that a
			co-routine has not already been woken. */
			if( xCoRoutinePreviouslyWoken == pdFALSE )
    1aa2:	c1 11       	cpse	r28, r1
    1aa4:	f8 cf       	rjmp	.-16     	; 0x1a96 <xQueueCRSendFromISR+0x14>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1aa6:	f8 01       	movw	r30, r16
    1aa8:	81 89       	ldd	r24, Z+17	; 0x11
    1aaa:	88 23       	and	r24, r24
    1aac:	39 f0       	breq	.+14     	; 0x1abc <xQueueCRSendFromISR+0x3a>
				{
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    1aae:	c8 01       	movw	r24, r16
    1ab0:	41 96       	adiw	r24, 0x11	; 17
    1ab2:	0e 94 d1 0f 	call	0x1fa2	; 0x1fa2 <xCoRoutineRemoveFromEventList>
					{
						return pdTRUE;
    1ab6:	41 e0       	ldi	r20, 0x01	; 1
    1ab8:	81 11       	cpse	r24, r1
    1aba:	01 c0       	rjmp	.+2      	; 0x1abe <xQueueCRSendFromISR+0x3c>
    1abc:	40 e0       	ldi	r20, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xCoRoutinePreviouslyWoken;
	}
    1abe:	84 2f       	mov	r24, r20
    1ac0:	cf 91       	pop	r28
    1ac2:	1f 91       	pop	r17
    1ac4:	0f 91       	pop	r16
    1ac6:	08 95       	ret

00001ac8 <xQueueCRReceiveFromISR>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue, void *pvBuffer, BaseType_t *pxCoRoutineWoken )
	{
    1ac8:	0f 93       	push	r16
    1aca:	1f 93       	push	r17
    1acc:	cf 93       	push	r28
    1ace:	df 93       	push	r29
    1ad0:	fc 01       	movw	r30, r24
	BaseType_t xReturn;
	Queue_t * const pxQueue = xQueue;

		/* We cannot block from an ISR, so check there is data available. If
		not then just leave without doing anything. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    1ad2:	82 8d       	ldd	r24, Z+26	; 0x1a
    1ad4:	88 23       	and	r24, r24
    1ad6:	79 f1       	breq	.+94     	; 0x1b36 <xQueueCRReceiveFromISR+0x6e>
		{
			/* Copy the data from the queue. */
			pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;
    1ad8:	24 8d       	ldd	r18, Z+28	; 0x1c
    1ada:	30 e0       	ldi	r19, 0x00	; 0
    1adc:	a6 81       	ldd	r26, Z+6	; 0x06
    1ade:	b7 81       	ldd	r27, Z+7	; 0x07
    1ae0:	a2 0f       	add	r26, r18
    1ae2:	b3 1f       	adc	r27, r19
    1ae4:	b7 83       	std	Z+7, r27	; 0x07
    1ae6:	a6 83       	std	Z+6, r26	; 0x06
			if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )
    1ae8:	84 81       	ldd	r24, Z+4	; 0x04
    1aea:	95 81       	ldd	r25, Z+5	; 0x05
    1aec:	a8 17       	cp	r26, r24
    1aee:	b9 07       	cpc	r27, r25
    1af0:	20 f0       	brcs	.+8      	; 0x1afa <xQueueCRReceiveFromISR+0x32>
			{
				pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
    1af2:	80 81       	ld	r24, Z
    1af4:	91 81       	ldd	r25, Z+1	; 0x01
    1af6:	97 83       	std	Z+7, r25	; 0x07
    1af8:	86 83       	std	Z+6, r24	; 0x06
    1afa:	8a 01       	movw	r16, r20
    1afc:	cb 01       	movw	r24, r22
    1afe:	ef 01       	movw	r28, r30
			}
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
			--( pxQueue->uxMessagesWaiting );
    1b00:	42 8d       	ldd	r20, Z+26	; 0x1a
    1b02:	41 50       	subi	r20, 0x01	; 1
    1b04:	42 8f       	std	Z+26, r20	; 0x1a
			( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );
    1b06:	66 81       	ldd	r22, Z+6	; 0x06
    1b08:	77 81       	ldd	r23, Z+7	; 0x07
    1b0a:	a9 01       	movw	r20, r18
    1b0c:	0e 94 2a 12 	call	0x2454	; 0x2454 <memcpy>

			if( ( *pxCoRoutineWoken ) == pdFALSE )
    1b10:	f8 01       	movw	r30, r16
    1b12:	80 81       	ld	r24, Z
    1b14:	88 23       	and	r24, r24
    1b16:	11 f0       	breq	.+4      	; 0x1b1c <xQueueCRReceiveFromISR+0x54>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			xReturn = pdPASS;
    1b18:	81 e0       	ldi	r24, 0x01	; 1
    1b1a:	0e c0       	rjmp	.+28     	; 0x1b38 <xQueueCRReceiveFromISR+0x70>
			--( pxQueue->uxMessagesWaiting );
			( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );

			if( ( *pxCoRoutineWoken ) == pdFALSE )
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    1b1c:	88 85       	ldd	r24, Y+8	; 0x08
    1b1e:	88 23       	and	r24, r24
    1b20:	d9 f3       	breq	.-10     	; 0x1b18 <xQueueCRReceiveFromISR+0x50>
				{
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    1b22:	ce 01       	movw	r24, r28
    1b24:	08 96       	adiw	r24, 0x08	; 8
    1b26:	0e 94 d1 0f 	call	0x1fa2	; 0x1fa2 <xCoRoutineRemoveFromEventList>
    1b2a:	88 23       	and	r24, r24
    1b2c:	a9 f3       	breq	.-22     	; 0x1b18 <xQueueCRReceiveFromISR+0x50>
					{
						*pxCoRoutineWoken = pdTRUE;
    1b2e:	81 e0       	ldi	r24, 0x01	; 1
    1b30:	f8 01       	movw	r30, r16
    1b32:	80 83       	st	Z, r24
    1b34:	01 c0       	rjmp	.+2      	; 0x1b38 <xQueueCRReceiveFromISR+0x70>

			xReturn = pdPASS;
		}
		else
		{
			xReturn = pdFAIL;
    1b36:	80 e0       	ldi	r24, 0x00	; 0
		}

		return xReturn;
	}
    1b38:	df 91       	pop	r29
    1b3a:	cf 91       	pop	r28
    1b3c:	1f 91       	pop	r17
    1b3e:	0f 91       	pop	r16
    1b40:	08 95       	ret

00001b42 <vListInitialise>:
/*-----------------------------------------------------------
 * PUBLIC LIST API documented in list.h
 *----------------------------------------------------------*/

void vListInitialise( List_t * const pxList )
{
    1b42:	fc 01       	movw	r30, r24
	/* The list structure contains a list item which is used to mark the
	end of the list.  To initialise the list the list end is inserted
	as the only list entry. */
	pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );			/*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
    1b44:	03 96       	adiw	r24, 0x03	; 3
    1b46:	92 83       	std	Z+2, r25	; 0x02
    1b48:	81 83       	std	Z+1, r24	; 0x01

	/* The list end value is the highest possible value in the list to
	ensure it remains at the end of the list. */
	pxList->xListEnd.xItemValue = portMAX_DELAY;
    1b4a:	2f ef       	ldi	r18, 0xFF	; 255
    1b4c:	3f ef       	ldi	r19, 0xFF	; 255
    1b4e:	34 83       	std	Z+4, r19	; 0x04
    1b50:	23 83       	std	Z+3, r18	; 0x03

	/* The list end next and previous pointers point to itself so we know
	when the list is empty. */
	pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );	/*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
    1b52:	96 83       	std	Z+6, r25	; 0x06
    1b54:	85 83       	std	Z+5, r24	; 0x05
	pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );/*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
    1b56:	90 87       	std	Z+8, r25	; 0x08
    1b58:	87 83       	std	Z+7, r24	; 0x07

	pxList->uxNumberOfItems = ( UBaseType_t ) 0U;
    1b5a:	10 82       	st	Z, r1
    1b5c:	08 95       	ret

00001b5e <vListInitialiseItem>:
/*-----------------------------------------------------------*/

void vListInitialiseItem( ListItem_t * const pxItem )
{
	/* Make sure the list item is not recorded as being on a list. */
	pxItem->pxContainer = NULL;
    1b5e:	fc 01       	movw	r30, r24
    1b60:	11 86       	std	Z+9, r1	; 0x09
    1b62:	10 86       	std	Z+8, r1	; 0x08
    1b64:	08 95       	ret

00001b66 <vListInsertEnd>:
	listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
}
/*-----------------------------------------------------------*/

void vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem )
{
    1b66:	cf 93       	push	r28
    1b68:	df 93       	push	r29
    1b6a:	9c 01       	movw	r18, r24
    1b6c:	fb 01       	movw	r30, r22
ListItem_t * const pxIndex = pxList->pxIndex;
    1b6e:	dc 01       	movw	r26, r24
    1b70:	11 96       	adiw	r26, 0x01	; 1
    1b72:	cd 91       	ld	r28, X+
    1b74:	dc 91       	ld	r29, X
    1b76:	12 97       	sbiw	r26, 0x02	; 2
	listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );

	/* Insert a new list item into pxList, but rather than sort the list,
	makes the new list item the last item to be removed by a call to
	listGET_OWNER_OF_NEXT_ENTRY(). */
	pxNewListItem->pxNext = pxIndex;
    1b78:	d3 83       	std	Z+3, r29	; 0x03
    1b7a:	c2 83       	std	Z+2, r28	; 0x02
	pxNewListItem->pxPrevious = pxIndex->pxPrevious;
    1b7c:	8c 81       	ldd	r24, Y+4	; 0x04
    1b7e:	9d 81       	ldd	r25, Y+5	; 0x05
    1b80:	95 83       	std	Z+5, r25	; 0x05
    1b82:	84 83       	std	Z+4, r24	; 0x04

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	pxIndex->pxPrevious->pxNext = pxNewListItem;
    1b84:	8c 81       	ldd	r24, Y+4	; 0x04
    1b86:	9d 81       	ldd	r25, Y+5	; 0x05
    1b88:	dc 01       	movw	r26, r24
    1b8a:	13 96       	adiw	r26, 0x03	; 3
    1b8c:	7c 93       	st	X, r23
    1b8e:	6e 93       	st	-X, r22
    1b90:	12 97       	sbiw	r26, 0x02	; 2
	pxIndex->pxPrevious = pxNewListItem;
    1b92:	7d 83       	std	Y+5, r23	; 0x05
    1b94:	6c 83       	std	Y+4, r22	; 0x04

	/* Remember which list the item is in. */
	pxNewListItem->pxContainer = pxList;
    1b96:	31 87       	std	Z+9, r19	; 0x09
    1b98:	20 87       	std	Z+8, r18	; 0x08

	( pxList->uxNumberOfItems )++;
    1b9a:	f9 01       	movw	r30, r18
    1b9c:	80 81       	ld	r24, Z
    1b9e:	8f 5f       	subi	r24, 0xFF	; 255
    1ba0:	80 83       	st	Z, r24
}
    1ba2:	df 91       	pop	r29
    1ba4:	cf 91       	pop	r28
    1ba6:	08 95       	ret

00001ba8 <vListInsert>:
/*-----------------------------------------------------------*/

void vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem )
{
    1ba8:	0f 93       	push	r16
    1baa:	1f 93       	push	r17
    1bac:	cf 93       	push	r28
    1bae:	df 93       	push	r29
    1bb0:	8c 01       	movw	r16, r24
    1bb2:	fb 01       	movw	r30, r22
ListItem_t *pxIterator;
const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;
    1bb4:	80 81       	ld	r24, Z
    1bb6:	91 81       	ldd	r25, Z+1	; 0x01
	new list item should be placed after it.  This ensures that TCBs which are
	stored in ready lists (all of which have the same xItemValue value) get a
	share of the CPU.  However, if the xItemValue is the same as the back marker
	the iteration loop below will not end.  Therefore the value is checked
	first, and the algorithm slightly modified if necessary. */
	if( xValueOfInsertion == portMAX_DELAY )
    1bb8:	8f 3f       	cpi	r24, 0xFF	; 255
    1bba:	2f ef       	ldi	r18, 0xFF	; 255
    1bbc:	92 07       	cpc	r25, r18
    1bbe:	21 f4       	brne	.+8      	; 0x1bc8 <vListInsert+0x20>
	{
		pxIterator = pxList->xListEnd.pxPrevious;
    1bc0:	e8 01       	movw	r28, r16
    1bc2:	af 81       	ldd	r26, Y+7	; 0x07
    1bc4:	b8 85       	ldd	r27, Y+8	; 0x08
    1bc6:	0e c0       	rjmp	.+28     	; 0x1be4 <vListInsert+0x3c>
			4) Using a queue or semaphore before it has been initialised or
			   before the scheduler has been started (are interrupts firing
			   before vTaskStartScheduler() has been called?).
		**********************************************************************/

		for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext ) /*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. *//*lint !e440 The iterator moves to a different value, not xValueOfInsertion. */
    1bc8:	d8 01       	movw	r26, r16
    1bca:	13 96       	adiw	r26, 0x03	; 3
    1bcc:	12 96       	adiw	r26, 0x02	; 2
    1bce:	2d 91       	ld	r18, X+
    1bd0:	3c 91       	ld	r19, X
    1bd2:	13 97       	sbiw	r26, 0x03	; 3
    1bd4:	e9 01       	movw	r28, r18
    1bd6:	48 81       	ld	r20, Y
    1bd8:	59 81       	ldd	r21, Y+1	; 0x01
    1bda:	84 17       	cp	r24, r20
    1bdc:	95 07       	cpc	r25, r21
    1bde:	10 f0       	brcs	.+4      	; 0x1be4 <vListInsert+0x3c>
    1be0:	d9 01       	movw	r26, r18
    1be2:	f4 cf       	rjmp	.-24     	; 0x1bcc <vListInsert+0x24>
			/* There is nothing to do here, just iterating to the wanted
			insertion position. */
		}
	}

	pxNewListItem->pxNext = pxIterator->pxNext;
    1be4:	12 96       	adiw	r26, 0x02	; 2
    1be6:	8d 91       	ld	r24, X+
    1be8:	9c 91       	ld	r25, X
    1bea:	13 97       	sbiw	r26, 0x03	; 3
    1bec:	93 83       	std	Z+3, r25	; 0x03
    1bee:	82 83       	std	Z+2, r24	; 0x02
	pxNewListItem->pxNext->pxPrevious = pxNewListItem;
    1bf0:	ec 01       	movw	r28, r24
    1bf2:	fd 83       	std	Y+5, r31	; 0x05
    1bf4:	ec 83       	std	Y+4, r30	; 0x04
	pxNewListItem->pxPrevious = pxIterator;
    1bf6:	b5 83       	std	Z+5, r27	; 0x05
    1bf8:	a4 83       	std	Z+4, r26	; 0x04
	pxIterator->pxNext = pxNewListItem;
    1bfa:	13 96       	adiw	r26, 0x03	; 3
    1bfc:	fc 93       	st	X, r31
    1bfe:	ee 93       	st	-X, r30
    1c00:	12 97       	sbiw	r26, 0x02	; 2

	/* Remember which list the item is in.  This allows fast removal of the
	item later. */
	pxNewListItem->pxContainer = pxList;
    1c02:	11 87       	std	Z+9, r17	; 0x09
    1c04:	00 87       	std	Z+8, r16	; 0x08

	( pxList->uxNumberOfItems )++;
    1c06:	f8 01       	movw	r30, r16
    1c08:	80 81       	ld	r24, Z
    1c0a:	8f 5f       	subi	r24, 0xFF	; 255
    1c0c:	80 83       	st	Z, r24
}
    1c0e:	df 91       	pop	r29
    1c10:	cf 91       	pop	r28
    1c12:	1f 91       	pop	r17
    1c14:	0f 91       	pop	r16
    1c16:	08 95       	ret

00001c18 <uxListRemove>:
/*-----------------------------------------------------------*/

UBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )
{
    1c18:	cf 93       	push	r28
    1c1a:	df 93       	push	r29
    1c1c:	fc 01       	movw	r30, r24
/* The list item knows which list it is in.  Obtain the list from the list
item. */
List_t * const pxList = pxItemToRemove->pxContainer;
    1c1e:	a0 85       	ldd	r26, Z+8	; 0x08
    1c20:	b1 85       	ldd	r27, Z+9	; 0x09

	pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;
    1c22:	82 81       	ldd	r24, Z+2	; 0x02
    1c24:	93 81       	ldd	r25, Z+3	; 0x03
    1c26:	24 81       	ldd	r18, Z+4	; 0x04
    1c28:	35 81       	ldd	r19, Z+5	; 0x05
    1c2a:	ec 01       	movw	r28, r24
    1c2c:	3d 83       	std	Y+5, r19	; 0x05
    1c2e:	2c 83       	std	Y+4, r18	; 0x04
	pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;
    1c30:	c4 81       	ldd	r28, Z+4	; 0x04
    1c32:	d5 81       	ldd	r29, Z+5	; 0x05
    1c34:	9b 83       	std	Y+3, r25	; 0x03
    1c36:	8a 83       	std	Y+2, r24	; 0x02

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	/* Make sure the index is left pointing to a valid item. */
	if( pxList->pxIndex == pxItemToRemove )
    1c38:	11 96       	adiw	r26, 0x01	; 1
    1c3a:	8d 91       	ld	r24, X+
    1c3c:	9c 91       	ld	r25, X
    1c3e:	12 97       	sbiw	r26, 0x02	; 2
    1c40:	e8 17       	cp	r30, r24
    1c42:	f9 07       	cpc	r31, r25
    1c44:	21 f4       	brne	.+8      	; 0x1c4e <uxListRemove+0x36>
	{
		pxList->pxIndex = pxItemToRemove->pxPrevious;
    1c46:	12 96       	adiw	r26, 0x02	; 2
    1c48:	dc 93       	st	X, r29
    1c4a:	ce 93       	st	-X, r28
    1c4c:	11 97       	sbiw	r26, 0x01	; 1
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxItemToRemove->pxContainer = NULL;
    1c4e:	11 86       	std	Z+9, r1	; 0x09
    1c50:	10 86       	std	Z+8, r1	; 0x08
	( pxList->uxNumberOfItems )--;
    1c52:	8c 91       	ld	r24, X
    1c54:	81 50       	subi	r24, 0x01	; 1
    1c56:	8c 93       	st	X, r24

	return pxList->uxNumberOfItems;
    1c58:	8c 91       	ld	r24, X
}
    1c5a:	df 91       	pop	r29
    1c5c:	cf 91       	pop	r28
    1c5e:	08 95       	ret

00001c60 <xCoRoutineCreate>:
static void prvCheckDelayedList( void );

/*-----------------------------------------------------------*/

BaseType_t xCoRoutineCreate( crCOROUTINE_CODE pxCoRoutineCode, UBaseType_t uxPriority, UBaseType_t uxIndex )
{
    1c60:	cf 92       	push	r12
    1c62:	df 92       	push	r13
    1c64:	ef 92       	push	r14
    1c66:	ff 92       	push	r15
    1c68:	1f 93       	push	r17
    1c6a:	cf 93       	push	r28
    1c6c:	df 93       	push	r29
    1c6e:	6c 01       	movw	r12, r24
    1c70:	16 2f       	mov	r17, r22
    1c72:	f4 2e       	mov	r15, r20
BaseType_t xReturn;
CRCB_t *pxCoRoutine;

	/* Allocate the memory that will store the co-routine control block. */
	pxCoRoutine = ( CRCB_t * ) pvPortMalloc( sizeof( CRCB_t ) );
    1c74:	8a e1       	ldi	r24, 0x1A	; 26
    1c76:	90 e0       	ldi	r25, 0x00	; 0
    1c78:	0e 94 f6 0f 	call	0x1fec	; 0x1fec <pvPortMalloc>
    1c7c:	ec 01       	movw	r28, r24
	if( pxCoRoutine )
    1c7e:	89 2b       	or	r24, r25
    1c80:	09 f4       	brne	.+2      	; 0x1c84 <xCoRoutineCreate+0x24>
    1c82:	57 c0       	rjmp	.+174    	; 0x1d32 <xCoRoutineCreate+0xd2>
	{
		/* If pxCurrentCoRoutine is NULL then this is the first co-routine to
		be created and the co-routine data structures need initialising. */
		if( pxCurrentCoRoutine == NULL )
    1c84:	80 91 8a 01 	lds	r24, 0x018A	; 0x80018a <pxCurrentCoRoutine>
    1c88:	90 91 8b 01 	lds	r25, 0x018B	; 0x80018b <pxCurrentCoRoutine+0x1>
    1c8c:	89 2b       	or	r24, r25
    1c8e:	21 f5       	brne	.+72     	; 0x1cd8 <xCoRoutineCreate+0x78>
		{
			pxCurrentCoRoutine = pxCoRoutine;
    1c90:	d0 93 8b 01 	sts	0x018B, r29	; 0x80018b <pxCurrentCoRoutine+0x1>
    1c94:	c0 93 8a 01 	sts	0x018A, r28	; 0x80018a <pxCurrentCoRoutine>
{
UBaseType_t uxPriority;

	for( uxPriority = 0; uxPriority < configMAX_CO_ROUTINE_PRIORITIES; uxPriority++ )
	{
		vListInitialise( ( List_t * ) &( pxReadyCoRoutineLists[ uxPriority ] ) );
    1c98:	82 eb       	ldi	r24, 0xB2	; 178
    1c9a:	91 e0       	ldi	r25, 0x01	; 1
    1c9c:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
    1ca0:	8b eb       	ldi	r24, 0xBB	; 187
    1ca2:	91 e0       	ldi	r25, 0x01	; 1
    1ca4:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	}

	vListInitialise( ( List_t * ) &xDelayedCoRoutineList1 );
    1ca8:	89 ea       	ldi	r24, 0xA9	; 169
    1caa:	91 e0       	ldi	r25, 0x01	; 1
    1cac:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	vListInitialise( ( List_t * ) &xDelayedCoRoutineList2 );
    1cb0:	80 ea       	ldi	r24, 0xA0	; 160
    1cb2:	91 e0       	ldi	r25, 0x01	; 1
    1cb4:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>
	vListInitialise( ( List_t * ) &xPendingReadyCoRoutineList );
    1cb8:	83 e9       	ldi	r24, 0x93	; 147
    1cba:	91 e0       	ldi	r25, 0x01	; 1
    1cbc:	0e 94 a1 0d 	call	0x1b42	; 0x1b42 <vListInitialise>

	/* Start with pxDelayedCoRoutineList using list1 and the
	pxOverflowDelayedCoRoutineList using list2. */
	pxDelayedCoRoutineList = &xDelayedCoRoutineList1;
    1cc0:	89 ea       	ldi	r24, 0xA9	; 169
    1cc2:	91 e0       	ldi	r25, 0x01	; 1
    1cc4:	90 93 9f 01 	sts	0x019F, r25	; 0x80019f <pxDelayedCoRoutineList+0x1>
    1cc8:	80 93 9e 01 	sts	0x019E, r24	; 0x80019e <pxDelayedCoRoutineList>
	pxOverflowDelayedCoRoutineList = &xDelayedCoRoutineList2;
    1ccc:	80 ea       	ldi	r24, 0xA0	; 160
    1cce:	91 e0       	ldi	r25, 0x01	; 1
    1cd0:	90 93 9d 01 	sts	0x019D, r25	; 0x80019d <pxOverflowDelayedCoRoutineList+0x1>
    1cd4:	80 93 9c 01 	sts	0x019C, r24	; 0x80019c <pxOverflowDelayedCoRoutineList>
    1cd8:	11 11       	cpse	r17, r1
    1cda:	11 e0       	ldi	r17, 0x01	; 1
		{
			uxPriority = configMAX_CO_ROUTINE_PRIORITIES - 1;
		}

		/* Fill out the co-routine control block from the function parameters. */
		pxCoRoutine->uxState = corINITIAL_STATE;
    1cdc:	19 8e       	std	Y+25, r1	; 0x19
    1cde:	18 8e       	std	Y+24, r1	; 0x18
		pxCoRoutine->uxPriority = uxPriority;
    1ce0:	1e 8b       	std	Y+22, r17	; 0x16
		pxCoRoutine->uxIndex = uxIndex;
    1ce2:	ff 8a       	std	Y+23, r15	; 0x17
		pxCoRoutine->pxCoRoutineFunction = pxCoRoutineCode;
    1ce4:	fe 01       	movw	r30, r28
    1ce6:	c1 92       	st	Z+, r12
    1ce8:	d1 92       	st	Z+, r13
    1cea:	7f 01       	movw	r14, r30

		/* Initialise all the other co-routine control block parameters. */
		vListInitialiseItem( &( pxCoRoutine->xGenericListItem ) );
    1cec:	cf 01       	movw	r24, r30
    1cee:	0e 94 af 0d 	call	0x1b5e	; 0x1b5e <vListInitialiseItem>
		vListInitialiseItem( &( pxCoRoutine->xEventListItem ) );
    1cf2:	ce 01       	movw	r24, r28
    1cf4:	0c 96       	adiw	r24, 0x0c	; 12
    1cf6:	0e 94 af 0d 	call	0x1b5e	; 0x1b5e <vListInitialiseItem>

		/* Set the co-routine control block as a link back from the ListItem_t.
		This is so we can get back to the containing CRCB from a generic item
		in a list. */
		listSET_LIST_ITEM_OWNER( &( pxCoRoutine->xGenericListItem ), pxCoRoutine );
    1cfa:	d9 87       	std	Y+9, r29	; 0x09
    1cfc:	c8 87       	std	Y+8, r28	; 0x08
		listSET_LIST_ITEM_OWNER( &( pxCoRoutine->xEventListItem ), pxCoRoutine );
    1cfe:	db 8b       	std	Y+19, r29	; 0x13
    1d00:	ca 8b       	std	Y+18, r28	; 0x12

		/* Event lists are always in priority order. */
		listSET_LIST_ITEM_VALUE( &( pxCoRoutine->xEventListItem ), ( ( TickType_t ) configMAX_CO_ROUTINE_PRIORITIES - ( TickType_t ) uxPriority ) );
    1d02:	82 e0       	ldi	r24, 0x02	; 2
    1d04:	90 e0       	ldi	r25, 0x00	; 0
    1d06:	81 1b       	sub	r24, r17
    1d08:	91 09       	sbc	r25, r1
    1d0a:	9d 87       	std	Y+13, r25	; 0x0d
    1d0c:	8c 87       	std	Y+12, r24	; 0x0c

		/* Now the co-routine has been initialised it can be added to the ready
		list at the correct priority. */
		prvAddCoRoutineToReadyQueue( pxCoRoutine );
    1d0e:	8e 89       	ldd	r24, Y+22	; 0x16
    1d10:	90 91 92 01 	lds	r25, 0x0192	; 0x800192 <uxTopCoRoutineReadyPriority>
    1d14:	98 17       	cp	r25, r24
    1d16:	10 f4       	brcc	.+4      	; 0x1d1c <xCoRoutineCreate+0xbc>
    1d18:	80 93 92 01 	sts	0x0192, r24	; 0x800192 <uxTopCoRoutineReadyPriority>
    1d1c:	f9 e0       	ldi	r31, 0x09	; 9
    1d1e:	8f 9f       	mul	r24, r31
    1d20:	c0 01       	movw	r24, r0
    1d22:	11 24       	eor	r1, r1
    1d24:	b7 01       	movw	r22, r14
    1d26:	8e 54       	subi	r24, 0x4E	; 78
    1d28:	9e 4f       	sbci	r25, 0xFE	; 254
    1d2a:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

		xReturn = pdPASS;
    1d2e:	81 e0       	ldi	r24, 0x01	; 1
    1d30:	01 c0       	rjmp	.+2      	; 0x1d34 <xCoRoutineCreate+0xd4>
	}
	else
	{
		xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    1d32:	8f ef       	ldi	r24, 0xFF	; 255
	}

	return xReturn;
}
    1d34:	df 91       	pop	r29
    1d36:	cf 91       	pop	r28
    1d38:	1f 91       	pop	r17
    1d3a:	ff 90       	pop	r15
    1d3c:	ef 90       	pop	r14
    1d3e:	df 90       	pop	r13
    1d40:	cf 90       	pop	r12
    1d42:	08 95       	ret

00001d44 <vCoRoutineAddToDelayedList>:
/*-----------------------------------------------------------*/

void vCoRoutineAddToDelayedList( TickType_t xTicksToDelay, List_t *pxEventList )
{
    1d44:	0f 93       	push	r16
    1d46:	1f 93       	push	r17
    1d48:	cf 93       	push	r28
    1d4a:	df 93       	push	r29
    1d4c:	8b 01       	movw	r16, r22
TickType_t xTimeToWake;

	/* Calculate the time to wake - this may overflow but this is
	not a problem. */
	xTimeToWake = xCoRoutineTickCount + xTicksToDelay;
    1d4e:	c0 91 90 01 	lds	r28, 0x0190	; 0x800190 <xCoRoutineTickCount>
    1d52:	d0 91 91 01 	lds	r29, 0x0191	; 0x800191 <xCoRoutineTickCount+0x1>
    1d56:	c8 0f       	add	r28, r24
    1d58:	d9 1f       	adc	r29, r25

	/* We must remove ourselves from the ready list before adding
	ourselves to the blocked list as the same list item is used for
	both lists. */
	( void ) uxListRemove( ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );
    1d5a:	80 91 8a 01 	lds	r24, 0x018A	; 0x80018a <pxCurrentCoRoutine>
    1d5e:	90 91 8b 01 	lds	r25, 0x018B	; 0x80018b <pxCurrentCoRoutine+0x1>
    1d62:	02 96       	adiw	r24, 0x02	; 2
    1d64:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>

	/* The list item will be inserted in wake time order. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentCoRoutine->xGenericListItem ), xTimeToWake );
    1d68:	e0 91 8a 01 	lds	r30, 0x018A	; 0x80018a <pxCurrentCoRoutine>
    1d6c:	f0 91 8b 01 	lds	r31, 0x018B	; 0x80018b <pxCurrentCoRoutine+0x1>
    1d70:	d3 83       	std	Z+3, r29	; 0x03
    1d72:	c2 83       	std	Z+2, r28	; 0x02

	if( xTimeToWake < xCoRoutineTickCount )
    1d74:	80 91 90 01 	lds	r24, 0x0190	; 0x800190 <xCoRoutineTickCount>
    1d78:	90 91 91 01 	lds	r25, 0x0191	; 0x800191 <xCoRoutineTickCount+0x1>
    1d7c:	bf 01       	movw	r22, r30
    1d7e:	6e 5f       	subi	r22, 0xFE	; 254
    1d80:	7f 4f       	sbci	r23, 0xFF	; 255
    1d82:	c8 17       	cp	r28, r24
    1d84:	d9 07       	cpc	r29, r25
    1d86:	28 f4       	brcc	.+10     	; 0x1d92 <vCoRoutineAddToDelayedList+0x4e>
	{
		/* Wake time has overflowed.  Place this item in the
		overflow list. */
		vListInsert( ( List_t * ) pxOverflowDelayedCoRoutineList, ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );
    1d88:	80 91 9c 01 	lds	r24, 0x019C	; 0x80019c <pxOverflowDelayedCoRoutineList>
    1d8c:	90 91 9d 01 	lds	r25, 0x019D	; 0x80019d <pxOverflowDelayedCoRoutineList+0x1>
    1d90:	04 c0       	rjmp	.+8      	; 0x1d9a <vCoRoutineAddToDelayedList+0x56>
	}
	else
	{
		/* The wake time has not overflowed, so we can use the
		current block list. */
		vListInsert( ( List_t * ) pxDelayedCoRoutineList, ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );
    1d92:	80 91 9e 01 	lds	r24, 0x019E	; 0x80019e <pxDelayedCoRoutineList>
    1d96:	90 91 9f 01 	lds	r25, 0x019F	; 0x80019f <pxDelayedCoRoutineList+0x1>
    1d9a:	0e 94 d4 0d 	call	0x1ba8	; 0x1ba8 <vListInsert>
	}

	if( pxEventList )
    1d9e:	01 15       	cp	r16, r1
    1da0:	11 05       	cpc	r17, r1
    1da2:	69 f0       	breq	.+26     	; 0x1dbe <vCoRoutineAddToDelayedList+0x7a>
	{
		/* Also add the co-routine to an event list.  If this is done then the
		function must be called with interrupts disabled. */
		vListInsert( pxEventList, &( pxCurrentCoRoutine->xEventListItem ) );
    1da4:	60 91 8a 01 	lds	r22, 0x018A	; 0x80018a <pxCurrentCoRoutine>
    1da8:	70 91 8b 01 	lds	r23, 0x018B	; 0x80018b <pxCurrentCoRoutine+0x1>
    1dac:	64 5f       	subi	r22, 0xF4	; 244
    1dae:	7f 4f       	sbci	r23, 0xFF	; 255
    1db0:	c8 01       	movw	r24, r16
	}
}
    1db2:	df 91       	pop	r29
    1db4:	cf 91       	pop	r28
    1db6:	1f 91       	pop	r17
    1db8:	0f 91       	pop	r16

	if( pxEventList )
	{
		/* Also add the co-routine to an event list.  If this is done then the
		function must be called with interrupts disabled. */
		vListInsert( pxEventList, &( pxCurrentCoRoutine->xEventListItem ) );
    1dba:	0c 94 d4 0d 	jmp	0x1ba8	; 0x1ba8 <vListInsert>
	}
}
    1dbe:	df 91       	pop	r29
    1dc0:	cf 91       	pop	r28
    1dc2:	1f 91       	pop	r17
    1dc4:	0f 91       	pop	r16
    1dc6:	08 95       	ret

00001dc8 <vCoRoutineSchedule>:
	xLastTickCount = xCoRoutineTickCount;
}
/*-----------------------------------------------------------*/

void vCoRoutineSchedule( void )
{
    1dc8:	ff 92       	push	r15
    1dca:	0f 93       	push	r16
    1dcc:	1f 93       	push	r17
    1dce:	cf 93       	push	r28
    1dd0:	df 93       	push	r29
			( void ) uxListRemove( &( pxUnblockedCRCB->xEventListItem ) );
		}
		portENABLE_INTERRUPTS();

		( void ) uxListRemove( &( pxUnblockedCRCB->xGenericListItem ) );
		prvAddCoRoutineToReadyQueue( pxUnblockedCRCB );
    1dd2:	99 e0       	ldi	r25, 0x09	; 9
    1dd4:	f9 2e       	mov	r15, r25
static void prvCheckPendingReadyList( void )
{
	/* Are there any co-routines waiting to get moved to the ready list?  These
	are co-routines that have been readied by an ISR.  The ISR cannot access
	the	ready lists itself. */
	while( listLIST_IS_EMPTY( &xPendingReadyCoRoutineList ) == pdFALSE )
    1dd6:	80 91 93 01 	lds	r24, 0x0193	; 0x800193 <xPendingReadyCoRoutineList>
    1dda:	88 23       	and	r24, r24
    1ddc:	11 f1       	breq	.+68     	; 0x1e22 <vCoRoutineSchedule+0x5a>
	{
		CRCB_t *pxUnblockedCRCB;

		/* The pending ready list can be accessed by an ISR. */
		portDISABLE_INTERRUPTS();
    1dde:	f8 94       	cli
		{
			pxUnblockedCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( (&xPendingReadyCoRoutineList) );
    1de0:	e0 91 98 01 	lds	r30, 0x0198	; 0x800198 <xPendingReadyCoRoutineList+0x5>
    1de4:	f0 91 99 01 	lds	r31, 0x0199	; 0x800199 <xPendingReadyCoRoutineList+0x6>
    1de8:	c6 81       	ldd	r28, Z+6	; 0x06
    1dea:	d7 81       	ldd	r29, Z+7	; 0x07
			( void ) uxListRemove( &( pxUnblockedCRCB->xEventListItem ) );
    1dec:	ce 01       	movw	r24, r28
    1dee:	0c 96       	adiw	r24, 0x0c	; 12
    1df0:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
		}
		portENABLE_INTERRUPTS();
    1df4:	78 94       	sei

		( void ) uxListRemove( &( pxUnblockedCRCB->xGenericListItem ) );
    1df6:	8e 01       	movw	r16, r28
    1df8:	0e 5f       	subi	r16, 0xFE	; 254
    1dfa:	1f 4f       	sbci	r17, 0xFF	; 255
    1dfc:	c8 01       	movw	r24, r16
    1dfe:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
		prvAddCoRoutineToReadyQueue( pxUnblockedCRCB );
    1e02:	8e 89       	ldd	r24, Y+22	; 0x16
    1e04:	90 91 92 01 	lds	r25, 0x0192	; 0x800192 <uxTopCoRoutineReadyPriority>
    1e08:	98 17       	cp	r25, r24
    1e0a:	10 f4       	brcc	.+4      	; 0x1e10 <vCoRoutineSchedule+0x48>
    1e0c:	80 93 92 01 	sts	0x0192, r24	; 0x800192 <uxTopCoRoutineReadyPriority>
    1e10:	f8 9e       	mul	r15, r24
    1e12:	c0 01       	movw	r24, r0
    1e14:	11 24       	eor	r1, r1
    1e16:	b8 01       	movw	r22, r16
    1e18:	8e 54       	subi	r24, 0x4E	; 78
    1e1a:	9e 4f       	sbci	r25, 0xFE	; 254
    1e1c:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
    1e20:	da cf       	rjmp	.-76     	; 0x1dd6 <vCoRoutineSchedule+0xe>

static void prvCheckDelayedList( void )
{
CRCB_t *pxCRCB;

	xPassedTicks = xTaskGetTickCount() - xLastTickCount;
    1e22:	0e 94 74 03 	call	0x6e8	; 0x6e8 <xTaskGetTickCount>
    1e26:	20 91 8e 01 	lds	r18, 0x018E	; 0x80018e <xLastTickCount>
    1e2a:	30 91 8f 01 	lds	r19, 0x018F	; 0x80018f <xLastTickCount+0x1>
    1e2e:	82 1b       	sub	r24, r18
    1e30:	93 0b       	sbc	r25, r19
    1e32:	90 93 8d 01 	sts	0x018D, r25	; 0x80018d <xPassedTicks+0x1>
    1e36:	80 93 8c 01 	sts	0x018C, r24	; 0x80018c <xPassedTicks>
					( void ) uxListRemove( &( pxCRCB->xEventListItem ) );
				}
			}
			portENABLE_INTERRUPTS();

			prvAddCoRoutineToReadyQueue( pxCRCB );
    1e3a:	89 e0       	ldi	r24, 0x09	; 9
    1e3c:	f8 2e       	mov	r15, r24
static void prvCheckDelayedList( void )
{
CRCB_t *pxCRCB;

	xPassedTicks = xTaskGetTickCount() - xLastTickCount;
	while( xPassedTicks )
    1e3e:	20 91 8c 01 	lds	r18, 0x018C	; 0x80018c <xPassedTicks>
    1e42:	30 91 8d 01 	lds	r19, 0x018D	; 0x80018d <xPassedTicks+0x1>
    1e46:	80 91 90 01 	lds	r24, 0x0190	; 0x800190 <xCoRoutineTickCount>
    1e4a:	90 91 91 01 	lds	r25, 0x0191	; 0x800191 <xCoRoutineTickCount+0x1>
    1e4e:	21 15       	cp	r18, r1
    1e50:	31 05       	cpc	r19, r1
    1e52:	09 f4       	brne	.+2      	; 0x1e56 <vCoRoutineSchedule+0x8e>
    1e54:	54 c0       	rjmp	.+168    	; 0x1efe <vCoRoutineSchedule+0x136>
	{
		xCoRoutineTickCount++;
    1e56:	01 96       	adiw	r24, 0x01	; 1
    1e58:	90 93 91 01 	sts	0x0191, r25	; 0x800191 <xCoRoutineTickCount+0x1>
    1e5c:	80 93 90 01 	sts	0x0190, r24	; 0x800190 <xCoRoutineTickCount>
		xPassedTicks--;
    1e60:	21 50       	subi	r18, 0x01	; 1
    1e62:	31 09       	sbc	r19, r1
    1e64:	30 93 8d 01 	sts	0x018D, r19	; 0x80018d <xPassedTicks+0x1>
    1e68:	20 93 8c 01 	sts	0x018C, r18	; 0x80018c <xPassedTicks>

		/* If the tick count has overflowed we need to swap the ready lists. */
		if( xCoRoutineTickCount == 0 )
    1e6c:	89 2b       	or	r24, r25
    1e6e:	09 f0       	breq	.+2      	; 0x1e72 <vCoRoutineSchedule+0xaa>
    1e70:	3e c0       	rjmp	.+124    	; 0x1eee <vCoRoutineSchedule+0x126>
		{
			List_t * pxTemp;

			/* Tick count has overflowed so we need to swap the delay lists.  If there are
			any items in pxDelayedCoRoutineList here then there is an error! */
			pxTemp = pxDelayedCoRoutineList;
    1e72:	80 91 9e 01 	lds	r24, 0x019E	; 0x80019e <pxDelayedCoRoutineList>
    1e76:	90 91 9f 01 	lds	r25, 0x019F	; 0x80019f <pxDelayedCoRoutineList+0x1>
			pxDelayedCoRoutineList = pxOverflowDelayedCoRoutineList;
    1e7a:	20 91 9c 01 	lds	r18, 0x019C	; 0x80019c <pxOverflowDelayedCoRoutineList>
    1e7e:	30 91 9d 01 	lds	r19, 0x019D	; 0x80019d <pxOverflowDelayedCoRoutineList+0x1>
    1e82:	30 93 9f 01 	sts	0x019F, r19	; 0x80019f <pxDelayedCoRoutineList+0x1>
    1e86:	20 93 9e 01 	sts	0x019E, r18	; 0x80019e <pxDelayedCoRoutineList>
			pxOverflowDelayedCoRoutineList = pxTemp;
    1e8a:	90 93 9d 01 	sts	0x019D, r25	; 0x80019d <pxOverflowDelayedCoRoutineList+0x1>
    1e8e:	80 93 9c 01 	sts	0x019C, r24	; 0x80019c <pxOverflowDelayedCoRoutineList>
    1e92:	2d c0       	rjmp	.+90     	; 0x1eee <vCoRoutineSchedule+0x126>
		}

		/* See if this tick has made a timeout expire. */
		while( listLIST_IS_EMPTY( pxDelayedCoRoutineList ) == pdFALSE )
		{
			pxCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedCoRoutineList );
    1e94:	05 80       	ldd	r0, Z+5	; 0x05
    1e96:	f6 81       	ldd	r31, Z+6	; 0x06
    1e98:	e0 2d       	mov	r30, r0
    1e9a:	c6 81       	ldd	r28, Z+6	; 0x06
    1e9c:	d7 81       	ldd	r29, Z+7	; 0x07

			if( xCoRoutineTickCount < listGET_LIST_ITEM_VALUE( &( pxCRCB->xGenericListItem ) ) )
    1e9e:	2a 81       	ldd	r18, Y+2	; 0x02
    1ea0:	3b 81       	ldd	r19, Y+3	; 0x03
    1ea2:	80 91 90 01 	lds	r24, 0x0190	; 0x800190 <xCoRoutineTickCount>
    1ea6:	90 91 91 01 	lds	r25, 0x0191	; 0x800191 <xCoRoutineTickCount+0x1>
    1eaa:	82 17       	cp	r24, r18
    1eac:	93 07       	cpc	r25, r19
    1eae:	38 f2       	brcs	.-114    	; 0x1e3e <vCoRoutineSchedule+0x76>
			{
				/* Timeout not yet expired. */
				break;
			}

			portDISABLE_INTERRUPTS();
    1eb0:	f8 94       	cli
				/* The event could have occurred just before this critical
				section.  If this is the case then the generic list item will
				have been moved to the pending ready list and the following
				line is still valid.  Also the pvContainer parameter will have
				been set to NULL so the following lines are also valid. */
				( void ) uxListRemove( &( pxCRCB->xGenericListItem ) );
    1eb2:	8e 01       	movw	r16, r28
    1eb4:	0e 5f       	subi	r16, 0xFE	; 254
    1eb6:	1f 4f       	sbci	r17, 0xFF	; 255
    1eb8:	c8 01       	movw	r24, r16
    1eba:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>

				/* Is the co-routine waiting on an event also? */
				if( pxCRCB->xEventListItem.pxContainer )
    1ebe:	8c 89       	ldd	r24, Y+20	; 0x14
    1ec0:	9d 89       	ldd	r25, Y+21	; 0x15
    1ec2:	89 2b       	or	r24, r25
    1ec4:	21 f0       	breq	.+8      	; 0x1ece <vCoRoutineSchedule+0x106>
				{
					( void ) uxListRemove( &( pxCRCB->xEventListItem ) );
    1ec6:	ce 01       	movw	r24, r28
    1ec8:	0c 96       	adiw	r24, 0x0c	; 12
    1eca:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
				}
			}
			portENABLE_INTERRUPTS();
    1ece:	78 94       	sei

			prvAddCoRoutineToReadyQueue( pxCRCB );
    1ed0:	8e 89       	ldd	r24, Y+22	; 0x16
    1ed2:	90 91 92 01 	lds	r25, 0x0192	; 0x800192 <uxTopCoRoutineReadyPriority>
    1ed6:	98 17       	cp	r25, r24
    1ed8:	10 f4       	brcc	.+4      	; 0x1ede <vCoRoutineSchedule+0x116>
    1eda:	80 93 92 01 	sts	0x0192, r24	; 0x800192 <uxTopCoRoutineReadyPriority>
    1ede:	f8 9e       	mul	r15, r24
    1ee0:	c0 01       	movw	r24, r0
    1ee2:	11 24       	eor	r1, r1
    1ee4:	b8 01       	movw	r22, r16
    1ee6:	8e 54       	subi	r24, 0x4E	; 78
    1ee8:	9e 4f       	sbci	r25, 0xFE	; 254
    1eea:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>
			pxDelayedCoRoutineList = pxOverflowDelayedCoRoutineList;
			pxOverflowDelayedCoRoutineList = pxTemp;
		}

		/* See if this tick has made a timeout expire. */
		while( listLIST_IS_EMPTY( pxDelayedCoRoutineList ) == pdFALSE )
    1eee:	e0 91 9e 01 	lds	r30, 0x019E	; 0x80019e <pxDelayedCoRoutineList>
    1ef2:	f0 91 9f 01 	lds	r31, 0x019F	; 0x80019f <pxDelayedCoRoutineList+0x1>
    1ef6:	80 81       	ld	r24, Z
    1ef8:	81 11       	cpse	r24, r1
    1efa:	cc cf       	rjmp	.-104    	; 0x1e94 <vCoRoutineSchedule+0xcc>
    1efc:	a0 cf       	rjmp	.-192    	; 0x1e3e <vCoRoutineSchedule+0x76>

			prvAddCoRoutineToReadyQueue( pxCRCB );
		}
	}

	xLastTickCount = xCoRoutineTickCount;
    1efe:	90 93 8f 01 	sts	0x018F, r25	; 0x80018f <xLastTickCount+0x1>
    1f02:	80 93 8e 01 	sts	0x018E, r24	; 0x80018e <xLastTickCount>
    1f06:	80 91 92 01 	lds	r24, 0x0192	; 0x800192 <uxTopCoRoutineReadyPriority>

	/* See if any delayed co-routines have timed out. */
	prvCheckDelayedList();

	/* Find the highest priority queue that contains ready co-routines. */
	while( listLIST_IS_EMPTY( &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) ) )
    1f0a:	69 e0       	ldi	r22, 0x09	; 9
    1f0c:	48 2f       	mov	r20, r24
    1f0e:	50 e0       	ldi	r21, 0x00	; 0
    1f10:	64 9f       	mul	r22, r20
    1f12:	90 01       	movw	r18, r0
    1f14:	65 9f       	mul	r22, r21
    1f16:	30 0d       	add	r19, r0
    1f18:	11 24       	eor	r1, r1
    1f1a:	f9 01       	movw	r30, r18
    1f1c:	ee 54       	subi	r30, 0x4E	; 78
    1f1e:	fe 4f       	sbci	r31, 0xFE	; 254
    1f20:	90 81       	ld	r25, Z
    1f22:	91 11       	cpse	r25, r1
    1f24:	0c c0       	rjmp	.+24     	; 0x1f3e <vCoRoutineSchedule+0x176>
	{
		if( uxTopCoRoutineReadyPriority == 0 )
    1f26:	81 11       	cpse	r24, r1
    1f28:	08 c0       	rjmp	.+16     	; 0x1f3a <vCoRoutineSchedule+0x172>
    1f2a:	10 92 92 01 	sts	0x0192, r1	; 0x800192 <uxTopCoRoutineReadyPriority>

	/* Call the co-routine. */
	( pxCurrentCoRoutine->pxCoRoutineFunction )( pxCurrentCoRoutine, pxCurrentCoRoutine->uxIndex );

	return;
}
    1f2e:	df 91       	pop	r29
    1f30:	cf 91       	pop	r28
    1f32:	1f 91       	pop	r17
    1f34:	0f 91       	pop	r16
    1f36:	ff 90       	pop	r15
    1f38:	08 95       	ret
		if( uxTopCoRoutineReadyPriority == 0 )
		{
			/* No more co-routines to check. */
			return;
		}
		--uxTopCoRoutineReadyPriority;
    1f3a:	81 50       	subi	r24, 0x01	; 1
    1f3c:	e7 cf       	rjmp	.-50     	; 0x1f0c <vCoRoutineSchedule+0x144>
    1f3e:	80 93 92 01 	sts	0x0192, r24	; 0x800192 <uxTopCoRoutineReadyPriority>
	}

	/* listGET_OWNER_OF_NEXT_ENTRY walks through the list, so the co-routines
	 of the	same priority get an equal share of the processor time. */
	listGET_OWNER_OF_NEXT_ENTRY( pxCurrentCoRoutine, &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) );
    1f42:	a1 81       	ldd	r26, Z+1	; 0x01
    1f44:	b2 81       	ldd	r27, Z+2	; 0x02
    1f46:	12 96       	adiw	r26, 0x02	; 2
    1f48:	0d 90       	ld	r0, X+
    1f4a:	bc 91       	ld	r27, X
    1f4c:	a0 2d       	mov	r26, r0
    1f4e:	b2 83       	std	Z+2, r27	; 0x02
    1f50:	a1 83       	std	Z+1, r26	; 0x01
    1f52:	2b 54       	subi	r18, 0x4B	; 75
    1f54:	3e 4f       	sbci	r19, 0xFE	; 254
    1f56:	a2 17       	cp	r26, r18
    1f58:	b3 07       	cpc	r27, r19
    1f5a:	31 f4       	brne	.+12     	; 0x1f68 <vCoRoutineSchedule+0x1a0>
    1f5c:	12 96       	adiw	r26, 0x02	; 2
    1f5e:	8d 91       	ld	r24, X+
    1f60:	9c 91       	ld	r25, X
    1f62:	13 97       	sbiw	r26, 0x03	; 3
    1f64:	92 83       	std	Z+2, r25	; 0x02
    1f66:	81 83       	std	Z+1, r24	; 0x01
    1f68:	89 e0       	ldi	r24, 0x09	; 9
    1f6a:	84 9f       	mul	r24, r20
    1f6c:	f0 01       	movw	r30, r0
    1f6e:	85 9f       	mul	r24, r21
    1f70:	f0 0d       	add	r31, r0
    1f72:	11 24       	eor	r1, r1
    1f74:	ee 54       	subi	r30, 0x4E	; 78
    1f76:	fe 4f       	sbci	r31, 0xFE	; 254
    1f78:	01 80       	ldd	r0, Z+1	; 0x01
    1f7a:	f2 81       	ldd	r31, Z+2	; 0x02
    1f7c:	e0 2d       	mov	r30, r0
    1f7e:	86 81       	ldd	r24, Z+6	; 0x06
    1f80:	97 81       	ldd	r25, Z+7	; 0x07
    1f82:	90 93 8b 01 	sts	0x018B, r25	; 0x80018b <pxCurrentCoRoutine+0x1>
    1f86:	80 93 8a 01 	sts	0x018A, r24	; 0x80018a <pxCurrentCoRoutine>

	/* Call the co-routine. */
	( pxCurrentCoRoutine->pxCoRoutineFunction )( pxCurrentCoRoutine, pxCurrentCoRoutine->uxIndex );
    1f8a:	dc 01       	movw	r26, r24
    1f8c:	ed 91       	ld	r30, X+
    1f8e:	fc 91       	ld	r31, X
    1f90:	11 97       	sbiw	r26, 0x01	; 1
    1f92:	57 96       	adiw	r26, 0x17	; 23
    1f94:	6c 91       	ld	r22, X

	return;
}
    1f96:	df 91       	pop	r29
    1f98:	cf 91       	pop	r28
    1f9a:	1f 91       	pop	r17
    1f9c:	0f 91       	pop	r16
    1f9e:	ff 90       	pop	r15
	/* listGET_OWNER_OF_NEXT_ENTRY walks through the list, so the co-routines
	 of the	same priority get an equal share of the processor time. */
	listGET_OWNER_OF_NEXT_ENTRY( pxCurrentCoRoutine, &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) );

	/* Call the co-routine. */
	( pxCurrentCoRoutine->pxCoRoutineFunction )( pxCurrentCoRoutine, pxCurrentCoRoutine->uxIndex );
    1fa0:	09 94       	ijmp

00001fa2 <xCoRoutineRemoveFromEventList>:
	pxOverflowDelayedCoRoutineList = &xDelayedCoRoutineList2;
}
/*-----------------------------------------------------------*/

BaseType_t xCoRoutineRemoveFromEventList( const List_t *pxEventList )
{
    1fa2:	0f 93       	push	r16
    1fa4:	1f 93       	push	r17
    1fa6:	cf 93       	push	r28
    1fa8:	df 93       	push	r29
BaseType_t xReturn;

	/* This function is called from within an interrupt.  It can only access
	event lists and the pending ready list.  This function assumes that a
	check has already been made to ensure pxEventList is not empty. */
	pxUnblockedCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
    1faa:	dc 01       	movw	r26, r24
    1fac:	15 96       	adiw	r26, 0x05	; 5
    1fae:	ed 91       	ld	r30, X+
    1fb0:	fc 91       	ld	r31, X
    1fb2:	16 97       	sbiw	r26, 0x06	; 6
    1fb4:	c6 81       	ldd	r28, Z+6	; 0x06
    1fb6:	d7 81       	ldd	r29, Z+7	; 0x07
	( void ) uxListRemove( &( pxUnblockedCRCB->xEventListItem ) );
    1fb8:	8e 01       	movw	r16, r28
    1fba:	04 5f       	subi	r16, 0xF4	; 244
    1fbc:	1f 4f       	sbci	r17, 0xFF	; 255
    1fbe:	c8 01       	movw	r24, r16
    1fc0:	0e 94 0c 0e 	call	0x1c18	; 0x1c18 <uxListRemove>
	vListInsertEnd( ( List_t * ) &( xPendingReadyCoRoutineList ), &( pxUnblockedCRCB->xEventListItem ) );
    1fc4:	b8 01       	movw	r22, r16
    1fc6:	83 e9       	ldi	r24, 0x93	; 147
    1fc8:	91 e0       	ldi	r25, 0x01	; 1
    1fca:	0e 94 b3 0d 	call	0x1b66	; 0x1b66 <vListInsertEnd>

	if( pxUnblockedCRCB->uxPriority >= pxCurrentCoRoutine->uxPriority )
    1fce:	e0 91 8a 01 	lds	r30, 0x018A	; 0x80018a <pxCurrentCoRoutine>
    1fd2:	f0 91 8b 01 	lds	r31, 0x018B	; 0x80018b <pxCurrentCoRoutine+0x1>
	else
	{
		xReturn = pdFALSE;
	}

	return xReturn;
    1fd6:	81 e0       	ldi	r24, 0x01	; 1
    1fd8:	2e 89       	ldd	r18, Y+22	; 0x16
    1fda:	96 89       	ldd	r25, Z+22	; 0x16
    1fdc:	29 17       	cp	r18, r25
    1fde:	08 f4       	brcc	.+2      	; 0x1fe2 <xCoRoutineRemoveFromEventList+0x40>
    1fe0:	80 e0       	ldi	r24, 0x00	; 0
}
    1fe2:	df 91       	pop	r29
    1fe4:	cf 91       	pop	r28
    1fe6:	1f 91       	pop	r17
    1fe8:	0f 91       	pop	r16
    1fea:	08 95       	ret

00001fec <pvPortMalloc>:
static size_t xNextFreeByte = ( size_t ) 0;

/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
    1fec:	cf 93       	push	r28
    1fee:	df 93       	push	r29
    1ff0:	ec 01       	movw	r28, r24
			xWantedSize += ( portBYTE_ALIGNMENT - ( xWantedSize & portBYTE_ALIGNMENT_MASK ) );
		}
	}
	#endif

	vTaskSuspendAll();
    1ff2:	0e 94 6e 03 	call	0x6dc	; 0x6dc <vTaskSuspendAll>
	{
		if( pucAlignedHeap == NULL )
    1ff6:	80 91 c4 01 	lds	r24, 0x01C4	; 0x8001c4 <pucAlignedHeap.2081>
    1ffa:	90 91 c5 01 	lds	r25, 0x01C5	; 0x8001c5 <pucAlignedHeap.2081+0x1>
    1ffe:	89 2b       	or	r24, r25
    2000:	31 f4       	brne	.+12     	; 0x200e <pvPortMalloc+0x22>
		{
			/* Ensure the heap starts on a correctly aligned boundary. */
			pucAlignedHeap = ( uint8_t * ) ( ( ( portPOINTER_SIZE_TYPE ) &ucHeap[ portBYTE_ALIGNMENT ] ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );
    2002:	89 ec       	ldi	r24, 0xC9	; 201
    2004:	91 e0       	ldi	r25, 0x01	; 1
    2006:	90 93 c5 01 	sts	0x01C5, r25	; 0x8001c5 <pucAlignedHeap.2081+0x1>
    200a:	80 93 c4 01 	sts	0x01C4, r24	; 0x8001c4 <pucAlignedHeap.2081>
		}

		/* Check there is enough room left for the allocation. */
		if( ( ( xNextFreeByte + xWantedSize ) < configADJUSTED_HEAP_SIZE ) &&
    200e:	20 91 c6 01 	lds	r18, 0x01C6	; 0x8001c6 <xNextFreeByte>
    2012:	30 91 c7 01 	lds	r19, 0x01C7	; 0x8001c7 <xNextFreeByte+0x1>
    2016:	c9 01       	movw	r24, r18
    2018:	8c 0f       	add	r24, r28
    201a:	9d 1f       	adc	r25, r29
    201c:	8b 3d       	cpi	r24, 0xDB	; 219
    201e:	45 e0       	ldi	r20, 0x05	; 5
    2020:	94 07       	cpc	r25, r20
    2022:	70 f4       	brcc	.+28     	; 0x2040 <pvPortMalloc+0x54>
    2024:	28 17       	cp	r18, r24
    2026:	39 07       	cpc	r19, r25
    2028:	58 f4       	brcc	.+22     	; 0x2040 <pvPortMalloc+0x54>
			( ( xNextFreeByte + xWantedSize ) > xNextFreeByte )	)/* Check for overflow. */
		{
			/* Return the next free byte then increment the index past this
			block. */
			pvReturn = pucAlignedHeap + xNextFreeByte;
    202a:	c0 91 c4 01 	lds	r28, 0x01C4	; 0x8001c4 <pucAlignedHeap.2081>
    202e:	d0 91 c5 01 	lds	r29, 0x01C5	; 0x8001c5 <pucAlignedHeap.2081+0x1>
    2032:	c2 0f       	add	r28, r18
    2034:	d3 1f       	adc	r29, r19
			xNextFreeByte += xWantedSize;
    2036:	90 93 c7 01 	sts	0x01C7, r25	; 0x8001c7 <xNextFreeByte+0x1>
    203a:	80 93 c6 01 	sts	0x01C6, r24	; 0x8001c6 <xNextFreeByte>
    203e:	02 c0       	rjmp	.+4      	; 0x2044 <pvPortMalloc+0x58>

/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
void *pvReturn = NULL;
    2040:	c0 e0       	ldi	r28, 0x00	; 0
    2042:	d0 e0       	ldi	r29, 0x00	; 0
			xNextFreeByte += xWantedSize;
		}

		traceMALLOC( pvReturn, xWantedSize );
	}
	( void ) xTaskResumeAll();
    2044:	0e 94 3a 04 	call	0x874	; 0x874 <xTaskResumeAll>
		}
	}
	#endif

	return pvReturn;
}
    2048:	ce 01       	movw	r24, r28
    204a:	df 91       	pop	r29
    204c:	cf 91       	pop	r28
    204e:	08 95       	ret

00002050 <vPortFree>:
/*-----------------------------------------------------------*/

void vPortFree( void *pv )
{
    2050:	08 95       	ret

00002052 <vPortInitialiseBlocks>:
/*-----------------------------------------------------------*/

void vPortInitialiseBlocks( void )
{
	/* Only required when static memory is not cleared. */
	xNextFreeByte = ( size_t ) 0;
    2052:	10 92 c7 01 	sts	0x01C7, r1	; 0x8001c7 <xNextFreeByte+0x1>
    2056:	10 92 c6 01 	sts	0x01C6, r1	; 0x8001c6 <xNextFreeByte>
    205a:	08 95       	ret

0000205c <xPortGetFreeHeapSize>:
}
/*-----------------------------------------------------------*/

size_t xPortGetFreeHeapSize( void )
{
	return ( configADJUSTED_HEAP_SIZE - xNextFreeByte );
    205c:	20 91 c6 01 	lds	r18, 0x01C6	; 0x8001c6 <xNextFreeByte>
    2060:	30 91 c7 01 	lds	r19, 0x01C7	; 0x8001c7 <xNextFreeByte+0x1>
}
    2064:	8b ed       	ldi	r24, 0xDB	; 219
    2066:	95 e0       	ldi	r25, 0x05	; 5
    2068:	82 1b       	sub	r24, r18
    206a:	93 0b       	sbc	r25, r19
    206c:	08 95       	ret

0000206e <pxPortInitialiseStack>:
uint16_t usAddress;

	/* Place a few bytes of known values on the bottom of the stack. 
	This is just useful for debugging. */

	*pxTopOfStack = 0x11;
    206e:	31 e1       	ldi	r19, 0x11	; 17
    2070:	fc 01       	movw	r30, r24
    2072:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = 0x22;
    2074:	31 97       	sbiw	r30, 0x01	; 1
    2076:	22 e2       	ldi	r18, 0x22	; 34
    2078:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = 0x33;
    207a:	31 97       	sbiw	r30, 0x01	; 1
    207c:	a3 e3       	ldi	r26, 0x33	; 51
    207e:	a0 83       	st	Z, r26
	/*lint -e950 -e611 -e923 Lint doesn't like this much - but nothing I can do about it. */

	/* The start of the task code will be popped off the stack last, so place
	it on first. */
	usAddress = ( uint16_t ) pxCode;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
    2080:	31 97       	sbiw	r30, 0x01	; 1
    2082:	60 83       	st	Z, r22
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
    2084:	31 97       	sbiw	r30, 0x01	; 1
    2086:	70 83       	st	Z, r23

	/* Next simulate the stack as if after a call to portSAVE_CONTEXT().  
	portSAVE_CONTEXT places the flags on the stack immediately after r0
	to ensure the interrupts get disabled as soon as possible, and so ensuring
	the stack use is minimal should a context switch interrupt occur. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R0 */
    2088:	31 97       	sbiw	r30, 0x01	; 1
    208a:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = portFLAGS_INT_ENABLED;
    208c:	31 97       	sbiw	r30, 0x01	; 1
    208e:	60 e8       	ldi	r22, 0x80	; 128
    2090:	60 83       	st	Z, r22
	pxTopOfStack--;


	/* Now the remaining registers.   The compiler expects R1 to be 0. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R1 */
    2092:	31 97       	sbiw	r30, 0x01	; 1
    2094:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x02;	/* R2 */
    2096:	31 97       	sbiw	r30, 0x01	; 1
    2098:	62 e0       	ldi	r22, 0x02	; 2
    209a:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x03;	/* R3 */
    209c:	31 97       	sbiw	r30, 0x01	; 1
    209e:	63 e0       	ldi	r22, 0x03	; 3
    20a0:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x04;	/* R4 */
    20a2:	31 97       	sbiw	r30, 0x01	; 1
    20a4:	64 e0       	ldi	r22, 0x04	; 4
    20a6:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x05;	/* R5 */
    20a8:	31 97       	sbiw	r30, 0x01	; 1
    20aa:	65 e0       	ldi	r22, 0x05	; 5
    20ac:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x06;	/* R6 */
    20ae:	31 97       	sbiw	r30, 0x01	; 1
    20b0:	66 e0       	ldi	r22, 0x06	; 6
    20b2:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x07;	/* R7 */
    20b4:	31 97       	sbiw	r30, 0x01	; 1
    20b6:	67 e0       	ldi	r22, 0x07	; 7
    20b8:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x08;	/* R8 */
    20ba:	31 97       	sbiw	r30, 0x01	; 1
    20bc:	68 e0       	ldi	r22, 0x08	; 8
    20be:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x09;	/* R9 */
    20c0:	31 97       	sbiw	r30, 0x01	; 1
    20c2:	69 e0       	ldi	r22, 0x09	; 9
    20c4:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x10;	/* R10 */
    20c6:	31 97       	sbiw	r30, 0x01	; 1
    20c8:	60 e1       	ldi	r22, 0x10	; 16
    20ca:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x11;	/* R11 */
    20cc:	31 97       	sbiw	r30, 0x01	; 1
    20ce:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x12;	/* R12 */
    20d0:	31 97       	sbiw	r30, 0x01	; 1
    20d2:	32 e1       	ldi	r19, 0x12	; 18
    20d4:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x13;	/* R13 */
    20d6:	31 97       	sbiw	r30, 0x01	; 1
    20d8:	33 e1       	ldi	r19, 0x13	; 19
    20da:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x14;	/* R14 */
    20dc:	31 97       	sbiw	r30, 0x01	; 1
    20de:	34 e1       	ldi	r19, 0x14	; 20
    20e0:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x15;	/* R15 */
    20e2:	31 97       	sbiw	r30, 0x01	; 1
    20e4:	35 e1       	ldi	r19, 0x15	; 21
    20e6:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x16;	/* R16 */
    20e8:	31 97       	sbiw	r30, 0x01	; 1
    20ea:	36 e1       	ldi	r19, 0x16	; 22
    20ec:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x17;	/* R17 */
    20ee:	31 97       	sbiw	r30, 0x01	; 1
    20f0:	37 e1       	ldi	r19, 0x17	; 23
    20f2:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x18;	/* R18 */
    20f4:	31 97       	sbiw	r30, 0x01	; 1
    20f6:	38 e1       	ldi	r19, 0x18	; 24
    20f8:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x19;	/* R19 */
    20fa:	31 97       	sbiw	r30, 0x01	; 1
    20fc:	39 e1       	ldi	r19, 0x19	; 25
    20fe:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x20;	/* R20 */
    2100:	31 97       	sbiw	r30, 0x01	; 1
    2102:	30 e2       	ldi	r19, 0x20	; 32
    2104:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x21;	/* R21 */
    2106:	31 97       	sbiw	r30, 0x01	; 1
    2108:	31 e2       	ldi	r19, 0x21	; 33
    210a:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x22;	/* R22 */
    210c:	31 97       	sbiw	r30, 0x01	; 1
    210e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x23;	/* R23 */
    2110:	31 97       	sbiw	r30, 0x01	; 1
    2112:	23 e2       	ldi	r18, 0x23	; 35
    2114:	20 83       	st	Z, r18
	pxTopOfStack--;

	/* Place the parameter on the stack in the expected location. */
	usAddress = ( uint16_t ) pvParameters;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
    2116:	31 97       	sbiw	r30, 0x01	; 1
    2118:	40 83       	st	Z, r20
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
    211a:	31 97       	sbiw	r30, 0x01	; 1
    211c:	50 83       	st	Z, r21
	pxTopOfStack--;

	*pxTopOfStack = ( StackType_t ) 0x26;	/* R26 X */
    211e:	31 97       	sbiw	r30, 0x01	; 1
    2120:	26 e2       	ldi	r18, 0x26	; 38
    2122:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x27;	/* R27 */
    2124:	31 97       	sbiw	r30, 0x01	; 1
    2126:	27 e2       	ldi	r18, 0x27	; 39
    2128:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x28;	/* R28 Y */
    212a:	31 97       	sbiw	r30, 0x01	; 1
    212c:	28 e2       	ldi	r18, 0x28	; 40
    212e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x29;	/* R29 */
    2130:	31 97       	sbiw	r30, 0x01	; 1
    2132:	29 e2       	ldi	r18, 0x29	; 41
    2134:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x30;	/* R30 Z */
    2136:	31 97       	sbiw	r30, 0x01	; 1
    2138:	20 e3       	ldi	r18, 0x30	; 48
    213a:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x031;	/* R31 */
    213c:	31 97       	sbiw	r30, 0x01	; 1
    213e:	21 e3       	ldi	r18, 0x31	; 49
    2140:	20 83       	st	Z, r18
	pxTopOfStack--;

	/*lint +e950 +e611 +e923 */

	return pxTopOfStack;
}
    2142:	86 97       	sbiw	r24, 0x26	; 38
    2144:	08 95       	ret

00002146 <xPortStartScheduler>:
	/* Adjust for correct value. */
	ulCompareMatch -= ( uint32_t ) 1;

	/* Setup compare match value for compare match A.  Interrupts are disabled 
	before this is called so we need not worry here. */
OCR1A = ulCompareMatch;
    2146:	89 ef       	ldi	r24, 0xF9	; 249
    2148:	90 e0       	ldi	r25, 0x00	; 0
    214a:	90 93 89 00 	sts	0x0089, r25	; 0x800089 <__DATA_REGION_ORIGIN__+0x29>
    214e:	80 93 88 00 	sts	0x0088, r24	; 0x800088 <__DATA_REGION_ORIGIN__+0x28>

	/* Setup clock source and compare match behaviour. */
	TCCR1A &= ~(_BV(WGM11) | _BV(WGM10));;
    2152:	e0 e8       	ldi	r30, 0x80	; 128
    2154:	f0 e0       	ldi	r31, 0x00	; 0
    2156:	80 81       	ld	r24, Z
    2158:	8c 7f       	andi	r24, 0xFC	; 252
    215a:	80 83       	st	Z, r24
	ucLowByte = portCLEAR_COUNTER_ON_MATCH | portPRESCALE_64;
	TCCR1B = ucLowByte;
    215c:	8b e0       	ldi	r24, 0x0B	; 11
    215e:	80 93 81 00 	sts	0x0081, r24	; 0x800081 <__DATA_REGION_ORIGIN__+0x21>

	/* Enable the interrupt - this is okay as interrupt are currently globally
	disabled. */
	ucLowByte = TIMSK1;
    2162:	ef e6       	ldi	r30, 0x6F	; 111
    2164:	f0 e0       	ldi	r31, 0x00	; 0
    2166:	80 81       	ld	r24, Z
	ucLowByte |= portCOMPARE_MATCH_A_INTERRUPT_ENABLE;
    2168:	82 60       	ori	r24, 0x02	; 2
	TIMSK1 = ucLowByte;
    216a:	80 83       	st	Z, r24
{
	/* Setup the hardware to generate the tick. */
	prvSetupTimerInterrupt();

	/* Restore the context of the first task that is going to run. */
	portRESTORE_CONTEXT();
    216c:	a0 91 24 01 	lds	r26, 0x0124	; 0x800124 <__data_end>
    2170:	b0 91 25 01 	lds	r27, 0x0125	; 0x800125 <__data_end+0x1>
    2174:	cd 91       	ld	r28, X+
    2176:	cd bf       	out	0x3d, r28	; 61
    2178:	dd 91       	ld	r29, X+
    217a:	de bf       	out	0x3e, r29	; 62
    217c:	ff 91       	pop	r31
    217e:	ef 91       	pop	r30
    2180:	df 91       	pop	r29
    2182:	cf 91       	pop	r28
    2184:	bf 91       	pop	r27
    2186:	af 91       	pop	r26
    2188:	9f 91       	pop	r25
    218a:	8f 91       	pop	r24
    218c:	7f 91       	pop	r23
    218e:	6f 91       	pop	r22
    2190:	5f 91       	pop	r21
    2192:	4f 91       	pop	r20
    2194:	3f 91       	pop	r19
    2196:	2f 91       	pop	r18
    2198:	1f 91       	pop	r17
    219a:	0f 91       	pop	r16
    219c:	ff 90       	pop	r15
    219e:	ef 90       	pop	r14
    21a0:	df 90       	pop	r13
    21a2:	cf 90       	pop	r12
    21a4:	bf 90       	pop	r11
    21a6:	af 90       	pop	r10
    21a8:	9f 90       	pop	r9
    21aa:	8f 90       	pop	r8
    21ac:	7f 90       	pop	r7
    21ae:	6f 90       	pop	r6
    21b0:	5f 90       	pop	r5
    21b2:	4f 90       	pop	r4
    21b4:	3f 90       	pop	r3
    21b6:	2f 90       	pop	r2
    21b8:	1f 90       	pop	r1
    21ba:	0f 90       	pop	r0
    21bc:	0f be       	out	0x3f, r0	; 63
    21be:	0f 90       	pop	r0

	/* Simulate a function call end as generated by the compiler.  We will now
	jump to the start of the task the context of which we have just restored. */
	asm volatile ( "ret" );
    21c0:	08 95       	ret

	/* Should not get here. */
	return pdTRUE;
}
    21c2:	81 e0       	ldi	r24, 0x01	; 1
    21c4:	08 95       	ret

000021c6 <vPortEndScheduler>:
/*-----------------------------------------------------------*/

void vPortEndScheduler( void )
{
    21c6:	08 95       	ret

000021c8 <vPortYield>:
 * can use a naked attribute.
 */
void vPortYield( void ) __attribute__ ( ( naked ) );
void vPortYield( void )
{
	portSAVE_CONTEXT();
    21c8:	0f 92       	push	r0
    21ca:	0f b6       	in	r0, 0x3f	; 63
    21cc:	f8 94       	cli
    21ce:	0f 92       	push	r0
    21d0:	1f 92       	push	r1
    21d2:	11 24       	eor	r1, r1
    21d4:	2f 92       	push	r2
    21d6:	3f 92       	push	r3
    21d8:	4f 92       	push	r4
    21da:	5f 92       	push	r5
    21dc:	6f 92       	push	r6
    21de:	7f 92       	push	r7
    21e0:	8f 92       	push	r8
    21e2:	9f 92       	push	r9
    21e4:	af 92       	push	r10
    21e6:	bf 92       	push	r11
    21e8:	cf 92       	push	r12
    21ea:	df 92       	push	r13
    21ec:	ef 92       	push	r14
    21ee:	ff 92       	push	r15
    21f0:	0f 93       	push	r16
    21f2:	1f 93       	push	r17
    21f4:	2f 93       	push	r18
    21f6:	3f 93       	push	r19
    21f8:	4f 93       	push	r20
    21fa:	5f 93       	push	r21
    21fc:	6f 93       	push	r22
    21fe:	7f 93       	push	r23
    2200:	8f 93       	push	r24
    2202:	9f 93       	push	r25
    2204:	af 93       	push	r26
    2206:	bf 93       	push	r27
    2208:	cf 93       	push	r28
    220a:	df 93       	push	r29
    220c:	ef 93       	push	r30
    220e:	ff 93       	push	r31
    2210:	a0 91 24 01 	lds	r26, 0x0124	; 0x800124 <__data_end>
    2214:	b0 91 25 01 	lds	r27, 0x0125	; 0x800125 <__data_end+0x1>
    2218:	0d b6       	in	r0, 0x3d	; 61
    221a:	0d 92       	st	X+, r0
    221c:	0e b6       	in	r0, 0x3e	; 62
    221e:	0d 92       	st	X+, r0
	vTaskSwitchContext();
    2220:	0e 94 f6 04 	call	0x9ec	; 0x9ec <vTaskSwitchContext>
	portRESTORE_CONTEXT();
    2224:	a0 91 24 01 	lds	r26, 0x0124	; 0x800124 <__data_end>
    2228:	b0 91 25 01 	lds	r27, 0x0125	; 0x800125 <__data_end+0x1>
    222c:	cd 91       	ld	r28, X+
    222e:	cd bf       	out	0x3d, r28	; 61
    2230:	dd 91       	ld	r29, X+
    2232:	de bf       	out	0x3e, r29	; 62
    2234:	ff 91       	pop	r31
    2236:	ef 91       	pop	r30
    2238:	df 91       	pop	r29
    223a:	cf 91       	pop	r28
    223c:	bf 91       	pop	r27
    223e:	af 91       	pop	r26
    2240:	9f 91       	pop	r25
    2242:	8f 91       	pop	r24
    2244:	7f 91       	pop	r23
    2246:	6f 91       	pop	r22
    2248:	5f 91       	pop	r21
    224a:	4f 91       	pop	r20
    224c:	3f 91       	pop	r19
    224e:	2f 91       	pop	r18
    2250:	1f 91       	pop	r17
    2252:	0f 91       	pop	r16
    2254:	ff 90       	pop	r15
    2256:	ef 90       	pop	r14
    2258:	df 90       	pop	r13
    225a:	cf 90       	pop	r12
    225c:	bf 90       	pop	r11
    225e:	af 90       	pop	r10
    2260:	9f 90       	pop	r9
    2262:	8f 90       	pop	r8
    2264:	7f 90       	pop	r7
    2266:	6f 90       	pop	r6
    2268:	5f 90       	pop	r5
    226a:	4f 90       	pop	r4
    226c:	3f 90       	pop	r3
    226e:	2f 90       	pop	r2
    2270:	1f 90       	pop	r1
    2272:	0f 90       	pop	r0
    2274:	0f be       	out	0x3f, r0	; 63
    2276:	0f 90       	pop	r0

	asm volatile ( "ret" );
    2278:	08 95       	ret

0000227a <vPortYieldFromTick>:
 * call comes from the tick ISR.
 */
void vPortYieldFromTick( void ) __attribute__ ( ( naked ) );
void vPortYieldFromTick( void )
{
	portSAVE_CONTEXT();
    227a:	0f 92       	push	r0
    227c:	0f b6       	in	r0, 0x3f	; 63
    227e:	f8 94       	cli
    2280:	0f 92       	push	r0
    2282:	1f 92       	push	r1
    2284:	11 24       	eor	r1, r1
    2286:	2f 92       	push	r2
    2288:	3f 92       	push	r3
    228a:	4f 92       	push	r4
    228c:	5f 92       	push	r5
    228e:	6f 92       	push	r6
    2290:	7f 92       	push	r7
    2292:	8f 92       	push	r8
    2294:	9f 92       	push	r9
    2296:	af 92       	push	r10
    2298:	bf 92       	push	r11
    229a:	cf 92       	push	r12
    229c:	df 92       	push	r13
    229e:	ef 92       	push	r14
    22a0:	ff 92       	push	r15
    22a2:	0f 93       	push	r16
    22a4:	1f 93       	push	r17
    22a6:	2f 93       	push	r18
    22a8:	3f 93       	push	r19
    22aa:	4f 93       	push	r20
    22ac:	5f 93       	push	r21
    22ae:	6f 93       	push	r22
    22b0:	7f 93       	push	r23
    22b2:	8f 93       	push	r24
    22b4:	9f 93       	push	r25
    22b6:	af 93       	push	r26
    22b8:	bf 93       	push	r27
    22ba:	cf 93       	push	r28
    22bc:	df 93       	push	r29
    22be:	ef 93       	push	r30
    22c0:	ff 93       	push	r31
    22c2:	a0 91 24 01 	lds	r26, 0x0124	; 0x800124 <__data_end>
    22c6:	b0 91 25 01 	lds	r27, 0x0125	; 0x800125 <__data_end+0x1>
    22ca:	0d b6       	in	r0, 0x3d	; 61
    22cc:	0d 92       	st	X+, r0
    22ce:	0e b6       	in	r0, 0x3e	; 62
    22d0:	0d 92       	st	X+, r0
	if( xTaskIncrementTick() != pdFALSE )
    22d2:	0e 94 8e 03 	call	0x71c	; 0x71c <xTaskIncrementTick>
    22d6:	81 11       	cpse	r24, r1
	{
		vTaskSwitchContext();
    22d8:	0e 94 f6 04 	call	0x9ec	; 0x9ec <vTaskSwitchContext>
	}
	portRESTORE_CONTEXT();
    22dc:	a0 91 24 01 	lds	r26, 0x0124	; 0x800124 <__data_end>
    22e0:	b0 91 25 01 	lds	r27, 0x0125	; 0x800125 <__data_end+0x1>
    22e4:	cd 91       	ld	r28, X+
    22e6:	cd bf       	out	0x3d, r28	; 61
    22e8:	dd 91       	ld	r29, X+
    22ea:	de bf       	out	0x3e, r29	; 62
    22ec:	ff 91       	pop	r31
    22ee:	ef 91       	pop	r30
    22f0:	df 91       	pop	r29
    22f2:	cf 91       	pop	r28
    22f4:	bf 91       	pop	r27
    22f6:	af 91       	pop	r26
    22f8:	9f 91       	pop	r25
    22fa:	8f 91       	pop	r24
    22fc:	7f 91       	pop	r23
    22fe:	6f 91       	pop	r22
    2300:	5f 91       	pop	r21
    2302:	4f 91       	pop	r20
    2304:	3f 91       	pop	r19
    2306:	2f 91       	pop	r18
    2308:	1f 91       	pop	r17
    230a:	0f 91       	pop	r16
    230c:	ff 90       	pop	r15
    230e:	ef 90       	pop	r14
    2310:	df 90       	pop	r13
    2312:	cf 90       	pop	r12
    2314:	bf 90       	pop	r11
    2316:	af 90       	pop	r10
    2318:	9f 90       	pop	r9
    231a:	8f 90       	pop	r8
    231c:	7f 90       	pop	r7
    231e:	6f 90       	pop	r6
    2320:	5f 90       	pop	r5
    2322:	4f 90       	pop	r4
    2324:	3f 90       	pop	r3
    2326:	2f 90       	pop	r2
    2328:	1f 90       	pop	r1
    232a:	0f 90       	pop	r0
    232c:	0f be       	out	0x3f, r0	; 63
    232e:	0f 90       	pop	r0

	asm volatile ( "ret" );
    2330:	08 95       	ret

00002332 <__vector_11>:
	 * count is incremented after the context is saved.
	 */
    void TIMER1_COMPA_vect( void ) __attribute__ ( ( signal, naked ) );
    void TIMER1_COMPA_vect( void )
	{
		vPortYieldFromTick();
    2332:	0e 94 3d 11 	call	0x227a	; 0x227a <vPortYieldFromTick>
		asm volatile ( "reti" );
    2336:	18 95       	reti

00002338 <uart_transmit>:
#endif
  UCSR0C = _BV(UCSZ01) | _BV(UCSZ00); /* 8-bit data */
  UCSR0B = _BV(RXEN0) | _BV(TXEN0); /* Enable RX and TX */
}

int uart_transmit(char c, FILE *stream) {
    2338:	cf 93       	push	r28
    233a:	c8 2f       	mov	r28, r24
  while (!(UCSR0A & _BV(UDRE0))) taskYIELD();
    233c:	80 91 c0 00 	lds	r24, 0x00C0	; 0x8000c0 <__DATA_REGION_ORIGIN__+0x60>
    2340:	85 fd       	sbrc	r24, 5
    2342:	03 c0       	rjmp	.+6      	; 0x234a <uart_transmit+0x12>
    2344:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
    2348:	f9 cf       	rjmp	.-14     	; 0x233c <uart_transmit+0x4>
  UDR0 = c;
    234a:	c0 93 c6 00 	sts	0x00C6, r28	; 0x8000c6 <__DATA_REGION_ORIGIN__+0x66>
  return 0;
}
    234e:	80 e0       	ldi	r24, 0x00	; 0
    2350:	90 e0       	ldi	r25, 0x00	; 0
    2352:	cf 91       	pop	r28
    2354:	08 95       	ret

00002356 <uart_receive>:

int uart_receive(FILE *stream) {
  while (!(UCSR0A & _BV(RXC0))) taskYIELD();
    2356:	80 91 c0 00 	lds	r24, 0x00C0	; 0x8000c0 <__DATA_REGION_ORIGIN__+0x60>
    235a:	87 fd       	sbrc	r24, 7
    235c:	03 c0       	rjmp	.+6      	; 0x2364 <uart_receive+0xe>
    235e:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vPortYield>
    2362:	f9 cf       	rjmp	.-14     	; 0x2356 <uart_receive>
  return UDR0;
    2364:	80 91 c6 00 	lds	r24, 0x00C6	; 0x8000c6 <__DATA_REGION_ORIGIN__+0x66>
}
    2368:	90 e0       	ldi	r25, 0x00	; 0
    236a:	08 95       	ret

0000236c <uart_init>:
    236c:	10 92 c5 00 	sts	0x00C5, r1	; 0x8000c5 <__DATA_REGION_ORIGIN__+0x65>
    2370:	87 e6       	ldi	r24, 0x67	; 103
    2372:	80 93 c4 00 	sts	0x00C4, r24	; 0x8000c4 <__DATA_REGION_ORIGIN__+0x64>
    2376:	e0 ec       	ldi	r30, 0xC0	; 192
    2378:	f0 e0       	ldi	r31, 0x00	; 0
    237a:	80 81       	ld	r24, Z
    237c:	8d 7f       	andi	r24, 0xFD	; 253
    237e:	80 83       	st	Z, r24
    2380:	86 e0       	ldi	r24, 0x06	; 6
    2382:	80 93 c2 00 	sts	0x00C2, r24	; 0x8000c2 <__DATA_REGION_ORIGIN__+0x62>
    2386:	88 e1       	ldi	r24, 0x18	; 24
    2388:	80 93 c1 00 	sts	0x00C1, r24	; 0x8000c1 <__DATA_REGION_ORIGIN__+0x61>
    238c:	08 95       	ret

0000238e <main>:
 * \brief Main function.
 *
 * \return
 ******************************************************************************/
int main(void)
{
    238e:	ef 92       	push	r14
    2390:	ff 92       	push	r15
    2392:	0f 93       	push	r16
    2394:	cf 93       	push	r28
    2396:	df 93       	push	r29
    2398:	00 d0       	rcall	.+0      	; 0x239a <main+0xc>
    239a:	00 d0       	rcall	.+0      	; 0x239c <main+0xe>
    239c:	cd b7       	in	r28, 0x3d	; 61
    239e:	de b7       	in	r29, 0x3e	; 62
    23a0:	e6 ea       	ldi	r30, 0xA6	; 166
    23a2:	f7 e0       	ldi	r31, 0x07	; 7
	for (int i = 0; i < 101; ++i)
	{
			press_memory[i] = 0;
    23a4:	11 92       	st	Z+, r1
    23a6:	11 92       	st	Z+, r1
 *
 * \return
 ******************************************************************************/
int main(void)
{
	for (int i = 0; i < 101; ++i)
    23a8:	88 e0       	ldi	r24, 0x08	; 8
    23aa:	e0 37       	cpi	r30, 0x70	; 112
    23ac:	f8 07       	cpc	r31, r24
    23ae:	d1 f7       	brne	.-12     	; 0x23a4 <main+0x16>
			press_memory[i] = 0;
	}
	// Create task.
	xTaskHandle sekunda_handle;
	xTaskHandle drabinka_handle;
		xTaskCreate
    23b0:	ce 01       	movw	r24, r28
    23b2:	03 96       	adiw	r24, 0x03	; 3
    23b4:	7c 01       	movw	r14, r24
    23b6:	02 e0       	ldi	r16, 0x02	; 2
    23b8:	20 e0       	ldi	r18, 0x00	; 0
    23ba:	30 e0       	ldi	r19, 0x00	; 0
    23bc:	45 e5       	ldi	r20, 0x55	; 85
    23be:	50 e0       	ldi	r21, 0x00	; 0
    23c0:	6e e0       	ldi	r22, 0x0E	; 14
    23c2:	71 e0       	ldi	r23, 0x01	; 1
    23c4:	84 e7       	ldi	r24, 0x74	; 116
    23c6:	90 e0       	ldi	r25, 0x00	; 0
    23c8:	0e 94 5a 01 	call	0x2b4	; 0x2b4 <xTaskCreate>
			 configMINIMAL_STACK_SIZE,
			 NULL,
			 mainSEKUNDA_TASK_PRIORITY,
			 &sekunda_handle
			);
		xTaskCreate
    23cc:	ce 01       	movw	r24, r28
    23ce:	01 96       	adiw	r24, 0x01	; 1
    23d0:	7c 01       	movw	r14, r24
    23d2:	01 e0       	ldi	r16, 0x01	; 1
    23d4:	20 e0       	ldi	r18, 0x00	; 0
    23d6:	30 e0       	ldi	r19, 0x00	; 0
    23d8:	45 e5       	ldi	r20, 0x55	; 85
    23da:	50 e0       	ldi	r21, 0x00	; 0
    23dc:	66 e1       	ldi	r22, 0x16	; 22
    23de:	71 e0       	ldi	r23, 0x01	; 1
    23e0:	83 e5       	ldi	r24, 0x53	; 83
    23e2:	90 e0       	ldi	r25, 0x00	; 0
    23e4:	0e 94 5a 01 	call	0x2b4	; 0x2b4 <xTaskCreate>
			 NULL,
			 mainDRABINKA_TASK_PRIORITY,
			 &drabinka_handle
			);
		// Start scheduler.
	vTaskStartScheduler();
    23e8:	0e 94 3f 03 	call	0x67e	; 0x67e <vTaskStartScheduler>
		return 0;
}
    23ec:	80 e0       	ldi	r24, 0x00	; 0
    23ee:	90 e0       	ldi	r25, 0x00	; 0
    23f0:	0f 90       	pop	r0
    23f2:	0f 90       	pop	r0
    23f4:	0f 90       	pop	r0
    23f6:	0f 90       	pop	r0
    23f8:	df 91       	pop	r29
    23fa:	cf 91       	pop	r28
    23fc:	0f 91       	pop	r16
    23fe:	ff 90       	pop	r15
    2400:	ef 90       	pop	r14
    2402:	08 95       	ret

00002404 <__divmodhi4>:
    2404:	97 fb       	bst	r25, 7
    2406:	07 2e       	mov	r0, r23
    2408:	16 f4       	brtc	.+4      	; 0x240e <__divmodhi4+0xa>
    240a:	00 94       	com	r0
    240c:	07 d0       	rcall	.+14     	; 0x241c <__divmodhi4_neg1>
    240e:	77 fd       	sbrc	r23, 7
    2410:	09 d0       	rcall	.+18     	; 0x2424 <__divmodhi4_neg2>
    2412:	0e 94 16 12 	call	0x242c	; 0x242c <__udivmodhi4>
    2416:	07 fc       	sbrc	r0, 7
    2418:	05 d0       	rcall	.+10     	; 0x2424 <__divmodhi4_neg2>
    241a:	3e f4       	brtc	.+14     	; 0x242a <__divmodhi4_exit>

0000241c <__divmodhi4_neg1>:
    241c:	90 95       	com	r25
    241e:	81 95       	neg	r24
    2420:	9f 4f       	sbci	r25, 0xFF	; 255
    2422:	08 95       	ret

00002424 <__divmodhi4_neg2>:
    2424:	70 95       	com	r23
    2426:	61 95       	neg	r22
    2428:	7f 4f       	sbci	r23, 0xFF	; 255

0000242a <__divmodhi4_exit>:
    242a:	08 95       	ret

0000242c <__udivmodhi4>:
    242c:	aa 1b       	sub	r26, r26
    242e:	bb 1b       	sub	r27, r27
    2430:	51 e1       	ldi	r21, 0x11	; 17
    2432:	07 c0       	rjmp	.+14     	; 0x2442 <__udivmodhi4_ep>

00002434 <__udivmodhi4_loop>:
    2434:	aa 1f       	adc	r26, r26
    2436:	bb 1f       	adc	r27, r27
    2438:	a6 17       	cp	r26, r22
    243a:	b7 07       	cpc	r27, r23
    243c:	10 f0       	brcs	.+4      	; 0x2442 <__udivmodhi4_ep>
    243e:	a6 1b       	sub	r26, r22
    2440:	b7 0b       	sbc	r27, r23

00002442 <__udivmodhi4_ep>:
    2442:	88 1f       	adc	r24, r24
    2444:	99 1f       	adc	r25, r25
    2446:	5a 95       	dec	r21
    2448:	a9 f7       	brne	.-22     	; 0x2434 <__udivmodhi4_loop>
    244a:	80 95       	com	r24
    244c:	90 95       	com	r25
    244e:	bc 01       	movw	r22, r24
    2450:	cd 01       	movw	r24, r26
    2452:	08 95       	ret

00002454 <memcpy>:
    2454:	fb 01       	movw	r30, r22
    2456:	dc 01       	movw	r26, r24
    2458:	02 c0       	rjmp	.+4      	; 0x245e <memcpy+0xa>
    245a:	01 90       	ld	r0, Z+
    245c:	0d 92       	st	X+, r0
    245e:	41 50       	subi	r20, 0x01	; 1
    2460:	50 40       	sbci	r21, 0x00	; 0
    2462:	d8 f7       	brcc	.-10     	; 0x245a <memcpy+0x6>
    2464:	08 95       	ret

00002466 <_exit>:
    2466:	f8 94       	cli

00002468 <__stop_program>:
    2468:	ff cf       	rjmp	.-2      	; 0x2468 <__stop_program>
